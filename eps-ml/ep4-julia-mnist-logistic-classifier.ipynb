{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b439f11d",
   "metadata": {},
   "source": [
    "# Logistic classification with MNIST\n",
    "\n",
    "(two predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f262ba3",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d63e87f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "#using Flux              # the julia ml library\n",
    "using Images            # image processing and machine vision for julia\n",
    "using MLJ               # make_blobs, rmse, confmat, f1score, coerce\n",
    "using MLDataUtils       # label, nlabel, labelfreq\n",
    "using MLDatasets        # mnist\n",
    "\n",
    "#using LinearAlgebra     # pinv pseudo-inverse matrix\n",
    "#using Metrics           # r2-score\n",
    "using Random\n",
    "using StatsBase         # standardize (normalization)\n",
    "#using Distributions\n",
    "\n",
    "using Plots; gr()\n",
    "#using StatsPlots\n",
    "using Printf\n",
    "\n",
    "#using CSV\n",
    "using DataFrames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53a09fe",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5001966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hSymmetry (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature extraction\n",
    "meanIntensity(img) = mean(Float64.(img))\n",
    "\n",
    "function hSymmetry(img)\n",
    "    imgFloat = Float64.(img)\n",
    "    imgReverse = reverse(imgFloat, dims=1)\n",
    "    return -mean( abs.(imgFloat - imgReverse) )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66ccdfa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "printMetrics (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metrics\n",
    "function printMetrics(ŷ, y)\n",
    "    display(confmat(ŷ, y))\n",
    "    println(\"accuracy: \", round(accuracy(ŷ, y); digits=3))\n",
    "    println(\"f1-score: \", round(f1score(ŷ, y);  digits=3))\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53255360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rescaleByColumns (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lib functions\n",
    "image2Vector(M) = vec(Float64.(M))\n",
    "\n",
    "function batchImage2Vector(imagesArray3D)\n",
    "    h, v, N = size(imagesArray3D)\n",
    "    vectorOfImageVectors = [ image2Vector( imagesArray3D[:, :, i] ) for i in 1:N]\n",
    "end\n",
    "\n",
    "vector2Image(vec, h, v) = reshape(Float64.(vec), (h, v))\n",
    "\n",
    "function rescaleByColumns(X)\n",
    "    # using StatsBase\n",
    "    X = Float64.(X)\n",
    "    dt = StatsBase.fit(ZScoreTransform, X; dims=1, center=true, scale=true)\n",
    "    rescaledX = StatsBase.transform(dt, X)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8903cf71",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bd90da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tbody><tr><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAiVJREFUaAW9wT2IFgQABuAHemnI4aJFISgJwkDIIiqIsMLcajiKIEEIshosmgSHhhoUIW/IcIgCISHa+psKsp8hEKSSSAlyECon61Q+jMDT4RuO7w6/n5Pe54myKIuyKIuyKIuyKIuyKIuyKIuyKIuyKIuyKIuyKIsZ3YQ5y17FLdiE3TiI5/EvDuAto6IsyqIsJrgDN+MRPIpb8YzV/sAhzOMSTuI7q0VZlEVZjHE/vsac8ZbwBgb4CH/hH/xmtSiLsiiLMc7iPOasdhyLeAL/4ajpRFmURVmM8Tf24Cn8hEOGfsZ2DLAZr5telEVZlMUEn+IYLmELXsQCBoZ+xcumF2VRFmUxhYuGLhjahY+xZHZRFmVRFjN4Ew/gMTyJr8wuyqIsymIGA7yEH/E+vsEJHMZV04myKIuymNEZvIAj2ImdWIcPcc5kURZlURZr8Al+xwK2YT/uxD78abwoi7IoizX6Bc/haRzBK7gb240XZVEWZXEDFnEUHyDYisfxreuLsiiLslije/EsHkQMncL3xouyKIuymNEmvIZ5bLDsCs5hyXhRFmVRFlPagB3YjY1GncA+fG6yKIuyKIsJ1mMz3sU9Rh3H2/gMS6YTZVEWZXEdt+E93Ie7jPoBC/gSl80myqIsymKFh7EHD+F2oy7jHezHwNpEWZRFWawwj3nLTuMLXMFBLLoxURZlURYr7MVe/58oi7Ioi7Ioi7Ioi7Ioi7IouwZsVVgTmd3ynQAAAABJRU5ErkJg\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAjJJREFUaAW9wT1oHAQABtB3+mGISDN0sIK46SaGFEUnxbEVFTtIkWYVRCgoAYcomRzUDlYQBREUhTo4WCwihcKB0EGtOneTQkAtgu1ih5zDDRlyf0nley/KoizKoizKoizKoizKoizKoizKoizKoixuw1G8inV8jg9wxWxRFmVRFge0ios4hBFO4VkcNluURVmUxQE8hq+xghFu4BYO4wn8jFsmi7Ioi7LYh7uxhi9wn11X8Q7O4Qe8ibdNFmVRFmWxDx/jpL3WcA+GeAoPmy7KoizKYkFHcRwDY0N8i3exjV/wN57GwHRRFmVRFgtYxUUcwgjf4SSexCY+wZ/4DTs4jjVcsVeURVmUxRwPYQMr+Avb+Aw3cQEX7LWM1/GSvaIsyqIsZljCeziGG1jHT1g23wMmi7Ioi7KYYQ3HjD2HodsXZVEWZTHDGQwwxNBi7sAOBiaLsiiLspjiGaxihPMWt4MRfjVZlEVZlMUUy7gLf+Ar8y1hy9glvGGyKIuyKIs5/sW22ZawiQ1cwxncNFmURVmUxRznzbaKDbyIb3DCbFEWZVEWUwwwwPM4bbLXsIkVfIl180VZlEVZTDHCCEdwFp/iOh7HKTyC+/E7vseHFhNlURZlMcedeAUn8A8etOsyLuEti4uyKIuymOIyfsSjxo7gXmPXcQ6n7V+URVmUxRTX8AJexqZd7+MjXHUwURZlURYzbGMLW/4/URZlURZlURZlURZlURZlURZlURZlUfYfqPxYlL4fzGQAAAAASUVORK5C\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAbVJREFUaAW9wT2rDQAABuDnnN6UhSLdlNQdbrZrMjCgbkl2E9kY/ASrSfkBBukOjMJkMJkQRvJRihhsSpFSDGdw7nHP/Tid3ueJsiiLsiiLsiiLsiiLsiiLsiiLsiiLsiiLsiiLsiiLOVvBHZzAW/+LsiiLsphwHHtxz2yO4IXpoizKoiwmnMQS7tm+IRZxEAPri7Ioi7KYcAFPzGY/LuI23lhflEVZlMWEodndNPLedFEWZVEWY5axYHa7jTwyXZRFWZTFmDPYaTYLWDTyxXRRFmVRFmMOGXll+65jAe/w3XRRFmVRFut4bmt24TTO45SRq/hmuiiLsiiLdeyx1mEMsYID2IFzGOInnuEXgpc2FmVRFmUx5if+4Aau+GcZA/zGD7zGLbzAY3zFZ+zEGxuLsiiLshhzGR9xzFqf8ACv8dT/LmEfPthclEVZlMWEa7Zvxchdm4uyKIuymKP7NhdlURZlURZlURZlMScDLOGJjUVZlEVZzMkfDG0uyqIsymKOjmLVxqIsyqIs5mRga6IsyqIs5uAhztqaKIuyKIs5WMWqrYmyKIuyKIuyKIuyKIuyKIuyv/irMYSJ7ydGAAAAAElFTkSuQmCC\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAYtJREFUaAW9waFqVQEABuCP8YNRRUFM7glkDzDQoGIw+AYbdpugYcUgDEwiy4p9wSooCjLwDWYRDIJrCibD1XDCLc577rmX//uiLMqiLMqiLMqiLMqiLMqiLMqiLMqiLMqiLMqiLMpiTfbwGBu4jg/+LcqiLMpiDXbxCDODP04XZVEWZbEGV3DGOFEWZVEWK7qB+wbHuIMTp4uyKIuyWME2XuKswVN89X9RFmVRFivYwWWD93hlsSiLsiiLiS7iHmb4gSfGibIoi7KYYBOH5p7jnXGiLMqiLCa4jasGb/HMeFEWZVEWS7qLfYOP2MFP40VZlEVZLGETh+a+4MRyoizKoiyW8BAzc/uWF2VRFmUx0hZumXuNz5YXZVEWZTHSG5w3+IRd00RZlEVZjHQBM4MD/DJNlEVZlMUIL7Bh7sh0URZlURYLbOEmZviNA5yYLsqiLMpigXO4ZPAND6wmyqIsyqIsyqIsymKBYxxh23pEWZRFWSzwHdesT5RFWZRFWZRFWZRFWZRFWZT9BXYjLFSLepVZAAAAAElFTkSuQmCC\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAf5JREFUaAW9wT+I1QUAB/DPxRf7Q4PEXeDikG22STRlS1xbOHkOOTganFMQooSgNtTU0pJDosEhIogtR0uUi9AmuES1iMtFxAMJHO45/IYb5L177xd8P58oi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7JY0ns4jeM4avAZnuB93MADs0VZlEVZLGED32AVK/gZa/jaYAWrOGW2KIuyKIsFBO/iO7yGX3AZ9/EybmHd4DfzRVmURVks4BNcM/gJG5gYbGDd4DGumy/KoizKYh9XcB5TfIuLmNhzwZ5z2DFflEVZlMUcX+A8nmEbn+M/g1ewjsNYwRXctb8oi7IoixkO4lNMsY0T9ryNH3DM4Da+spgoi7IoixkOYNXgHN7EGXyMd/A6ppjiJp5aTJRFWZTFDM+wgzX8hak9TzDBIfyNexYXZVEWZTHDvziBH/EG/sBdfI9/sIVD2LKcKIuyKIs5HmDNi47jA+ziT8uJsiiLshjhVexiii3LibIoi7IYYdt4URZlURYjfGS8KIuyKIsRjhgvyqIsymKEX/ESdi0vyqIsymKEh/gdb+EIdiwuyqIsymKkL3ENV7GJRxYTZVEWZTHSHZzCh7iEM3hqf1EWZVEWI01wEldxFpfwyP6iLMqiLP6HCTaxaXFRFmVR9hxr7UyvfehgBAAAAABJRU5ErkJg\"></td></tr></tbody></table><div><small>(a vector displayed as a row to save space)</small></div>"
      ],
      "text/plain": [
       "5-element Vector{Base.ReinterpretArray{Gray{N0f8}, 2, N0f8, Matrix{N0f8}, true}}:\n",
       " [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n",
       " [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n",
       " [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n",
       " [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n",
       " [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1×5 adjoint(::Vector{Int64}) with eltype Int64:\n",
       " 5  0  4  1  9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load mnist from MLDatasets\n",
    "trainX_original,      trainY_original      = MNIST.traindata()\n",
    "validationX_original, validationY_original = MNIST.testdata();\n",
    "\n",
    "display([MNIST.convert2image(MNIST.traintensor(i)) for i in 1:5])\n",
    "trainY_original[1:5]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f2acc6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28, 28, 42001), (28, 28, 17999), (28, 28, 10000))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split trainset, testset, validation set\n",
    "Random.seed!(1)\n",
    "(trainX, trainY), (testX, testY) = stratifiedobs((trainX_original, trainY_original), p = 0.7)\n",
    "validationX = copy(validationX_original); validationY = copy(validationY_original)\n",
    "\n",
    "size(trainX), size(testX), size(validationX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b9c3b0",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "Data preprocessing depends on the data source, thus can widely vary from what is shown here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a75bf6b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Vector{Float64}}:\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert images to vectors\n",
    "trainX = batchImage2Vector(trainX)\n",
    "trainX[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d182058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Int64}:\n",
       " 1\n",
       " 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((8514,), (8514,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select classes for prediction\n",
    "c = (1, 5)\n",
    "\n",
    "# data selection from above classes and sizes\n",
    "trainX = vcat( trainX[trainY .== c[1] ], trainX[ trainY .== c[2] ] )\n",
    "trainY = vcat( trainY[trainY .== c[1] ], trainY[ trainY .== c[2] ] )\n",
    "\n",
    "display(levels(trainY))\n",
    "size(trainX), size(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a941e91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictors and outcome\n",
    "function generatePredictors(X)\n",
    "    N = size(X)[1]\n",
    "    x1 = [meanIntensity(X[i]) for i in 1:N]\n",
    "    x2 = [hSymmetry(X[i])     for i in 1:N]\n",
    "    Xs = hcat(x1, x2)\n",
    "    Xs = rescaleByColumns(Xs)\n",
    "    \n",
    "    return Xs\n",
    "end\n",
    "\n",
    "trainXLog = generatePredictors(trainX)\n",
    "trainYLog = copy(trainY);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbaf1f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specific conversions for the model to fit\n",
    "trainXLog = DataFrame(trainXLog, :auto)\n",
    "trainYLog = coerce(trainYLog, OrderedFactor);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26954e9",
   "metadata": {},
   "source": [
    "## Training, Testing, Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb875eb7",
   "metadata": {},
   "source": [
    "### Load the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88839a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLJLinearModels.LogisticClassifier"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticClassifier = @load LogisticClassifier pkg=MLJLinearModels verbosity=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9827ee",
   "metadata": {},
   "source": [
    "### Instantiate the model\n",
    "\n",
    "In the context of MLJ, \"model\" means just a container for hyper-parameters.\n",
    "\n",
    "It is worth to note the output of the below command line, which is a list of the actual values assigned for each hyper-parameters, including the default ones. This information can be useful, for exemple, for tuning the parameter at a later stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d2e528b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticClassifier(\n",
       "    lambda = 1.0,\n",
       "    gamma = 0.0,\n",
       "    penalty = :l2,\n",
       "    fit_intercept = true,\n",
       "    penalize_intercept = false,\n",
       "    scale_penalty_with_samples = true,\n",
       "    solver = nothing)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticClassifier()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a2b80462",
   "metadata": {},
   "source": [
    "info(LogisticClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad11e62b",
   "metadata": {},
   "source": [
    "### Creates a machine\n",
    "\n",
    "In MLJ, \"machine\" means an object with all learning parameters (i.e. hyper-parameters + trainset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac360eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Machine{LogisticClassifier,…} trained 0 times; caches data\n",
       "  model: MLJLinearModels.LogisticClassifier\n",
       "  args: \n",
       "    1:\tSource @746 ⏎ `Table{AbstractVector{Continuous}}`\n",
       "    2:\tSource @969 ⏎ `AbstractVector{OrderedFactor{2}}`\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mach = MLJ.machine(model, trainXLog, trainYLog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b248fb7",
   "metadata": {},
   "source": [
    "### Train the machine\n",
    "\n",
    "The machine (or model) is trained according to the programmed hyper-parameters and dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f545d603",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training Machine{LogisticClassifier,…}.\n",
      "└ @ MLJBase /home/ciro/.julia/packages/MLJBase/CglMw/src/machines.jl:464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Machine{LogisticClassifier,…} trained 1 time; caches data\n",
       "  model: MLJLinearModels.LogisticClassifier\n",
       "  args: \n",
       "    1:\tSource @746 ⏎ `Table{AbstractVector{Continuous}}`\n",
       "    2:\tSource @969 ⏎ `AbstractVector{OrderedFactor{2}}`\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit!(mach,\n",
    "    # acceleration = CPUThreads(),   # https://alan-turing-institute.github.io/MLJ.jl/v0.7/acceleration_and_parallelism/\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ed512e",
   "metadata": {},
   "source": [
    "After training, one can inspect the learning parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75147513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(classes = CategoricalArrays.CategoricalValue{Int64, UInt32}[1, 5],\n",
       " coefs = [:x1 => 0.22327300773694728, :x2 => -0.27803815922822733],\n",
       " intercept = -0.22368399037741235,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_params(mach)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da0347c",
   "metadata": {},
   "source": [
    "Everything else the developer might be interested in, if any, can be accesses from the training report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa670359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report(mach)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c248ab3",
   "metadata": {},
   "source": [
    "### Predict an outcome\n",
    "\n",
    "The trained machine/model, stored in the object created for that purpose, is now used to predict the outcome for the trainset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d929faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = MLJ.predict(mach, trainXLog);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d9e558",
   "metadata": {},
   "source": [
    "We can inspect a few rows of the prediction, then just a single row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e149e3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element CategoricalDistributions.UnivariateFiniteArray{OrderedFactor{2}, Int64, UInt32, Float64, 1}:\n",
       " UnivariateFinite{OrderedFactor{2}}(1=>0.633, 5=>0.367)\n",
       " UnivariateFinite{OrderedFactor{2}}(1=>0.704, 5=>0.296)\n",
       " UnivariateFinite{OrderedFactor{2}}(1=>0.698, 5=>0.302)\n",
       " UnivariateFinite{OrderedFactor{2}}(1=>0.632, 5=>0.368)\n",
       " UnivariateFinite{OrderedFactor{2}}(1=>0.647, 5=>0.353)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "         \u001b[1mUnivariateFinite{OrderedFactor{2}}\u001b[22m     \n",
       "     \u001b[90m┌                                        ┐\u001b[39m \n",
       "   \u001b[0m1 \u001b[90m┤\u001b[39m\u001b[38;5;2m■■■■■■■■■■■■■■■■■■■■\u001b[39m\u001b[0m 0.6330328095306961 \u001b[90m \u001b[39m \n",
       "   \u001b[0m5 \u001b[90m┤\u001b[39m\u001b[38;5;2m■■■■■■■■■■■■\u001b[39m\u001b[0m 0.36696719046930387        \u001b[90m \u001b[39m \n",
       "     \u001b[90m└                                        ┘\u001b[39m "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(p[1:5])\n",
    "p[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f980bed",
   "metadata": {},
   "source": [
    "For this particular model, the prediction is represented as probabilities for each of the classes. To translate that as the most likely class, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e709471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element CategoricalArrays.CategoricalArray{Int64,1,UInt32}:\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ŷ = predict_mode(mach, trainXLog)\n",
    "ŷ[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a55afab",
   "metadata": {},
   "source": [
    "We can also extract relevant metrics as in the below example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "526a13d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              ┌───────────────────────────┐\n",
       "              │       Ground Truth        │\n",
       "┌─────────────┼─────────────┬─────────────┤\n",
       "│  Predicted  │      1      │      5      │\n",
       "├─────────────┼─────────────┼─────────────┤\n",
       "│      1      │    4651     │    1281     │\n",
       "├─────────────┼─────────────┼─────────────┤\n",
       "│      5      │     68      │    2514     │\n",
       "└─────────────┴─────────────┴─────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.842\n",
      "f1-score: 0.788\n"
     ]
    }
   ],
   "source": [
    "printMetrics(ŷ, trainYLog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00479bba",
   "metadata": {},
   "source": [
    "### Tune the hyper-parameters\n",
    "\n",
    "When this particular model was instantiated above, one can see that the hyper-parameter \"Lambda\" could be of relevance to improve the model. Let's tune it as an attempt to minimize the cross-entropy loss and maximize accuracy.\n",
    "\n",
    "First, we define the parameter and limits to scan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60aca7bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NumericRange(1.0e-5 ≤ lambda ≤ 0.1; origin=0.050005, unit=0.049995000000000005) on log10 scale"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = range(model, :lambda, lower = 1e-5, upper=1e-1, scale = :log10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76392a4",
   "metadata": {},
   "source": [
    "Then, we define a 10-fold cross-validation, and capture the range parameter(lambdas) and the cross-entropy losses vectors (losses). The first two parameters of the tuple out of the function \"learning_curve\" are not relevent for this example, so are ignored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20e2511a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training Machine{ProbabilisticTunedModel{Grid,…},…}.\n",
      "└ @ MLJBase /home/ciro/.julia/packages/MLJBase/CglMw/src/machines.jl:464\n",
      "┌ Info: Attempting to evaluate 100 models.\n",
      "└ @ MLJTuning /home/ciro/.julia/packages/MLJTuning/Al9yX/src/tuned_models.jl:680\n",
      "\u001b[33mEvaluating over 100 metamodels: 100%[=========================] Time: 0:00:28\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "_, _, lambdas, losses = learning_curve(mach,\n",
    "                                        range=r,\n",
    "                                        resampling=CV(nfolds=10),\n",
    "                                        resolution=100,                 # default 30\n",
    "                                        measure=cross_entropy,\n",
    "                                        acceleration=CPUProcesses());   # useful if more than one parameter is plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90ce1ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"500\" height=\"300\" viewBox=\"0 0 2000 1200\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip170\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2000\" height=\"1200\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip170)\" d=\"\n",
       "M0 1200 L2000 1200 L2000 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip171\">\n",
       "    <rect x=\"400\" y=\"0\" width=\"1401\" height=\"1200\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip170)\" d=\"\n",
       "M241.276 1035.39 L1952.76 1035.39 L1952.76 117.424 L241.276 117.424  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip172\">\n",
       "    <rect x=\"241\" y=\"117\" width=\"1712\" height=\"919\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip172)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  289.553,1035.39 289.553,117.424 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip172)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  693.244,1035.39 693.244,117.424 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip172)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1096.94,1035.39 1096.94,117.424 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip172)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1500.63,1035.39 1500.63,117.424 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip172)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1904.32,1035.39 1904.32,117.424 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip170)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  241.276,1035.39 1952.76,1035.39 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip170)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  289.553,1035.39 289.553,1016.49 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip170)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  693.244,1035.39 693.244,1016.49 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip170)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1096.94,1035.39 1096.94,1016.49 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip170)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1500.63,1035.39 1500.63,1016.49 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip170)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1904.32,1035.39 1904.32,1016.49 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip170)\" d=\"M236.775 1063.11 Q233.164 1063.11 231.335 1066.67 Q229.53 1070.21 229.53 1077.34 Q229.53 1084.45 231.335 1088.01 Q233.164 1091.56 236.775 1091.56 Q240.41 1091.56 242.215 1088.01 Q244.044 1084.45 244.044 1077.34 Q244.044 1070.21 242.215 1066.67 Q240.41 1063.11 236.775 1063.11 M236.775 1059.4 Q242.585 1059.4 245.641 1064.01 Q248.72 1068.59 248.72 1077.34 Q248.72 1086.07 245.641 1090.68 Q242.585 1095.26 236.775 1095.26 Q230.965 1095.26 227.886 1090.68 Q224.831 1086.07 224.831 1077.34 Q224.831 1068.59 227.886 1064.01 Q230.965 1059.4 236.775 1059.4 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M256.937 1088.71 L261.821 1088.71 L261.821 1094.59 L256.937 1094.59 L256.937 1088.71 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M282.007 1063.11 Q278.395 1063.11 276.567 1066.67 Q274.761 1070.21 274.761 1077.34 Q274.761 1084.45 276.567 1088.01 Q278.395 1091.56 282.007 1091.56 Q285.641 1091.56 287.446 1088.01 Q289.275 1084.45 289.275 1077.34 Q289.275 1070.21 287.446 1066.67 Q285.641 1063.11 282.007 1063.11 M282.007 1059.4 Q287.817 1059.4 290.872 1064.01 Q293.951 1068.59 293.951 1077.34 Q293.951 1086.07 290.872 1090.68 Q287.817 1095.26 282.007 1095.26 Q276.196 1095.26 273.118 1090.68 Q270.062 1086.07 270.062 1077.34 Q270.062 1068.59 273.118 1064.01 Q276.196 1059.4 282.007 1059.4 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M312.168 1063.11 Q308.557 1063.11 306.729 1066.67 Q304.923 1070.21 304.923 1077.34 Q304.923 1084.45 306.729 1088.01 Q308.557 1091.56 312.168 1091.56 Q315.803 1091.56 317.608 1088.01 Q319.437 1084.45 319.437 1077.34 Q319.437 1070.21 317.608 1066.67 Q315.803 1063.11 312.168 1063.11 M312.168 1059.4 Q317.979 1059.4 321.034 1064.01 Q324.113 1068.59 324.113 1077.34 Q324.113 1086.07 321.034 1090.68 Q317.979 1095.26 312.168 1095.26 Q306.358 1095.26 303.28 1090.68 Q300.224 1086.07 300.224 1077.34 Q300.224 1068.59 303.28 1064.01 Q306.358 1059.4 312.168 1059.4 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M342.33 1063.11 Q338.719 1063.11 336.89 1066.67 Q335.085 1070.21 335.085 1077.34 Q335.085 1084.45 336.89 1088.01 Q338.719 1091.56 342.33 1091.56 Q345.965 1091.56 347.77 1088.01 Q349.599 1084.45 349.599 1077.34 Q349.599 1070.21 347.77 1066.67 Q345.965 1063.11 342.33 1063.11 M342.33 1059.4 Q348.14 1059.4 351.196 1064.01 Q354.275 1068.59 354.275 1077.34 Q354.275 1086.07 351.196 1090.68 Q348.14 1095.26 342.33 1095.26 Q336.52 1095.26 333.441 1090.68 Q330.386 1086.07 330.386 1077.34 Q330.386 1068.59 333.441 1064.01 Q336.52 1059.4 342.33 1059.4 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M640.964 1063.11 Q637.353 1063.11 635.524 1066.67 Q633.719 1070.21 633.719 1077.34 Q633.719 1084.45 635.524 1088.01 Q637.353 1091.56 640.964 1091.56 Q644.598 1091.56 646.404 1088.01 Q648.233 1084.45 648.233 1077.34 Q648.233 1070.21 646.404 1066.67 Q644.598 1063.11 640.964 1063.11 M640.964 1059.4 Q646.774 1059.4 649.83 1064.01 Q652.909 1068.59 652.909 1077.34 Q652.909 1086.07 649.83 1090.68 Q646.774 1095.26 640.964 1095.26 Q635.154 1095.26 632.075 1090.68 Q629.02 1086.07 629.02 1077.34 Q629.02 1068.59 632.075 1064.01 Q635.154 1059.4 640.964 1059.4 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M661.126 1088.71 L666.01 1088.71 L666.01 1094.59 L661.126 1094.59 L661.126 1088.71 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M686.195 1063.11 Q682.584 1063.11 680.756 1066.67 Q678.95 1070.21 678.95 1077.34 Q678.95 1084.45 680.756 1088.01 Q682.584 1091.56 686.195 1091.56 Q689.83 1091.56 691.635 1088.01 Q693.464 1084.45 693.464 1077.34 Q693.464 1070.21 691.635 1066.67 Q689.83 1063.11 686.195 1063.11 M686.195 1059.4 Q692.006 1059.4 695.061 1064.01 Q698.14 1068.59 698.14 1077.34 Q698.14 1086.07 695.061 1090.68 Q692.006 1095.26 686.195 1095.26 Q680.385 1095.26 677.307 1090.68 Q674.251 1086.07 674.251 1077.34 Q674.251 1068.59 677.307 1064.01 Q680.385 1059.4 686.195 1059.4 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M710.385 1090.65 L726.704 1090.65 L726.704 1094.59 L704.76 1094.59 L704.76 1090.65 Q707.422 1087.9 712.006 1083.27 Q716.612 1078.62 717.793 1077.27 Q720.038 1074.75 720.917 1073.01 Q721.82 1071.25 721.82 1069.56 Q721.82 1066.81 719.876 1065.07 Q717.955 1063.34 714.853 1063.34 Q712.654 1063.34 710.2 1064.1 Q707.769 1064.87 704.992 1066.42 L704.992 1061.69 Q707.816 1060.56 710.269 1059.98 Q712.723 1059.4 714.76 1059.4 Q720.13 1059.4 723.325 1062.09 Q726.519 1064.77 726.519 1069.26 Q726.519 1071.39 725.709 1073.31 Q724.922 1075.21 722.816 1077.81 Q722.237 1078.48 719.135 1081.69 Q716.033 1084.89 710.385 1090.65 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M736.566 1060.03 L754.922 1060.03 L754.922 1063.96 L740.848 1063.96 L740.848 1072.44 Q741.866 1072.09 742.885 1071.93 Q743.903 1071.74 744.922 1071.74 Q750.709 1071.74 754.089 1074.91 Q757.468 1078.08 757.468 1083.5 Q757.468 1089.08 753.996 1092.18 Q750.524 1095.26 744.204 1095.26 Q742.028 1095.26 739.76 1094.89 Q737.515 1094.52 735.107 1093.78 L735.107 1089.08 Q737.191 1090.21 739.413 1090.77 Q741.635 1091.32 744.112 1091.32 Q748.116 1091.32 750.454 1089.22 Q752.792 1087.11 752.792 1083.5 Q752.792 1079.89 750.454 1077.78 Q748.116 1075.68 744.112 1075.68 Q742.237 1075.68 740.362 1076.09 Q738.51 1076.51 736.566 1077.39 L736.566 1060.03 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M1044.16 1063.11 Q1040.55 1063.11 1038.72 1066.67 Q1036.91 1070.21 1036.91 1077.34 Q1036.91 1084.45 1038.72 1088.01 Q1040.55 1091.56 1044.16 1091.56 Q1047.79 1091.56 1049.6 1088.01 Q1051.43 1084.45 1051.43 1077.34 Q1051.43 1070.21 1049.6 1066.67 Q1047.79 1063.11 1044.16 1063.11 M1044.16 1059.4 Q1049.97 1059.4 1053.02 1064.01 Q1056.1 1068.59 1056.1 1077.34 Q1056.1 1086.07 1053.02 1090.68 Q1049.97 1095.26 1044.16 1095.26 Q1038.35 1095.26 1035.27 1090.68 Q1032.21 1086.07 1032.21 1077.34 Q1032.21 1068.59 1035.27 1064.01 Q1038.35 1059.4 1044.16 1059.4 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M1064.32 1088.71 L1069.2 1088.71 L1069.2 1094.59 L1064.32 1094.59 L1064.32 1088.71 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M1089.39 1063.11 Q1085.78 1063.11 1083.95 1066.67 Q1082.14 1070.21 1082.14 1077.34 Q1082.14 1084.45 1083.95 1088.01 Q1085.78 1091.56 1089.39 1091.56 Q1093.02 1091.56 1094.83 1088.01 Q1096.66 1084.45 1096.66 1077.34 Q1096.66 1070.21 1094.83 1066.67 Q1093.02 1063.11 1089.39 1063.11 M1089.39 1059.4 Q1095.2 1059.4 1098.25 1064.01 Q1101.33 1068.59 1101.33 1077.34 Q1101.33 1086.07 1098.25 1090.68 Q1095.2 1095.26 1089.39 1095.26 Q1083.58 1095.26 1080.5 1090.68 Q1077.44 1086.07 1077.44 1077.34 Q1077.44 1068.59 1080.5 1064.01 Q1083.58 1059.4 1089.39 1059.4 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M1109.6 1060.03 L1127.95 1060.03 L1127.95 1063.96 L1113.88 1063.96 L1113.88 1072.44 Q1114.9 1072.09 1115.92 1071.93 Q1116.94 1071.74 1117.95 1071.74 Q1123.74 1071.74 1127.12 1074.91 Q1130.5 1078.08 1130.5 1083.5 Q1130.5 1089.08 1127.03 1092.18 Q1123.56 1095.26 1117.24 1095.26 Q1115.06 1095.26 1112.79 1094.89 Q1110.55 1094.52 1108.14 1093.78 L1108.14 1089.08 Q1110.22 1090.21 1112.44 1090.77 Q1114.67 1091.32 1117.14 1091.32 Q1121.15 1091.32 1123.49 1089.22 Q1125.82 1087.11 1125.82 1083.5 Q1125.82 1079.89 1123.49 1077.78 Q1121.15 1075.68 1117.14 1075.68 Q1115.27 1075.68 1113.39 1076.09 Q1111.54 1076.51 1109.6 1077.39 L1109.6 1060.03 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M1149.71 1063.11 Q1146.1 1063.11 1144.27 1066.67 Q1142.47 1070.21 1142.47 1077.34 Q1142.47 1084.45 1144.27 1088.01 Q1146.1 1091.56 1149.71 1091.56 Q1153.35 1091.56 1155.15 1088.01 Q1156.98 1084.45 1156.98 1077.34 Q1156.98 1070.21 1155.15 1066.67 Q1153.35 1063.11 1149.71 1063.11 M1149.71 1059.4 Q1155.52 1059.4 1158.58 1064.01 Q1161.66 1068.59 1161.66 1077.34 Q1161.66 1086.07 1158.58 1090.68 Q1155.52 1095.26 1149.71 1095.26 Q1143.9 1095.26 1140.82 1090.68 Q1137.77 1086.07 1137.77 1077.34 Q1137.77 1068.59 1140.82 1064.01 Q1143.9 1059.4 1149.71 1059.4 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M1448.35 1063.11 Q1444.74 1063.11 1442.91 1066.67 Q1441.1 1070.21 1441.1 1077.34 Q1441.1 1084.45 1442.91 1088.01 Q1444.74 1091.56 1448.35 1091.56 Q1451.98 1091.56 1453.79 1088.01 Q1455.62 1084.45 1455.62 1077.34 Q1455.62 1070.21 1453.79 1066.67 Q1451.98 1063.11 1448.35 1063.11 M1448.35 1059.4 Q1454.16 1059.4 1457.21 1064.01 Q1460.29 1068.59 1460.29 1077.34 Q1460.29 1086.07 1457.21 1090.68 Q1454.16 1095.26 1448.35 1095.26 Q1442.54 1095.26 1439.46 1090.68 Q1436.4 1086.07 1436.4 1077.34 Q1436.4 1068.59 1439.46 1064.01 Q1442.54 1059.4 1448.35 1059.4 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M1468.51 1088.71 L1473.39 1088.71 L1473.39 1094.59 L1468.51 1094.59 L1468.51 1088.71 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M1493.58 1063.11 Q1489.97 1063.11 1488.14 1066.67 Q1486.33 1070.21 1486.33 1077.34 Q1486.33 1084.45 1488.14 1088.01 Q1489.97 1091.56 1493.58 1091.56 Q1497.21 1091.56 1499.02 1088.01 Q1500.85 1084.45 1500.85 1077.34 Q1500.85 1070.21 1499.02 1066.67 Q1497.21 1063.11 1493.58 1063.11 M1493.58 1059.4 Q1499.39 1059.4 1502.44 1064.01 Q1505.52 1068.59 1505.52 1077.34 Q1505.52 1086.07 1502.44 1090.68 Q1499.39 1095.26 1493.58 1095.26 Q1487.77 1095.26 1484.69 1090.68 Q1481.63 1086.07 1481.63 1077.34 Q1481.63 1068.59 1484.69 1064.01 Q1487.77 1059.4 1493.58 1059.4 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M1512.56 1060.03 L1534.78 1060.03 L1534.78 1062.02 L1522.24 1094.59 L1517.35 1094.59 L1529.16 1063.96 L1512.56 1063.96 L1512.56 1060.03 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M1543.95 1060.03 L1562.3 1060.03 L1562.3 1063.96 L1548.23 1063.96 L1548.23 1072.44 Q1549.25 1072.09 1550.27 1071.93 Q1551.29 1071.74 1552.3 1071.74 Q1558.09 1071.74 1561.47 1074.91 Q1564.85 1078.08 1564.85 1083.5 Q1564.85 1089.08 1561.38 1092.18 Q1557.91 1095.26 1551.59 1095.26 Q1549.41 1095.26 1547.14 1094.89 Q1544.9 1094.52 1542.49 1093.78 L1542.49 1089.08 Q1544.57 1090.21 1546.8 1090.77 Q1549.02 1091.32 1551.49 1091.32 Q1555.5 1091.32 1557.84 1089.22 Q1560.17 1087.11 1560.17 1083.5 Q1560.17 1079.89 1557.84 1077.78 Q1555.5 1075.68 1551.49 1075.68 Q1549.62 1075.68 1547.74 1076.09 Q1545.89 1076.51 1543.95 1077.39 L1543.95 1060.03 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M1851.54 1063.11 Q1847.93 1063.11 1846.1 1066.67 Q1844.29 1070.21 1844.29 1077.34 Q1844.29 1084.45 1846.1 1088.01 Q1847.93 1091.56 1851.54 1091.56 Q1855.17 1091.56 1856.98 1088.01 Q1858.81 1084.45 1858.81 1077.34 Q1858.81 1070.21 1856.98 1066.67 Q1855.17 1063.11 1851.54 1063.11 M1851.54 1059.4 Q1857.35 1059.4 1860.41 1064.01 Q1863.48 1068.59 1863.48 1077.34 Q1863.48 1086.07 1860.41 1090.68 Q1857.35 1095.26 1851.54 1095.26 Q1845.73 1095.26 1842.65 1090.68 Q1839.6 1086.07 1839.6 1077.34 Q1839.6 1068.59 1842.65 1064.01 Q1845.73 1059.4 1851.54 1059.4 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M1871.7 1088.71 L1876.59 1088.71 L1876.59 1094.59 L1871.7 1094.59 L1871.7 1088.71 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M1887.58 1090.65 L1895.22 1090.65 L1895.22 1064.29 L1886.91 1065.95 L1886.91 1061.69 L1895.17 1060.03 L1899.85 1060.03 L1899.85 1090.65 L1907.49 1090.65 L1907.49 1094.59 L1887.58 1094.59 L1887.58 1090.65 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M1926.93 1063.11 Q1923.32 1063.11 1921.49 1066.67 Q1919.69 1070.21 1919.69 1077.34 Q1919.69 1084.45 1921.49 1088.01 Q1923.32 1091.56 1926.93 1091.56 Q1930.57 1091.56 1932.37 1088.01 Q1934.2 1084.45 1934.2 1077.34 Q1934.2 1070.21 1932.37 1066.67 Q1930.57 1063.11 1926.93 1063.11 M1926.93 1059.4 Q1932.74 1059.4 1935.8 1064.01 Q1938.88 1068.59 1938.88 1077.34 Q1938.88 1086.07 1935.8 1090.68 Q1932.74 1095.26 1926.93 1095.26 Q1921.12 1095.26 1918.04 1090.68 Q1914.99 1086.07 1914.99 1077.34 Q1914.99 1068.59 1918.04 1064.01 Q1921.12 1059.4 1926.93 1059.4 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M1957.1 1063.11 Q1953.48 1063.11 1951.66 1066.67 Q1949.85 1070.21 1949.85 1077.34 Q1949.85 1084.45 1951.66 1088.01 Q1953.48 1091.56 1957.1 1091.56 Q1960.73 1091.56 1962.54 1088.01 Q1964.36 1084.45 1964.36 1077.34 Q1964.36 1070.21 1962.54 1066.67 Q1960.73 1063.11 1957.1 1063.11 M1957.1 1059.4 Q1962.91 1059.4 1965.96 1064.01 Q1969.04 1068.59 1969.04 1077.34 Q1969.04 1086.07 1965.96 1090.68 Q1962.91 1095.26 1957.1 1095.26 Q1951.29 1095.26 1948.21 1090.68 Q1945.15 1086.07 1945.15 1077.34 Q1945.15 1068.59 1948.21 1064.01 Q1951.29 1059.4 1957.1 1059.4 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M971.946 1126.73 L978.375 1126.73 L978.375 1168.84 L1001.51 1168.84 L1001.51 1174.25 L971.946 1174.25 L971.946 1126.73 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M1024.21 1156.33 Q1017.11 1156.33 1014.37 1157.96 Q1011.64 1159.58 1011.64 1163.49 Q1011.64 1166.61 1013.67 1168.46 Q1015.74 1170.27 1019.27 1170.27 Q1024.14 1170.27 1027.07 1166.84 Q1030.03 1163.37 1030.03 1157.64 L1030.03 1156.33 L1024.21 1156.33 M1035.89 1153.91 L1035.89 1174.25 L1030.03 1174.25 L1030.03 1168.84 Q1028.03 1172.09 1025.04 1173.65 Q1022.04 1175.17 1017.72 1175.17 Q1012.24 1175.17 1008.99 1172.12 Q1005.78 1169.03 1005.78 1163.88 Q1005.78 1157.86 1009.79 1154.8 Q1013.83 1151.75 1021.82 1151.75 L1030.03 1151.75 L1030.03 1151.18 Q1030.03 1147.13 1027.36 1144.94 Q1024.72 1142.71 1019.91 1142.71 Q1016.86 1142.71 1013.96 1143.44 Q1011.06 1144.17 1008.39 1145.64 L1008.39 1140.23 Q1011.6 1138.99 1014.63 1138.38 Q1017.65 1137.74 1020.52 1137.74 Q1028.25 1137.74 1032.07 1141.75 Q1035.89 1145.77 1035.89 1153.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M1075.71 1145.45 Q1077.9 1141.5 1080.96 1139.62 Q1084.01 1137.74 1088.15 1137.74 Q1093.72 1137.74 1096.75 1141.66 Q1099.77 1145.54 1099.77 1152.74 L1099.77 1174.25 L1093.88 1174.25 L1093.88 1152.93 Q1093.88 1147.8 1092.07 1145.32 Q1090.25 1142.84 1086.53 1142.84 Q1081.98 1142.84 1079.34 1145.86 Q1076.69 1148.88 1076.69 1154.1 L1076.69 1174.25 L1070.81 1174.25 L1070.81 1152.93 Q1070.81 1147.77 1068.99 1145.32 Q1067.18 1142.84 1063.39 1142.84 Q1058.9 1142.84 1056.26 1145.89 Q1053.62 1148.92 1053.62 1154.1 L1053.62 1174.25 L1047.73 1174.25 L1047.73 1138.6 L1053.62 1138.6 L1053.62 1144.14 Q1055.62 1140.86 1058.42 1139.3 Q1061.22 1137.74 1065.08 1137.74 Q1068.96 1137.74 1071.66 1139.72 Q1074.4 1141.69 1075.71 1145.45 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M1137.04 1156.46 Q1137.04 1150 1134.37 1146.34 Q1131.73 1142.65 1127.08 1142.65 Q1122.43 1142.65 1119.76 1146.34 Q1117.12 1150 1117.12 1156.46 Q1117.12 1162.92 1119.76 1166.61 Q1122.43 1170.27 1127.08 1170.27 Q1131.73 1170.27 1134.37 1166.61 Q1137.04 1162.92 1137.04 1156.46 M1117.12 1144.01 Q1118.96 1140.83 1121.76 1139.3 Q1124.6 1137.74 1128.51 1137.74 Q1135 1137.74 1139.05 1142.9 Q1143.12 1148.06 1143.12 1156.46 Q1143.12 1164.86 1139.05 1170.02 Q1135 1175.17 1128.51 1175.17 Q1124.6 1175.17 1121.76 1173.65 Q1118.96 1172.09 1117.12 1168.9 L1117.12 1174.25 L1111.23 1174.25 L1111.23 1124.73 L1117.12 1124.73 L1117.12 1144.01 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M1176.28 1144.01 L1176.28 1124.73 L1182.14 1124.73 L1182.14 1174.25 L1176.28 1174.25 L1176.28 1168.9 Q1174.44 1172.09 1171.61 1173.65 Q1168.81 1175.17 1164.86 1175.17 Q1158.4 1175.17 1154.32 1170.02 Q1150.28 1164.86 1150.28 1156.46 Q1150.28 1148.06 1154.32 1142.9 Q1158.4 1137.74 1164.86 1137.74 Q1168.81 1137.74 1171.61 1139.3 Q1174.44 1140.83 1176.28 1144.01 M1156.33 1156.46 Q1156.33 1162.92 1158.97 1166.61 Q1161.64 1170.27 1166.29 1170.27 Q1170.94 1170.27 1173.61 1166.61 Q1176.28 1162.92 1176.28 1156.46 Q1176.28 1150 1173.61 1146.34 Q1170.94 1142.65 1166.29 1142.65 Q1161.64 1142.65 1158.97 1146.34 Q1156.33 1150 1156.33 1156.46 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M1210.41 1156.33 Q1203.31 1156.33 1200.57 1157.96 Q1197.83 1159.58 1197.83 1163.49 Q1197.83 1166.61 1199.87 1168.46 Q1201.94 1170.27 1205.47 1170.27 Q1210.34 1170.27 1213.27 1166.84 Q1216.23 1163.37 1216.23 1157.64 L1216.23 1156.33 L1210.41 1156.33 M1222.09 1153.91 L1222.09 1174.25 L1216.23 1174.25 L1216.23 1168.84 Q1214.22 1172.09 1211.23 1173.65 Q1208.24 1175.17 1203.91 1175.17 Q1198.44 1175.17 1195.19 1172.12 Q1191.98 1169.03 1191.98 1163.88 Q1191.98 1157.86 1195.99 1154.8 Q1200.03 1151.75 1208.02 1151.75 L1216.23 1151.75 L1216.23 1151.18 Q1216.23 1147.13 1213.56 1144.94 Q1210.91 1142.71 1206.11 1142.71 Q1203.05 1142.71 1200.16 1143.44 Q1197.26 1144.17 1194.59 1145.64 L1194.59 1140.23 Q1197.8 1138.99 1200.82 1138.38 Q1203.85 1137.74 1206.71 1137.74 Q1214.45 1137.74 1218.27 1141.75 Q1222.09 1145.77 1222.09 1153.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip172)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  241.276,892.18 1952.76,892.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip172)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  241.276,736.983 1952.76,736.983 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip172)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  241.276,581.786 1952.76,581.786 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip172)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  241.276,426.588 1952.76,426.588 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip172)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  241.276,271.391 1952.76,271.391 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip170)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  241.276,1035.39 241.276,117.424 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip170)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  241.276,892.18 260.174,892.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip170)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  241.276,736.983 260.174,736.983 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip170)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  241.276,581.786 260.174,581.786 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip170)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  241.276,426.588 260.174,426.588 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip170)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  241.276,271.391 260.174,271.391 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip170)\" d=\"M124.031 877.979 Q120.42 877.979 118.591 881.544 Q116.786 885.086 116.786 892.215 Q116.786 899.322 118.591 902.886 Q120.42 906.428 124.031 906.428 Q127.665 906.428 129.471 902.886 Q131.3 899.322 131.3 892.215 Q131.3 885.086 129.471 881.544 Q127.665 877.979 124.031 877.979 M124.031 874.275 Q129.841 874.275 132.897 878.882 Q135.976 883.465 135.976 892.215 Q135.976 900.942 132.897 905.548 Q129.841 910.132 124.031 910.132 Q118.221 910.132 115.142 905.548 Q112.087 900.942 112.087 892.215 Q112.087 883.465 115.142 878.882 Q118.221 874.275 124.031 874.275 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M144.193 903.581 L149.077 903.581 L149.077 909.46 L144.193 909.46 L144.193 903.581 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M163.29 905.525 L179.61 905.525 L179.61 909.46 L157.665 909.46 L157.665 905.525 Q160.327 902.771 164.911 898.141 Q169.517 893.488 170.698 892.146 Q172.943 889.623 173.823 887.887 Q174.725 886.127 174.725 884.437 Q174.725 881.683 172.781 879.947 Q170.86 878.211 167.758 878.211 Q165.559 878.211 163.105 878.975 Q160.675 879.738 157.897 881.289 L157.897 876.567 Q160.721 875.433 163.175 874.854 Q165.628 874.275 167.665 874.275 Q173.036 874.275 176.23 876.961 Q179.424 879.646 179.424 884.137 Q179.424 886.266 178.614 888.187 Q177.827 890.086 175.721 892.678 Q175.142 893.349 172.04 896.567 Q168.938 899.761 163.29 905.525 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M199.424 893.049 Q196.091 893.049 194.17 894.831 Q192.272 896.613 192.272 899.738 Q192.272 902.863 194.17 904.646 Q196.091 906.428 199.424 906.428 Q202.758 906.428 204.679 904.646 Q206.6 902.84 206.6 899.738 Q206.6 896.613 204.679 894.831 Q202.781 893.049 199.424 893.049 M194.748 891.058 Q191.739 890.317 190.049 888.257 Q188.383 886.197 188.383 883.234 Q188.383 879.09 191.323 876.683 Q194.285 874.275 199.424 874.275 Q204.586 874.275 207.526 876.683 Q210.466 879.09 210.466 883.234 Q210.466 886.197 208.776 888.257 Q207.109 890.317 204.123 891.058 Q207.503 891.845 209.378 894.136 Q211.276 896.428 211.276 899.738 Q211.276 904.761 208.197 907.447 Q205.142 910.132 199.424 910.132 Q193.707 910.132 190.628 907.447 Q187.573 904.761 187.573 899.738 Q187.573 896.428 189.471 894.136 Q191.369 891.845 194.748 891.058 M193.035 883.674 Q193.035 886.359 194.702 887.863 Q196.392 889.368 199.424 889.368 Q202.434 889.368 204.123 887.863 Q205.836 886.359 205.836 883.674 Q205.836 880.988 204.123 879.484 Q202.434 877.979 199.424 877.979 Q196.392 877.979 194.702 879.484 Q193.035 880.988 193.035 883.674 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M123.939 722.782 Q120.328 722.782 118.499 726.347 Q116.693 729.888 116.693 737.018 Q116.693 744.124 118.499 747.689 Q120.328 751.231 123.939 751.231 Q127.573 751.231 129.378 747.689 Q131.207 744.124 131.207 737.018 Q131.207 729.888 129.378 726.347 Q127.573 722.782 123.939 722.782 M123.939 719.078 Q129.749 719.078 132.804 723.685 Q135.883 728.268 135.883 737.018 Q135.883 745.745 132.804 750.351 Q129.749 754.934 123.939 754.934 Q118.128 754.934 115.05 750.351 Q111.994 745.745 111.994 737.018 Q111.994 728.268 115.05 723.685 Q118.128 719.078 123.939 719.078 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M144.101 748.383 L148.985 748.383 L148.985 754.263 L144.101 754.263 L144.101 748.383 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M173.337 735.629 Q176.693 736.347 178.568 738.615 Q180.466 740.884 180.466 744.217 Q180.466 749.333 176.948 752.133 Q173.429 754.934 166.948 754.934 Q164.772 754.934 162.457 754.495 Q160.165 754.078 157.712 753.221 L157.712 748.708 Q159.656 749.842 161.971 750.421 Q164.286 750.999 166.809 750.999 Q171.207 750.999 173.499 749.263 Q175.813 747.527 175.813 744.217 Q175.813 741.161 173.661 739.448 Q171.531 737.712 167.712 737.712 L163.684 737.712 L163.684 733.87 L167.897 733.87 Q171.346 733.87 173.174 732.504 Q175.003 731.115 175.003 728.522 Q175.003 725.86 173.105 724.448 Q171.23 723.013 167.712 723.013 Q165.79 723.013 163.591 723.43 Q161.392 723.847 158.753 724.726 L158.753 720.56 Q161.415 719.819 163.73 719.448 Q166.068 719.078 168.128 719.078 Q173.452 719.078 176.554 721.509 Q179.656 723.916 179.656 728.036 Q179.656 730.907 178.012 732.897 Q176.369 734.865 173.337 735.629 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M199.332 722.782 Q195.721 722.782 193.892 726.347 Q192.086 729.888 192.086 737.018 Q192.086 744.124 193.892 747.689 Q195.721 751.231 199.332 751.231 Q202.966 751.231 204.772 747.689 Q206.6 744.124 206.6 737.018 Q206.6 729.888 204.772 726.347 Q202.966 722.782 199.332 722.782 M199.332 719.078 Q205.142 719.078 208.197 723.685 Q211.276 728.268 211.276 737.018 Q211.276 745.745 208.197 750.351 Q205.142 754.934 199.332 754.934 Q193.522 754.934 190.443 750.351 Q187.387 745.745 187.387 737.018 Q187.387 728.268 190.443 723.685 Q193.522 719.078 199.332 719.078 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M125.536 567.584 Q121.925 567.584 120.096 571.149 Q118.291 574.691 118.291 581.82 Q118.291 588.927 120.096 592.492 Q121.925 596.033 125.536 596.033 Q129.17 596.033 130.976 592.492 Q132.804 588.927 132.804 581.82 Q132.804 574.691 130.976 571.149 Q129.17 567.584 125.536 567.584 M125.536 563.881 Q131.346 563.881 134.402 568.487 Q137.48 573.071 137.48 581.82 Q137.48 590.547 134.402 595.154 Q131.346 599.737 125.536 599.737 Q119.726 599.737 116.647 595.154 Q113.591 590.547 113.591 581.82 Q113.591 573.071 116.647 568.487 Q119.726 563.881 125.536 563.881 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M145.698 593.186 L150.582 593.186 L150.582 599.066 L145.698 599.066 L145.698 593.186 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M174.934 580.432 Q178.29 581.149 180.165 583.418 Q182.063 585.686 182.063 589.019 Q182.063 594.135 178.545 596.936 Q175.026 599.737 168.545 599.737 Q166.369 599.737 164.054 599.297 Q161.763 598.881 159.309 598.024 L159.309 593.51 Q161.253 594.644 163.568 595.223 Q165.883 595.802 168.406 595.802 Q172.804 595.802 175.096 594.066 Q177.411 592.33 177.411 589.019 Q177.411 585.964 175.258 584.251 Q173.128 582.515 169.309 582.515 L165.281 582.515 L165.281 578.672 L169.494 578.672 Q172.943 578.672 174.772 577.307 Q176.6 575.918 176.6 573.325 Q176.6 570.663 174.702 569.251 Q172.827 567.816 169.309 567.816 Q167.387 567.816 165.188 568.233 Q162.989 568.649 160.35 569.529 L160.35 565.362 Q163.013 564.621 165.327 564.251 Q167.665 563.881 169.725 563.881 Q175.049 563.881 178.151 566.311 Q181.253 568.719 181.253 572.839 Q181.253 575.709 179.61 577.7 Q177.966 579.668 174.934 580.432 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M194.957 595.131 L211.276 595.131 L211.276 599.066 L189.332 599.066 L189.332 595.131 Q191.994 592.376 196.577 587.746 Q201.184 583.094 202.364 581.751 Q204.61 579.228 205.489 577.492 Q206.392 575.733 206.392 574.043 Q206.392 571.288 204.447 569.552 Q202.526 567.816 199.424 567.816 Q197.225 567.816 194.772 568.58 Q192.341 569.344 189.563 570.895 L189.563 566.172 Q192.387 565.038 194.841 564.459 Q197.295 563.881 199.332 563.881 Q204.702 563.881 207.897 566.566 Q211.091 569.251 211.091 573.742 Q211.091 575.871 210.281 577.793 Q209.494 579.691 207.387 582.283 Q206.809 582.955 203.707 586.172 Q200.605 589.367 194.957 595.131 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M123.453 412.387 Q119.841 412.387 118.013 415.952 Q116.207 419.493 116.207 426.623 Q116.207 433.73 118.013 437.294 Q119.841 440.836 123.453 440.836 Q127.087 440.836 128.892 437.294 Q130.721 433.73 130.721 426.623 Q130.721 419.493 128.892 415.952 Q127.087 412.387 123.453 412.387 M123.453 408.683 Q129.263 408.683 132.318 413.29 Q135.397 417.873 135.397 426.623 Q135.397 435.35 132.318 439.956 Q129.263 444.54 123.453 444.54 Q117.642 444.54 114.564 439.956 Q111.508 435.35 111.508 426.623 Q111.508 417.873 114.564 413.29 Q117.642 408.683 123.453 408.683 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M143.614 437.989 L148.499 437.989 L148.499 443.868 L143.614 443.868 L143.614 437.989 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M172.85 425.234 Q176.207 425.952 178.082 428.22 Q179.98 430.489 179.98 433.822 Q179.98 438.938 176.462 441.739 Q172.943 444.54 166.462 444.54 Q164.286 444.54 161.971 444.1 Q159.679 443.683 157.226 442.827 L157.226 438.313 Q159.17 439.447 161.485 440.026 Q163.8 440.604 166.323 440.604 Q170.721 440.604 173.012 438.868 Q175.327 437.132 175.327 433.822 Q175.327 430.767 173.174 429.054 Q171.045 427.318 167.225 427.318 L163.198 427.318 L163.198 423.475 L167.411 423.475 Q170.86 423.475 172.688 422.109 Q174.517 420.72 174.517 418.128 Q174.517 415.466 172.619 414.054 Q170.744 412.619 167.225 412.619 Q165.304 412.619 163.105 413.035 Q160.906 413.452 158.267 414.331 L158.267 410.165 Q160.929 409.424 163.244 409.054 Q165.582 408.683 167.642 408.683 Q172.966 408.683 176.068 411.114 Q179.17 413.521 179.17 417.642 Q179.17 420.512 177.526 422.503 Q175.883 424.47 172.85 425.234 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M201.693 413.382 L189.887 431.831 L201.693 431.831 L201.693 413.382 M200.466 409.308 L206.346 409.308 L206.346 431.831 L211.276 431.831 L211.276 435.72 L206.346 435.72 L206.346 443.868 L201.693 443.868 L201.693 435.72 L186.091 435.72 L186.091 431.206 L200.466 409.308 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M123.777 257.19 Q120.166 257.19 118.337 260.754 Q116.531 264.296 116.531 271.426 Q116.531 278.532 118.337 282.097 Q120.166 285.639 123.777 285.639 Q127.411 285.639 129.216 282.097 Q131.045 278.532 131.045 271.426 Q131.045 264.296 129.216 260.754 Q127.411 257.19 123.777 257.19 M123.777 253.486 Q129.587 253.486 132.642 258.092 Q135.721 262.676 135.721 271.426 Q135.721 280.153 132.642 284.759 Q129.587 289.342 123.777 289.342 Q117.966 289.342 114.888 284.759 Q111.832 280.153 111.832 271.426 Q111.832 262.676 114.888 258.092 Q117.966 253.486 123.777 253.486 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M143.939 282.791 L148.823 282.791 L148.823 288.671 L143.939 288.671 L143.939 282.791 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M173.174 270.037 Q176.531 270.754 178.406 273.023 Q180.304 275.291 180.304 278.625 Q180.304 283.74 176.786 286.541 Q173.267 289.342 166.786 289.342 Q164.61 289.342 162.295 288.902 Q160.003 288.486 157.55 287.629 L157.55 283.115 Q159.494 284.25 161.809 284.828 Q164.124 285.407 166.647 285.407 Q171.045 285.407 173.337 283.671 Q175.651 281.935 175.651 278.625 Q175.651 275.569 173.499 273.856 Q171.369 272.12 167.55 272.12 L163.522 272.12 L163.522 268.278 L167.735 268.278 Q171.184 268.278 173.012 266.912 Q174.841 265.523 174.841 262.93 Q174.841 260.268 172.943 258.856 Q171.068 257.421 167.55 257.421 Q165.628 257.421 163.429 257.838 Q161.23 258.255 158.591 259.134 L158.591 254.967 Q161.253 254.227 163.568 253.856 Q165.906 253.486 167.966 253.486 Q173.29 253.486 176.392 255.917 Q179.494 258.324 179.494 262.444 Q179.494 265.315 177.85 267.305 Q176.207 269.273 173.174 270.037 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M199.748 269.528 Q196.6 269.528 194.748 271.68 Q192.92 273.833 192.92 277.583 Q192.92 281.31 194.748 283.486 Q196.6 285.639 199.748 285.639 Q202.897 285.639 204.725 283.486 Q206.577 281.31 206.577 277.583 Q206.577 273.833 204.725 271.68 Q202.897 269.528 199.748 269.528 M209.031 254.875 L209.031 259.134 Q207.272 258.301 205.466 257.861 Q203.684 257.421 201.924 257.421 Q197.295 257.421 194.841 260.546 Q192.411 263.671 192.063 269.991 Q193.429 267.977 195.489 266.912 Q197.549 265.824 200.026 265.824 Q205.235 265.824 208.244 268.995 Q211.276 272.143 211.276 277.583 Q211.276 282.907 208.128 286.125 Q204.98 289.342 199.748 289.342 Q193.753 289.342 190.582 284.759 Q187.411 280.153 187.411 271.426 Q187.411 263.231 191.299 258.37 Q195.188 253.486 201.739 253.486 Q203.498 253.486 205.281 253.833 Q207.086 254.18 209.031 254.875 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M23.3924 835.172 L30.1719 835.172 Q27.1482 838.418 25.6523 842.111 Q24.1563 845.771 24.1563 849.909 Q24.1563 858.057 29.1534 862.385 Q34.1187 866.714 43.5399 866.714 Q52.9293 866.714 57.9264 862.385 Q62.8916 858.057 62.8916 849.909 Q62.8916 845.771 61.3957 842.111 Q59.8998 838.418 56.8761 835.172 L63.5919 835.172 Q65.8835 838.546 67.0294 842.333 Q68.1752 846.089 68.1752 850.291 Q68.1752 861.08 61.5867 867.287 Q54.9663 873.494 43.5399 873.494 Q32.0816 873.494 25.4931 867.287 Q18.8728 861.08 18.8728 850.291 Q18.8728 846.025 20.0186 842.27 Q21.1326 838.482 23.3924 835.172 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M37.0787 804.839 Q36.5058 805.826 36.2512 807.004 Q35.9647 808.15 35.9647 809.55 Q35.9647 814.515 39.2112 817.189 Q42.4259 819.831 48.4733 819.831 L67.2522 819.831 L67.2522 825.719 L31.6042 825.719 L31.6042 819.831 L37.1424 819.831 Q33.8959 817.985 32.3363 815.024 Q30.7448 812.064 30.7448 807.831 Q30.7448 807.227 30.8403 806.494 Q30.904 805.762 31.0631 804.871 L37.0787 804.839 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M35.7101 786.315 Q35.7101 791.026 39.4022 793.763 Q43.0625 796.5 49.46 796.5 Q55.8575 796.5 59.5497 793.795 Q63.2099 791.058 63.2099 786.315 Q63.2099 781.636 59.5178 778.899 Q55.8257 776.162 49.46 776.162 Q43.1261 776.162 39.434 778.899 Q35.7101 781.636 35.7101 786.315 M30.7448 786.315 Q30.7448 778.676 35.7101 774.316 Q40.6753 769.955 49.46 769.955 Q58.2129 769.955 63.2099 774.316 Q68.1752 778.676 68.1752 786.315 Q68.1752 793.986 63.2099 798.346 Q58.2129 802.675 49.46 802.675 Q40.6753 802.675 35.7101 798.346 Q30.7448 793.986 30.7448 786.315 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M32.6545 737.522 L38.1927 737.522 Q36.9196 740.005 36.283 742.678 Q35.6464 745.352 35.6464 748.216 Q35.6464 752.577 36.9832 754.773 Q38.32 756.937 40.9936 756.937 Q43.0306 756.937 44.2083 755.378 Q45.3541 753.818 46.4045 749.108 L46.8501 747.102 Q48.1869 740.864 50.6377 738.254 Q53.0566 735.612 57.4171 735.612 Q62.3824 735.612 65.2788 739.559 Q68.1752 743.474 68.1752 750.349 Q68.1752 753.213 67.6023 756.333 Q67.0612 759.42 65.9472 762.858 L59.8998 762.858 Q61.5867 759.611 62.446 756.46 Q63.2736 753.309 63.2736 750.222 Q63.2736 746.084 61.8731 743.856 Q60.4409 741.628 57.8627 741.628 Q55.4756 741.628 54.2025 743.251 Q52.9293 744.843 51.7517 750.285 L51.2742 752.322 Q50.1284 757.765 47.7731 760.184 Q45.386 762.603 41.2482 762.603 Q36.2193 762.603 33.4821 759.038 Q30.7448 755.473 30.7448 748.917 Q30.7448 745.67 31.2223 742.806 Q31.6997 739.941 32.6545 737.522 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M32.6545 703.561 L38.1927 703.561 Q36.9196 706.044 36.283 708.717 Q35.6464 711.391 35.6464 714.255 Q35.6464 718.616 36.9832 720.812 Q38.32 722.976 40.9936 722.976 Q43.0306 722.976 44.2083 721.417 Q45.3541 719.857 46.4045 715.147 L46.8501 713.141 Q48.1869 706.903 50.6377 704.293 Q53.0566 701.651 57.4171 701.651 Q62.3824 701.651 65.2788 705.598 Q68.1752 709.513 68.1752 716.388 Q68.1752 719.252 67.6023 722.372 Q67.0612 725.459 65.9472 728.896 L59.8998 728.896 Q61.5867 725.65 62.446 722.499 Q63.2736 719.348 63.2736 716.261 Q63.2736 712.123 61.8731 709.895 Q60.4409 707.667 57.8627 707.667 Q55.4756 707.667 54.2025 709.29 Q52.9293 710.882 51.7517 716.324 L51.2742 718.361 Q50.1284 723.804 47.7731 726.223 Q45.386 728.642 41.2482 728.642 Q36.2193 728.642 33.4821 725.077 Q30.7448 721.512 30.7448 714.956 Q30.7448 711.709 31.2223 708.845 Q31.6997 705.98 32.6545 703.561 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M46.7864 695.286 L46.7864 678.13 L52.0063 678.13 L52.0063 695.286 L46.7864 695.286 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M47.9641 638.312 L50.8286 638.312 L50.8286 665.239 Q56.8761 664.857 60.0589 661.611 Q63.2099 658.333 63.2099 652.508 Q63.2099 649.134 62.3824 645.983 Q61.5549 642.8 59.8998 639.681 L65.4379 639.681 Q66.7747 642.832 67.475 646.142 Q68.1752 649.452 68.1752 652.858 Q68.1752 661.388 63.2099 666.385 Q58.2447 671.35 49.7783 671.35 Q41.0254 671.35 35.9011 666.64 Q30.7448 661.897 30.7448 653.877 Q30.7448 646.683 35.3918 642.514 Q40.0069 638.312 47.9641 638.312 M46.2453 644.169 Q41.4392 644.233 38.5746 646.874 Q35.7101 649.484 35.7101 653.813 Q35.7101 658.715 38.4792 661.675 Q41.2482 664.603 46.2772 665.048 L46.2453 644.169 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M45.7361 599.068 L67.2522 599.068 L67.2522 604.924 L45.927 604.924 Q40.8663 604.924 38.3518 606.898 Q35.8374 608.871 35.8374 612.818 Q35.8374 617.56 38.8611 620.298 Q41.8848 623.035 47.1047 623.035 L67.2522 623.035 L67.2522 628.923 L31.6042 628.923 L31.6042 623.035 L37.1424 623.035 Q33.9277 620.934 32.3363 618.101 Q30.7448 615.237 30.7448 611.513 Q30.7448 605.37 34.5643 602.219 Q38.3518 599.068 45.7361 599.068 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M21.4827 581.594 L31.6042 581.594 L31.6042 569.531 L36.1557 569.531 L36.1557 581.594 L55.5074 581.594 Q59.8679 581.594 61.1093 580.416 Q62.3506 579.207 62.3506 575.547 L62.3506 569.531 L67.2522 569.531 L67.2522 575.547 Q67.2522 582.326 64.7377 584.904 Q62.1914 587.482 55.5074 587.482 L36.1557 587.482 L36.1557 591.779 L31.6042 591.779 L31.6042 587.482 L21.4827 587.482 L21.4827 581.594 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M37.0787 541.172 Q36.5058 542.158 36.2512 543.336 Q35.9647 544.482 35.9647 545.882 Q35.9647 550.848 39.2112 553.521 Q42.4259 556.163 48.4733 556.163 L67.2522 556.163 L67.2522 562.051 L31.6042 562.051 L31.6042 556.163 L37.1424 556.163 Q33.8959 554.317 32.3363 551.357 Q30.7448 548.397 30.7448 544.164 Q30.7448 543.559 30.8403 542.827 Q30.904 542.095 31.0631 541.204 L37.0787 541.172 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M35.7101 522.648 Q35.7101 527.358 39.4022 530.095 Q43.0625 532.833 49.46 532.833 Q55.8575 532.833 59.5497 530.127 Q63.2099 527.39 63.2099 522.648 Q63.2099 517.969 59.5178 515.232 Q55.8257 512.494 49.46 512.494 Q43.1261 512.494 39.434 515.232 Q35.7101 517.969 35.7101 522.648 M30.7448 522.648 Q30.7448 515.009 35.7101 510.648 Q40.6753 506.288 49.46 506.288 Q58.2129 506.288 63.2099 510.648 Q68.1752 515.009 68.1752 522.648 Q68.1752 530.318 63.2099 534.679 Q58.2129 539.007 49.46 539.007 Q40.6753 539.007 35.7101 534.679 Q30.7448 530.318 30.7448 522.648 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M61.905 490.915 L80.8111 490.915 L80.8111 496.803 L31.6042 496.803 L31.6042 490.915 L37.0151 490.915 Q33.8322 489.068 32.3044 486.268 Q30.7448 483.435 30.7448 479.52 Q30.7448 473.027 35.9011 468.985 Q41.0573 464.911 49.46 464.911 Q57.8627 464.911 63.019 468.985 Q68.1752 473.027 68.1752 479.52 Q68.1752 483.435 66.6474 486.268 Q65.0878 489.068 61.905 490.915 M49.46 470.99 Q42.9988 470.99 39.3385 473.663 Q35.6464 476.305 35.6464 480.952 Q35.6464 485.599 39.3385 488.273 Q42.9988 490.915 49.46 490.915 Q55.9212 490.915 59.6133 488.273 Q63.2736 485.599 63.2736 480.952 Q63.2736 476.305 59.6133 473.663 Q55.9212 470.99 49.46 470.99 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M70.5623 440.371 Q76.928 442.853 78.8696 445.209 Q80.8111 447.564 80.8111 451.511 L80.8111 456.19 L75.9095 456.19 L75.9095 452.752 Q75.9095 450.333 74.7637 448.996 Q73.6179 447.66 69.3528 446.036 L66.6792 444.986 L31.6042 459.404 L31.6042 453.198 L59.486 442.058 L31.6042 430.918 L31.6042 424.711 L70.5623 440.371 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M17.727 395.906 L17.727 390.05 L67.2522 390.05 L67.2522 395.906 L17.727 395.906 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M35.7101 363.982 Q35.7101 368.693 39.4022 371.43 Q43.0625 374.167 49.46 374.167 Q55.8575 374.167 59.5497 371.462 Q63.2099 368.725 63.2099 363.982 Q63.2099 359.304 59.5178 356.566 Q55.8257 353.829 49.46 353.829 Q43.1261 353.829 39.434 356.566 Q35.7101 359.304 35.7101 363.982 M30.7448 363.982 Q30.7448 356.344 35.7101 351.983 Q40.6753 347.622 49.46 347.622 Q58.2129 347.622 63.2099 351.983 Q68.1752 356.344 68.1752 363.982 Q68.1752 371.653 63.2099 376.014 Q58.2129 380.342 49.46 380.342 Q40.6753 380.342 35.7101 376.014 Q30.7448 371.653 30.7448 363.982 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M32.6545 315.189 L38.1927 315.189 Q36.9196 317.672 36.283 320.345 Q35.6464 323.019 35.6464 325.884 Q35.6464 330.244 36.9832 332.44 Q38.32 334.605 40.9936 334.605 Q43.0306 334.605 44.2083 333.045 Q45.3541 331.485 46.4045 326.775 L46.8501 324.77 Q48.1869 318.531 50.6377 315.921 Q53.0566 313.28 57.4171 313.28 Q62.3824 313.28 65.2788 317.226 Q68.1752 321.141 68.1752 328.016 Q68.1752 330.881 67.6023 334 Q67.0612 337.087 65.9472 340.525 L59.8998 340.525 Q61.5867 337.278 62.446 334.127 Q63.2736 330.976 63.2736 327.889 Q63.2736 323.751 61.8731 321.523 Q60.4409 319.295 57.8627 319.295 Q55.4756 319.295 54.2025 320.918 Q52.9293 322.51 51.7517 327.952 L51.2742 329.989 Q50.1284 335.432 47.7731 337.851 Q45.386 340.27 41.2482 340.27 Q36.2193 340.27 33.4821 336.705 Q30.7448 333.141 30.7448 326.584 Q30.7448 323.337 31.2223 320.473 Q31.6997 317.608 32.6545 315.189 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M32.6545 281.228 L38.1927 281.228 Q36.9196 283.711 36.283 286.384 Q35.6464 289.058 35.6464 291.923 Q35.6464 296.283 36.9832 298.479 Q38.32 300.644 40.9936 300.644 Q43.0306 300.644 44.2083 299.084 Q45.3541 297.524 46.4045 292.814 L46.8501 290.809 Q48.1869 284.57 50.6377 281.96 Q53.0566 279.318 57.4171 279.318 Q62.3824 279.318 65.2788 283.265 Q68.1752 287.18 68.1752 294.055 Q68.1752 296.92 67.6023 300.039 Q67.0612 303.126 65.9472 306.564 L59.8998 306.564 Q61.5867 303.317 62.446 300.166 Q63.2736 297.015 63.2736 293.928 Q63.2736 289.79 61.8731 287.562 Q60.4409 285.334 57.8627 285.334 Q55.4756 285.334 54.2025 286.957 Q52.9293 288.549 51.7517 293.991 L51.2742 296.028 Q50.1284 301.471 47.7731 303.89 Q45.386 306.309 41.2482 306.309 Q36.2193 306.309 33.4821 302.744 Q30.7448 299.179 30.7448 292.623 Q30.7448 289.376 31.2223 286.512 Q31.6997 283.647 32.6545 281.228 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M820.866 12.096 L859.106 12.096 L859.106 18.9825 L829.049 18.9825 L829.049 36.8875 L857.851 36.8875 L857.851 43.7741 L829.049 43.7741 L829.049 65.6895 L859.836 65.6895 L859.836 72.576 L820.866 72.576 L820.866 12.096 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M899.251 34.1734 Q897.995 33.4443 896.496 33.1202 Q895.038 32.7556 893.256 32.7556 Q886.936 32.7556 883.533 36.8875 Q880.171 40.9789 880.171 48.6757 L880.171 72.576 L872.677 72.576 L872.677 27.2059 L880.171 27.2059 L880.171 34.2544 Q882.521 30.1225 886.288 28.1376 Q890.055 26.1121 895.443 26.1121 Q896.213 26.1121 897.144 26.2337 Q898.076 26.3147 899.21 26.5172 L899.251 34.1734 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M931.901 34.1734 Q930.645 33.4443 929.147 33.1202 Q927.688 32.7556 925.906 32.7556 Q919.586 32.7556 916.184 36.8875 Q912.821 40.9789 912.821 48.6757 L912.821 72.576 L905.327 72.576 L905.327 27.2059 L912.821 27.2059 L912.821 34.2544 Q915.171 30.1225 918.938 28.1376 Q922.706 26.1121 928.093 26.1121 Q928.863 26.1121 929.795 26.2337 Q930.726 26.3147 931.861 26.5172 L931.901 34.1734 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M955.477 32.4315 Q949.482 32.4315 945.998 37.1306 Q942.515 41.7891 942.515 49.9314 Q942.515 58.0738 945.958 62.7728 Q949.442 67.4314 955.477 67.4314 Q961.432 67.4314 964.916 62.7323 Q968.4 58.0333 968.4 49.9314 Q968.4 41.8701 964.916 37.1711 Q961.432 32.4315 955.477 32.4315 M955.477 26.1121 Q965.2 26.1121 970.749 32.4315 Q976.299 38.7509 976.299 49.9314 Q976.299 61.0714 970.749 67.4314 Q965.2 73.7508 955.477 73.7508 Q945.715 73.7508 940.165 67.4314 Q934.656 61.0714 934.656 49.9314 Q934.656 38.7509 940.165 32.4315 Q945.715 26.1121 955.477 26.1121 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M1014.94 34.1734 Q1013.69 33.4443 1012.19 33.1202 Q1010.73 32.7556 1008.95 32.7556 Q1002.63 32.7556 999.227 36.8875 Q995.865 40.9789 995.865 48.6757 L995.865 72.576 L988.371 72.576 L988.371 27.2059 L995.865 27.2059 L995.865 34.2544 Q998.214 30.1225 1001.98 28.1376 Q1005.75 26.1121 1011.14 26.1121 Q1011.91 26.1121 1012.84 26.2337 Q1013.77 26.3147 1014.9 26.5172 L1014.94 34.1734 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M1072.1 9.54393 L1072.1 15.7418 L1064.97 15.7418 Q1060.96 15.7418 1059.38 17.3622 Q1057.84 18.9825 1057.84 23.1955 L1057.84 27.2059 L1070.12 27.2059 L1070.12 32.9987 L1057.84 32.9987 L1057.84 72.576 L1050.35 72.576 L1050.35 32.9987 L1043.22 32.9987 L1043.22 27.2059 L1050.35 27.2059 L1050.35 24.0462 Q1050.35 16.471 1053.87 13.0277 Q1057.4 9.54393 1065.05 9.54393 L1072.1 9.54393 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M1077.57 54.671 L1077.57 27.2059 L1085.03 27.2059 L1085.03 54.3874 Q1085.03 60.8284 1087.54 64.0691 Q1090.05 67.2693 1095.07 67.2693 Q1101.11 67.2693 1104.59 63.421 Q1108.12 59.5726 1108.12 52.9291 L1108.12 27.2059 L1115.57 27.2059 L1115.57 72.576 L1108.12 72.576 L1108.12 65.6084 Q1105.4 69.7404 1101.8 71.7658 Q1098.23 73.7508 1093.49 73.7508 Q1085.67 73.7508 1081.62 68.8897 Q1077.57 64.0286 1077.57 54.671 M1096.33 26.1121 L1096.33 26.1121 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M1168.64 45.1919 L1168.64 72.576 L1161.18 72.576 L1161.18 45.4349 Q1161.18 38.994 1158.67 35.7938 Q1156.16 32.5936 1151.14 32.5936 Q1145.1 32.5936 1141.62 36.4419 Q1138.13 40.2903 1138.13 46.9338 L1138.13 72.576 L1130.64 72.576 L1130.64 27.2059 L1138.13 27.2059 L1138.13 34.2544 Q1140.81 30.163 1144.41 28.1376 Q1148.06 26.1121 1152.8 26.1121 Q1160.62 26.1121 1164.63 30.9732 Q1168.64 35.7938 1168.64 45.1919 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M1216.15 28.9478 L1216.15 35.9153 Q1212.99 34.1734 1209.79 33.3227 Q1206.63 32.4315 1203.39 32.4315 Q1196.14 32.4315 1192.13 37.0496 Q1188.12 41.6271 1188.12 49.9314 Q1188.12 58.2358 1192.13 62.8538 Q1196.14 67.4314 1203.39 67.4314 Q1206.63 67.4314 1209.79 66.5807 Q1212.99 65.6895 1216.15 63.9476 L1216.15 70.8341 Q1213.03 72.2924 1209.67 73.0216 Q1206.35 73.7508 1202.58 73.7508 Q1192.33 73.7508 1186.3 67.3098 Q1180.26 60.8689 1180.26 49.9314 Q1180.26 38.832 1186.34 32.472 Q1192.46 26.1121 1203.07 26.1121 Q1206.51 26.1121 1209.79 26.8413 Q1213.07 27.5299 1216.15 28.9478 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M1236.49 14.324 L1236.49 27.2059 L1251.84 27.2059 L1251.84 32.9987 L1236.49 32.9987 L1236.49 57.6282 Q1236.49 63.1779 1237.99 64.7578 Q1239.53 66.3376 1244.19 66.3376 L1251.84 66.3376 L1251.84 72.576 L1244.19 72.576 Q1235.56 72.576 1232.28 69.3758 Q1228.99 66.1351 1228.99 57.6282 L1228.99 32.9987 L1223.53 32.9987 L1223.53 27.2059 L1228.99 27.2059 L1228.99 14.324 L1236.49 14.324 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M1261.64 27.2059 L1269.1 27.2059 L1269.1 72.576 L1261.64 72.576 L1261.64 27.2059 M1261.64 9.54393 L1269.1 9.54393 L1269.1 18.9825 L1261.64 18.9825 L1261.64 9.54393 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M1302.28 32.4315 Q1296.28 32.4315 1292.8 37.1306 Q1289.31 41.7891 1289.31 49.9314 Q1289.31 58.0738 1292.76 62.7728 Q1296.24 67.4314 1302.28 67.4314 Q1308.23 67.4314 1311.71 62.7323 Q1315.2 58.0333 1315.2 49.9314 Q1315.2 41.8701 1311.71 37.1711 Q1308.23 32.4315 1302.28 32.4315 M1302.28 26.1121 Q1312 26.1121 1317.55 32.4315 Q1323.1 38.7509 1323.1 49.9314 Q1323.1 61.0714 1317.55 67.4314 Q1312 73.7508 1302.28 73.7508 Q1292.51 73.7508 1286.96 67.4314 Q1281.45 61.0714 1281.45 49.9314 Q1281.45 38.7509 1286.96 32.4315 Q1292.51 26.1121 1302.28 26.1121 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip170)\" d=\"M1373.17 45.1919 L1373.17 72.576 L1365.71 72.576 L1365.71 45.4349 Q1365.71 38.994 1363.2 35.7938 Q1360.69 32.5936 1355.67 32.5936 Q1349.63 32.5936 1346.15 36.4419 Q1342.66 40.2903 1342.66 46.9338 L1342.66 72.576 L1335.17 72.576 L1335.17 27.2059 L1342.66 27.2059 L1342.66 34.2544 Q1345.34 30.163 1348.94 28.1376 Q1352.59 26.1121 1357.33 26.1121 Q1365.15 26.1121 1369.16 30.9732 Q1373.17 35.7938 1373.17 45.1919 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip172)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:8; stroke-opacity:1; fill:none\" points=\"\n",
       "  289.714,1009.41 289.73,1009.41 289.747,1009.41 289.766,1009.41 289.787,1009.4 289.81,1009.4 289.835,1009.4 289.862,1009.4 289.893,1009.4 289.926,1009.4 \n",
       "  289.962,1009.4 290.002,1009.39 290.046,1009.39 290.094,1009.39 290.147,1009.38 290.205,1009.38 290.268,1009.38 290.338,1009.37 290.415,1009.37 290.499,1009.36 \n",
       "  290.591,1009.35 290.692,1009.35 290.803,1009.34 290.925,1009.33 291.059,1009.31 291.206,1009.3 291.367,1009.28 291.544,1009.27 291.738,1009.24 291.951,1009.22 \n",
       "  292.184,1009.19 292.441,1009.16 292.723,1009.12 293.032,1009.07 293.371,1009.02 293.743,1008.95 294.152,1008.88 294.6,1008.79 295.092,1008.69 295.632,1008.57 \n",
       "  296.225,1008.43 296.876,1008.27 297.589,1008.08 298.373,1007.85 299.233,1007.59 300.177,1007.28 301.213,1006.92 302.35,1006.5 303.597,1006.02 304.966,1005.45 \n",
       "  306.469,1004.79 308.119,1004.03 309.929,1003.14 311.915,1002.12 314.096,1000.94 316.489,999.585 319.115,998.029 321.997,996.248 325.16,994.214 328.632,991.898 \n",
       "  332.442,989.268 336.624,986.289 341.213,982.927 346.25,979.141 351.778,974.893 357.845,970.138 364.504,964.833 371.811,958.933 379.831,952.389 388.633,945.152 \n",
       "  398.293,937.174 408.896,928.402 420.531,918.785 433.302,908.27 447.317,896.804 462.699,884.333 479.58,870.803 498.108,856.159 518.442,840.348 540.758,823.312 \n",
       "  565.25,804.999 592.13,785.352 621.631,764.317 654.008,741.838 689.542,717.86 728.541,692.329 771.342,665.19 818.316,636.39 869.869,605.875 926.449,573.593 \n",
       "  988.546,539.493 1056.7,503.525 1131.49,465.641 1213.58,425.797 1303.67,383.948 1402.55,340.056 1511.06,294.084 1630.16,246.002 1760.87,195.782 1904.32,143.404 \n",
       "  \n",
       "  \"/>\n",
       "</svg>\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(lambdas, losses, title=\"Error function\", size=(500,300), linewidth=2, legend=false)\n",
    "xlabel!(\"Lambda\")\n",
    "ylabel!(\"Cross-entropy loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fddc3a8",
   "metadata": {},
   "source": [
    "As seen on the chart above, the best tuning parameter is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71e7a40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.999999999999999e-6"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lambda = lambdas[argmin(losses)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9771b6c9",
   "metadata": {},
   "source": [
    "### Retrain with best tuning parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c71f7c",
   "metadata": {},
   "source": [
    "(in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ad33182",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Updating Machine{LogisticClassifier,…}.\n",
      "└ @ MLJBase /home/ciro/.julia/packages/MLJBase/CglMw/src/machines.jl:465\n"
     ]
    }
   ],
   "source": [
    "model.lambda = best_lambda\n",
    "fit!(mach,\n",
    "    verbosity=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9747c65d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              ┌───────────────────────────┐\n",
       "              │       Ground Truth        │\n",
       "┌─────────────┼─────────────┬─────────────┤\n",
       "│  Predicted  │      1      │      5      │\n",
       "├─────────────┼─────────────┼─────────────┤\n",
       "│      1      │    4399     │     474     │\n",
       "├─────────────┼─────────────┼─────────────┤\n",
       "│      5      │     320     │    3321     │\n",
       "└─────────────┴─────────────┴─────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.907\n",
      "f1-score: 0.893\n"
     ]
    }
   ],
   "source": [
    "ŷ = predict_mode(mach, trainXLog)\n",
    "printMetrics(ŷ, trainYLog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae20b9b9",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a597269f",
   "metadata": {},
   "source": [
    "(in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b033362f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mEvaluating over 10 folds: 100%[=========================] Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PerformanceEvaluation object with these fields:\n",
       "  measure, measurement, operation, per_fold,\n",
       "  per_observation, fitted_params_per_fold,\n",
       "  report_per_fold, train_test_pairs\n",
       "Extract:\n",
       "┌───────────────────────────────┬─────────────┬──────────────┬──────────────────\n",
       "│\u001b[22m measure                       \u001b[0m│\u001b[22m measurement \u001b[0m│\u001b[22m operation    \u001b[0m│\u001b[22m per_fold       \u001b[0m ⋯\n",
       "├───────────────────────────────┼─────────────┼──────────────┼──────────────────\n",
       "│ FScore(β = 1.0,rev = nothing) │ 0.458       │ predict_mode │ [0.0, 0.0, 0.0, ⋯\n",
       "└───────────────────────────────┴─────────────┴──────────────┴──────────────────\n",
       "\u001b[36m                                                                1 column omitted\u001b[0m\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLJ.evaluate!(mach,\n",
    "    resampling=CV(nfolds=10),\n",
    "    measures=[f1score])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1615552b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(classes = CategoricalArrays.CategoricalValue{Int64, UInt32}[1, 5],\n",
       " coefs = [:x1 => 0.9187358219113964, :x2 => -3.5959349255921778],\n",
       " intercept = -0.21911107443348532,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_params(mach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26f2485a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              ┌───────────────────────────┐\n",
       "              │       Ground Truth        │\n",
       "┌─────────────┼─────────────┬─────────────┤\n",
       "│  Predicted  │      1      │      5      │\n",
       "├─────────────┼─────────────┼─────────────┤\n",
       "│      1      │    4460     │     539     │\n",
       "├─────────────┼─────────────┼─────────────┤\n",
       "│      5      │     259     │    3256     │\n",
       "└─────────────┴─────────────┴─────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.906\n",
      "f1-score: 0.891\n"
     ]
    }
   ],
   "source": [
    "ŷ = predict_mode(mach, trainXLog)\n",
    "printMetrics(ŷ, trainYLog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41338dc",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4bbf7616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "preprocess (generic function with 1 method)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this function summarizes the steps taken during the preprocessing of the training dataset\n",
    "# once preprocessing steps are defined, it is created as to ease usage on the test and validation sets\n",
    "\n",
    "function preprocess(X, y)\n",
    "    X = batchImage2Vector(X)\n",
    "    \n",
    "    preprocessX = vcat( X[y .== c[1] ], X[ y .== c[2] ] )\n",
    "    preprocessY = vcat( y[y .== c[1] ], y[ y .== c[2] ] )\n",
    "\n",
    "    preprocessX = generatePredictors(preprocessX)\n",
    "    \n",
    "    preprocessX = DataFrame(preprocessX, :auto)\n",
    "    preprocessY = coerce(preprocessY, OrderedFactor)\n",
    "\n",
    "    return (preprocessX, preprocessY)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d999abef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              ┌───────────────────────────┐\n",
       "              │       Ground Truth        │\n",
       "┌─────────────┼─────────────┬─────────────┤\n",
       "│  Predicted  │      1      │      5      │\n",
       "├─────────────┼─────────────┼─────────────┤\n",
       "│      1      │    1916     │     227     │\n",
       "├─────────────┼─────────────┼─────────────┤\n",
       "│      5      │     107     │    1399     │\n",
       "└─────────────┴─────────────┴─────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.908\n",
      "f1-score: 0.893\n"
     ]
    }
   ],
   "source": [
    "testXLog, testYLog = preprocess(testX, testY)\n",
    "\n",
    "ŷ = predict_mode(mach, testXLog)\n",
    "printMetrics(ŷ, testYLog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adec86d6",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed9e76ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              ┌───────────────────────────┐\n",
       "              │       Ground Truth        │\n",
       "┌─────────────┼─────────────┬─────────────┤\n",
       "│  Predicted  │      1      │      5      │\n",
       "├─────────────┼─────────────┼─────────────┤\n",
       "│      1      │    1071     │     111     │\n",
       "├─────────────┼─────────────┼─────────────┤\n",
       "│      5      │     64      │     781     │\n",
       "└─────────────┴─────────────┴─────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.914\n",
      "f1-score: 0.899\n"
     ]
    }
   ],
   "source": [
    "validationXLog, validationYLog = preprocess(validationX, validationY)\n",
    "\n",
    "ŷ = predict_mode(mach, validationXLog)\n",
    "printMetrics(ŷ, validationYLog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bbcc29",
   "metadata": {},
   "source": [
    "## Demonstration of the prediction\n",
    "\n",
    "By pressing ENTER at the below cell several times, a randomly chosen slice of the actual outcome is compared to a correspondent slice of the predicted outcome. Due to the accuracy < 1 for the model, a few of them will not match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51c1c938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tbody><tr><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAf9JREFUaAW9wb+L1gUAB+An+TgpQgnaYjiYRIYHLYHY4OAQBUIkQhhlLUEOgv9AgzQ03KBI6CBEcC3ScEQYTcElHjYockNgukhg0CCSCP7A4TuIyNv7vXvj8zxRFmVRFmVRFmVRFmVRFmVRFmVRFmVRFmVRFmVRFmUxo/XYjHexA6/jTWzAF/jes6IsyqIs1uBlfIS3sR1vGFzHZXyFBdzxvCiLsiiLVZjDZziAbQbLmMcSLuC+/xZlURZlsQrHcRh3cRIL+B2PjRdlURZlMcIr+AZz+AA/419rE2VRFmUxwud4B9/hB7OJsiiLsphiBz41+NrsoizKoiym+BBbDE7iocFVXMeP+Mt4URZlURZT7PLUPk/tN7iNPbhpnCiLsiiLKX7CLSzhosFreBVHsRsL2ItHpouyKIuymOJbz7uNX7GIW3gL5/Cx6aIsyqIsZvA3TuBL7DROlEVZlMWM/jR4yThRFmVRFjNYh0MGl4wTZVEWZTGD/XjP4IZxoizKoixmcN5gEfPGibIoi7KYYA/u4YpnvYA5nMVG/IZPcNc4URZlURYTzGMTjmDZYCtO432DX3AQd4wXZVEWZTHBIk5gCSsG2/AiruEsTlu9KIuyKIsJzmALjmI3VnAK5/EHHlibKIuyKIsJ/sExHPP/irIoi7Ioi7Ioi7Ioi7Ioi7InNC1ILnZj/tgAAAAASUVORK5C\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAgpJREFUaAW9wT2oFWQABuDn3l6yGmoJxNlaomzNpa2MQAz6gYigFCVobosgEANLEboqgmDQ0BJkiHcIgyBqSHFxMrEcXLqD+JNKWNhwh4bTOeeTK+/zRFmURVmURVmURVmURVmURVmURVmURVmURVmURVmUxRSLeBsf4gncNd1G/G5MlEVZlMUUj2Mf/sJOXMJmrLfqKn7AV3gRR4yJsiiLsphiBSexDT/iPE6Z9Bx+My7KoizKYob3sAG/4EmsmHTRvYmyKIuymOE23sdZvIElaxdlURZlMccF/IxPsGTtoizKoiwGfI0X8DKWsYgteA3f4w4u4bT5oizKoiwGfIslPIRncQibcQuvYAGP4FN8jL9NF2VRFmUxYAUX8DkexiL24wAu4wHswkHcwF7TRVmURVkM+gnbcRCf4bL//IOj2Im3sNd0URZlURaDPsA+/Or/3cFxvGq2KIuyKItB13HdbH+aL8qiLMriPlpvviiLsiiL++RRvIvDZouyKIuyGLSAd3DMpAVsxTqcMFuURVmUxaBd2INjJj2NL/ERzpgtyqIsymLQ8zhv0lM4jnM4YL4oi7Ioi3vwIB7DNatewje4gk24ab4oi7Ioi0Gn8CYu4jurXscVPIObxkRZlEVZDPoCf2AHtuAMdmM/bhgXZVEWZTHoLpaxbG2iLMqiLMqiLMqiLMqiLMqi7F+u01NwEtlQfQAAAABJRU5ErkJg\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAd9JREFUaAW9wTGIlgUABuBHeB0OF4e00UFBcXWRmxOuxVk9EI8IhFvEQZFAKGgpcAk5F0kHFUEQxKUzUBpcRNTR7cThqIiuxoRs+AZx6P/v++94nyfKoizKoizKoizKoizKoizKoizKoizKoizKoizKoizKoizKoixGCpax1wc78B7z+BSHfOwdHmMBURZlURYjHcMVH9uB9wYbWDe4jt/xCr8YRFmURVnM6BJ+M5jHU4MnWPP/oizKoixG2I89eIk7eGtww+ZFWZRFWWzCHL7FIp7hiNlFWZRFWUxxGOexhD/xg62JsiiLsphgJ77HAjawiJ9sTZRFWZTFBOewgL9xAo9sXZRFWZTFBJcN/sGa7RFlURZlMcFp3MMneIVb+Bl3zS7KoizKYoL7+Byf4SzO4Ascw0X8Ybwoi7IoiylWsYoLOI5vsITnWDFelEVZlMUID/AOD3EOt/GXcaIsyqIsRnqJNziAU1gxTpRFWZTFSOvYwD4cNF6URVmUxUhHccDsoizKoiymmMMlXDaYxy6sYcV4URZlURZT7MaX+BFf4aTBCbw2XpRFWZTFJuzFc8xhHd/hhdlEWZRFWUzxK5ZxFW/xNW6aXZRFWZTFFP/iGq7ZHlEWZVEWZVEWZVH2H5gARV5x+vZWAAAAAElFTkSuQmCC\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAUZJREFUaAW9waGqlwcAxuHnwA8RYasuLRmNYwvalkRYXDWcW7KZvQGDLGjaDXgRCwcHZhHGWTjB+v++A+/zZCxjGctYxjKWsYxlLGMZy1jGMpaxjOWka7zCn7hxuYxlLGM56RbP8TveulzGMpax3NNrfMSNy2QsYxnLPf2IX/HOZTKWsYzlpJfOyVjGMpYTHuEJrhyXsYxlLCf8jKe4xX/45nIZy1jGck+f8JfLZSxjGcsJv/jug2MylrGM5YSHvnvvmIxlLGM54RmucIXPjslYxjKWE17iFv/gi2MylrGM5aDf8IM7f+Nfx2QsYxnLQT/hgTvXjstYxjKWe/jquIxlLGM56DGunJexjGUsB73ArfMylrGMZSxjGctYxjKWsYzloPf4w3kZy1jGctAbvHFexjKWsYxlLGMZy1jGMpaxjGUsYxn7H0juG0tpx7iYAAAAAElFTkSuQmCC\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAXJJREFUaAW9wSFrVmEABtCDPGxJ8F8sLQkKat1QlkVxzb9gMaltyLpWi1hcF4xiM4hYnDIQDFYFYYig4evuvfd+POdEWZRFWZRFWZRFWZRFWZRFWZRFWZRFWZRFWZRFWZTFGhziHj5jy/9FWZRFWazBMf7gmbNFWZRFWazBHr7gwNmiLMqiLBa6hes4MSbKoizKYqFH2MCxMVEWZVEWC1zDFt7jtjFRFmVRFgtsW/mEU2OiLMqiLBa4aOWFcVEWZVEWM+1gHyd4ZVyURVmUxUwPsYkD/DYuyqIsymKGm7iKt3hpmiiLsiiLGZ7gL57ih2miLMqiLCa6jPN4jeemi7Ioi7KYIHiADTw2T5RFWZTFBJdwA1/xzjxRFmVRFhPct3IHP80TZVEWZTHoCnbxER/MF2VRFmUx6C5OsYtf5ouyKIuyGHAB+/iG75aJsiiLshiwjU0cWS7KoizKYsAbnLMeURZlURZlURZlURZlURZlUfYPRcgnvfhqr14AAAAASUVORK5C\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAh9JREFUaAW9wbGL1QUAB/BP1xdtiTwouiEIl8gcHIrgiJKwqTEuaGh0ylr6ByJqSoIoxwg5hws0F4eglsJRqIaGBgcV4qCXQ0gSJO81vOHHA39378X5/XyiLMqiLMqiLMqiLMqiLMqiLMqiLMqiLMriAVrHYfyNO+aiLMqiLB6AE3gC57GBH3HKXJRFWZTFAdrEq/gIM/cXZVEWZXFATuMzPGJvURZlURb/w5t42txJPI8jOGQwwTa2cdMgyqIsymJFm/jaYA1Tg2/xIa65vyiLsiiLJb2Ot7CJmcEUt/AzLuMS/jEuyqIsymIJr+FTPIMZfsJtXMNV/Ipdy4myKIuy2McmvsRTBuvYwZ/43mqiLMqiLPZwHFdwxKKjOGvuE7yHS5YTZVEWZTHiYXyAdYM1TC3awDlcxy/2F2VRFmUx4jm8gZnB7ziP38x9jsfwOHbwCib2FmVRFmUx4phFN3EKNwxexBmribIoi7IYcRVn8TbOYRu7Fn2DM1YTZVEWZTFiF1/gHr7CxKLj2DG4gYn9RVmURVmMeBTf4RguYmLRy3gSa5jiruVEWZRFWYw4iWdxEes4gXu4g9N4BzNMcQvvWk6URVmUxYgtc1vYMvcvbmPD4C7ex67lRFmURVmM+Bgv4ajBIWxYdAE/WF6URVmUxYjreAGHDR7CzKI/rCbKoizKYg9/OXhRFmVRFmVRFmVRFmVRFmVRFmVRFmVR9h8+Y1VkypEbQQAAAABJRU5ErkJg\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAb5JREFUaAW9wb+LzgEAB+AnfbLpDKgrZVAyioU/wA2sN/gHdF2SU5RBlAXLUZJNYVDcbrvBJoOSjcEgPwqZ6JIfww2X5d73+975PE+URVmURVmURVmURVmURVmURVmURVmURVmURVmURVmURVmURVmURVmURVn8B7uw3b/e4TuiLMqiLCa0FcEMDmDGmj2YtuoXVnATFxFlURZlMcAU5nAIB7HXv37hCZ5hNx7hC5atibIoi7IYwxZcw0lMWfMJH/AAL/ASX60vyqIsymIMl3DOqh+4hYf4hI+GibIoi7IYYRtOWPUNC7hvclEWZVEWI5zDPqvO4r6NibIoi7IYYcWaZRsXZVEWZTHCXZzBTsziho2JsiiLshjhI5Ywj0UcwRW8Mpkoi7IoizGcRjCLWRzDPVzGZ8NEWZRFWYzhN+ZwFaewgHkcxiHDRFmURVkM8BbnsR/HscNwURZlURYDncBRk4uyKIuyGNM2LOACtuInrhouyqIsymIM87iIaazgMW7jqeGiLMqiLNZxB7OYwnNcxxLem1yURVmUxToWsYg/eGNzRFmURVms47XNF2VRFmVRFmVRFmVRFmVRFmV/AWCOPDa6f/LtAAAAAElFTkSuQmCC\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAWZJREFUaAW9wSFyU1EABdCTmatAtplBMcjWxncPKWtgBxgQOMCxgeJRnXQlxf7sgdSCDKIb+O915p4TZVEWZVEWZVEWZVEWZVEWZVEWZVEWZVEWA97jHt/wxZwoi7Ioi5W2+IEzPuMXFuOiLMqiLFb6g4+49+wGi3FRFmVRFgMOOONsXpRFWZTFoCdcmBdlURZlMeiAD+ZFWZRFWQw6YYMb3BkXZVEWZTHoAZ+wxxWOxkRZlEVZDPqLf3iNV8ZFWZRFWQxacMQOt/htTJRFWZTFoGtcYYNL46IsyqIsBi04YmdOlEVZlMWkDbbGRVmURVlMeMAOe1xjsV6URVmUxYTv+OrZDRbrRVmURVlMOmCPW9xZL8qiLMpi0gkbbI2JsiiLsniBMy5wiZN1oizKoixeYIN3eIuTdaIsyqIsJv3EHk84Wi/KoizKYtIj3hgXZVEWZVEWZVEWZVEWZVEWZVEWZVEWZf8B+k0o2l08IjsAAAAASUVORK5C\"></td></tr></tbody></table><div><small>(a vector displayed as a row to save space)</small></div>"
      ],
      "text/plain": [
       "8-element Vector{Base.ReinterpretArray{Gray{Float64}, 2, Float64, Matrix{Float64}, true}}:\n",
       " [Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); … ; Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0)]\n",
       " [Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); … ; Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0)]\n",
       " [Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); … ; Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0)]\n",
       " [Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); … ; Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0)]\n",
       " [Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); … ; Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0)]\n",
       " [Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); … ; Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0)]\n",
       " [Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); … ; Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0)]\n",
       " [Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); … ; Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 5, 5, 1, 1, 5, 5, 1]\n",
      "CategoricalArrays.CategoricalValue{Int64, UInt32}[5, 5, 5, 1, 1, 5, 5, 1]\n"
     ]
    }
   ],
   "source": [
    "# demonstration of prediction accuracy\n",
    "N = size(trainX)[1]\n",
    "v = rand(1:N, 8)                            # select a random sample of images\n",
    "\n",
    "trainXLog = generatePredictors(trainX[v])   # convert images to predictors\n",
    "p = MLJ.predict(mach, trainXLog)            # predict outcome from sample images\n",
    "ŷ = predict_mode(mach, trainXLog)           # convert probability to classes\n",
    "\n",
    "display([MNIST.convert2image(vector2Image( trainX[i], 28, 28) ) for i in v])\n",
    "println(trainY[v])\n",
    "println(ŷ)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.5",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
