{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b439f11d",
   "metadata": {},
   "source": [
    "## Logistic regression with MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f262ba3",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d63e87f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "using Flux              # the julia ml library\n",
    "using Images            # image processing and machine vision for julia\n",
    "using MLJ               # make_blobs, rmse, confmat, categorical\n",
    "using MLDataUtils       # label, nlabel, labelfreq\n",
    "using MLDatasets        # mnist\n",
    "\n",
    "using GLM               # (lm works as regression; GLM not OK for categorical outcomes)\n",
    "using MLJLinearModels   # LogisticClassifier\n",
    "\n",
    "using LinearAlgebra     # pinv pseudo-inverse matrix\n",
    "using Metrics           # r2-score\n",
    "using Random\n",
    "using StatsBase         # standardize (normalization)\n",
    "using Distributions\n",
    "\n",
    "using Plots; gr()\n",
    "using StatsPlots\n",
    "using Printf\n",
    "\n",
    "using CSV\n",
    "using DataFrames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53a09fe",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5001966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hSymmetry (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# functions for feature extraction\n",
    "meanIntensity(img) = mean(Float64.(img))\n",
    "\n",
    "function hSymmetry(img)\n",
    "    imgFloat = Float64.(img)\n",
    "    imgReverse = reverse(imgFloat, dims=1)\n",
    "    return -mean( abs.(imgFloat - imgReverse) )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53255360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rescaleByColumns (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lib functions\n",
    "image2Vector(M) = vec(Float64.(M))\n",
    "\n",
    "function batchImage2Vector(imagesArray3D)\n",
    "    h, v, N = size(imagesArray3D)\n",
    "    vectorOfImageVectors = [ image2Vector( imagesArray3D[:, :, i] ) for i in 1:N]\n",
    "end\n",
    "\n",
    "vector2Image(vec, h, v) = reshape(Float64.(vec), (h, v))\n",
    "\n",
    "function rescaleByColumns(X)\n",
    "    # using StatsBase\n",
    "    X = Float64.(X)\n",
    "    dt = StatsBase.fit(ZScoreTransform, X; dims=1, center=true, scale=true)\n",
    "    rescaledX = StatsBase.transform(dt, X)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8903cf71",
   "metadata": {},
   "source": [
    "### MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bd90da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tbody><tr><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAiVJREFUaAW9wT2IFgQABuAHemnI4aJFISgJwkDIIiqIsMLcajiKIEEIshosmgSHhhoUIW/IcIgCISHa+psKsp8hEKSSSAlyECon61Q+jMDT4RuO7w6/n5Pe54myKIuyKIuyKIuyKIuyKIuyKIuyKIuyKIuyKIuyKIsZ3YQ5y17FLdiE3TiI5/EvDuAto6IsyqIsJrgDN+MRPIpb8YzV/sAhzOMSTuI7q0VZlEVZjHE/vsac8ZbwBgb4CH/hH/xmtSiLsiiLMc7iPOasdhyLeAL/4ajpRFmURVmM8Tf24Cn8hEOGfsZ2DLAZr5telEVZlMUEn+IYLmELXsQCBoZ+xcumF2VRFmUxhYuGLhjahY+xZHZRFmVRFjN4Ew/gMTyJr8wuyqIsymIGA7yEH/E+vsEJHMZV04myKIuymNEZvIAj2ImdWIcPcc5kURZlURZr8Al+xwK2YT/uxD78abwoi7IoizX6Bc/haRzBK7gb240XZVEWZXEDFnEUHyDYisfxreuLsiiLslije/EsHkQMncL3xouyKIuymNEmvIZ5bLDsCs5hyXhRFmVRFlPagB3YjY1GncA+fG6yKIuyKIsJ1mMz3sU9Rh3H2/gMS6YTZVEWZXEdt+E93Ie7jPoBC/gSl80myqIsymKFh7EHD+F2oy7jHezHwNpEWZRFWawwj3nLTuMLXMFBLLoxURZlURYr7MVe/58oi7Ioi7Ioi7Ioi7Ioi7IouwZsVVgTmd3ynQAAAABJRU5ErkJg\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAjJJREFUaAW9wT1oHAQABtB3+mGISDN0sIK46SaGFEUnxbEVFTtIkWYVRCgoAYcomRzUDlYQBREUhTo4WCwihcKB0EGtOneTQkAtgu1ih5zDDRlyf0nley/KoizKoizKoizKoizKoizKoizKoizKoixuw1G8inV8jg9wxWxRFmVRFge0ios4hBFO4VkcNluURVmUxQE8hq+xghFu4BYO4wn8jFsmi7Ioi7LYh7uxhi9wn11X8Q7O4Qe8ibdNFmVRFmWxDx/jpL3WcA+GeAoPmy7KoizKYkFHcRwDY0N8i3exjV/wN57GwHRRFmVRFgtYxUUcwgjf4SSexCY+wZ/4DTs4jjVcsVeURVmUxRwPYQMr+Avb+Aw3cQEX7LWM1/GSvaIsyqIsZljCeziGG1jHT1g23wMmi7Ioi7KYYQ3HjD2HodsXZVEWZTHDGQwwxNBi7sAOBiaLsiiLspjiGaxihPMWt4MRfjVZlEVZlMUUy7gLf+Ar8y1hy9glvGGyKIuyKIs5/sW22ZawiQ1cwxncNFmURVmUxRznzbaKDbyIb3DCbFEWZVEWUwwwwPM4bbLXsIkVfIl180VZlEVZTDHCCEdwFp/iOh7HKTyC+/E7vseHFhNlURZlMcedeAUn8A8etOsyLuEti4uyKIuymOIyfsSjxo7gXmPXcQ6n7V+URVmUxRTX8AJexqZd7+MjXHUwURZlURYzbGMLW/4/URZlURZlURZlURZlURZlURZlURZlUfYfqPxYlL4fzGQAAAAASUVORK5C\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAbVJREFUaAW9wT2rDQAABuDnnN6UhSLdlNQdbrZrMjCgbkl2E9kY/ASrSfkBBukOjMJkMJkQRvJRihhsSpFSDGdw7nHP/Tid3ueJsiiLsiiLsiiLsiiLsiiLsiiLsiiLsiiLsiiLsiiLOVvBHZzAW/+LsiiLsphwHHtxz2yO4IXpoizKoiwmnMQS7tm+IRZxEAPri7Ioi7KYcAFPzGY/LuI23lhflEVZlMWEodndNPLedFEWZVEWY5axYHa7jTwyXZRFWZTFmDPYaTYLWDTyxXRRFmVRFmMOGXll+65jAe/w3XRRFmVRFut4bmt24TTO45SRq/hmuiiLsiiLdeyx1mEMsYID2IFzGOInnuEXgpc2FmVRFmUx5if+4Aau+GcZA/zGD7zGLbzAY3zFZ+zEGxuLsiiLshhzGR9xzFqf8ACv8dT/LmEfPthclEVZlMWEa7Zvxchdm4uyKIuymKP7NhdlURZlURZlURZlMScDLOGJjUVZlEVZzMkfDG0uyqIsymKOjmLVxqIsyqIs5mRga6IsyqIs5uAhztqaKIuyKIs5WMWqrYmyKIuyKIuyKIuyKIuyKIuyv/irMYSJ7ydGAAAAAElFTkSuQmCC\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAYtJREFUaAW9waFqVQEABuCP8YNRRUFM7glkDzDQoGIw+AYbdpugYcUgDEwiy4p9wSooCjLwDWYRDIJrCibD1XDCLc577rmX//uiLMqiLMqiLMqiLMqiLMqiLMqiLMqiLMqiLMqiLMpiTfbwGBu4jg/+LcqiLMpiDXbxCDODP04XZVEWZbEGV3DGOFEWZVEWK7qB+wbHuIMTp4uyKIuyWME2XuKswVN89X9RFmVRFivYwWWD93hlsSiLsiiLiS7iHmb4gSfGibIoi7KYYBOH5p7jnXGiLMqiLCa4jasGb/HMeFEWZVEWS7qLfYOP2MFP40VZlEVZLGETh+a+4MRyoizKoiyW8BAzc/uWF2VRFmUx0hZumXuNz5YXZVEWZTHSG5w3+IRd00RZlEVZjHQBM4MD/DJNlEVZlMUIL7Bh7sh0URZlURYLbOEmZviNA5yYLsqiLMpigXO4ZPAND6wmyqIsyqIsyqIsymKBYxxh23pEWZRFWSzwHdesT5RFWZRFWZRFWZRFWZRFWZT9BXYjLFSLepVZAAAAAElFTkSuQmCC\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAf5JREFUaAW9wT+I1QUAB/DPxRf7Q4PEXeDikG22STRlS1xbOHkOOTganFMQooSgNtTU0pJDosEhIogtR0uUi9AmuES1iMtFxAMJHO45/IYb5L177xd8P58oi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7JY0ns4jeM4avAZnuB93MADs0VZlEVZLGED32AVK/gZa/jaYAWrOGW2KIuyKIsFBO/iO7yGX3AZ9/EybmHd4DfzRVmURVks4BNcM/gJG5gYbGDd4DGumy/KoizKYh9XcB5TfIuLmNhzwZ5z2DFflEVZlMUcX+A8nmEbn+M/g1ewjsNYwRXctb8oi7IoixkO4lNMsY0T9ryNH3DM4Da+spgoi7IoixkOYNXgHN7EGXyMd/A6ppjiJp5aTJRFWZTFDM+wgzX8hak9TzDBIfyNexYXZVEWZTHDvziBH/EG/sBdfI9/sIVD2LKcKIuyKIs5HmDNi47jA+ziT8uJsiiLshjhVexiii3LibIoi7IYYdt4URZlURYjfGS8KIuyKIsRjhgvyqIsymKEX/ESdi0vyqIsymKEh/gdb+EIdiwuyqIsymKkL3ENV7GJRxYTZVEWZTHSHZzCh7iEM3hqf1EWZVEWI01wEldxFpfwyP6iLMqiLP6HCTaxaXFRFmVR9hxr7UyvfehgBAAAAABJRU5ErkJg\"></td></tr></tbody></table><div><small>(a vector displayed as a row to save space)</small></div>"
      ],
      "text/plain": [
       "5-element Vector{Base.ReinterpretArray{Gray{N0f8}, 2, N0f8, Matrix{N0f8}, true}}:\n",
       " [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n",
       " [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n",
       " [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n",
       " [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n",
       " [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1×5 adjoint(::Vector{Int64}) with eltype Int64:\n",
       " 5  0  4  1  9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load mnist from MLDatasets\n",
    "trainX_original,      trainY_original      = MNIST.traindata()\n",
    "validationX_original, validationY_original = MNIST.testdata();\n",
    "\n",
    "display([MNIST.convert2image(MNIST.traintensor(i)) for i in 1:5])\n",
    "trainY_original[1:5]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f2acc6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28, 28, 42001), (28, 28, 17999), (28, 28, 10000))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split trainset, testset, validation set\n",
    "Random.seed!(1)\n",
    "(trainX, trainY), (testX, testY) = stratifiedobs((trainX_original, trainY_original), p = 0.7)\n",
    "validationX = copy(validationX_original); validationY = copy(validationY_original)\n",
    "\n",
    "size(trainX), size(testX), size(validationX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b9c3b0",
   "metadata": {},
   "source": [
    "### Logistic classification (two classes - two predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a75bf6b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42001,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert images to vectors\n",
    "trainX = batchImage2Vector(trainX)\n",
    "size(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d182058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Int64}:\n",
       " 1\n",
       " 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((8514,), (8514,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select classes for prediction\n",
    "c = (1, 5)\n",
    "\n",
    "# data selection from above classes and sizes\n",
    "trainX = vcat( trainX[trainY .== c[1] ], trainX[ trainY .== c[2] ] )\n",
    "trainY = vcat( trainY[trainY .== c[1] ], trainY[ trainY .== c[2] ] )\n",
    "display(levels(trainY))\n",
    "size(trainX), size(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a941e91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictors and outcome\n",
    "function generatePredictors(X)\n",
    "    N = size(X)[1]\n",
    "    x1 = [meanIntensity(X[i]) for i in 1:N]\n",
    "    x2 = [hSymmetry(X[i])     for i in 1:N]\n",
    "    Xs = hcat(x1, x2)\n",
    "    Xs = rescaleByColumns(Xs)\n",
    "    \n",
    "    return Xs\n",
    "end\n",
    "\n",
    "trainXLog = generatePredictors(trainX)\n",
    "trainYLog = copy(trainY);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbaf1f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specific conversions for MLJ\n",
    "trainXLog = DataFrame(trainXLog, :auto)\n",
    "trainYLog = categorical(trainYLog, ordered=true);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "609325e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "machine(model, args...; cache=true)\n",
       "\\end{verbatim}\n",
       "Construct a \\texttt{Machine} object binding a \\texttt{model}, storing hyper-parameters of some machine learning algorithm, to some data, \\texttt{args}. Calling \\texttt{fit!} on a \\texttt{Machine} object stores in the machine object the outcomes of applying the algorithm. This in turn enables generalization to new data using operations such as \\texttt{predict} or \\texttt{transform}:\n",
       "\n",
       "\\begin{verbatim}\n",
       "using MLJModels\n",
       "X, y = make_regression()\n",
       "\n",
       "PCA = @load PCA pkg=MultivariateStats\n",
       "model = PCA()\n",
       "mach = machine(model, X)\n",
       "fit!(mach, rows=1:50)\n",
       "transform(mach, selectrows(X, 51:100)) # or transform(mach, rows=51:100)\n",
       "\n",
       "DecisionTreeRegressor = @load DecisionTreeRegressor pkg=DecisionTree\n",
       "model = DecisionTreeRegressor()\n",
       "mach = machine(model, X, y)\n",
       "fit!(mach, rows=1:50)\n",
       "predict(mach, selectrows(X, 51:100)) # or predict(mach, rows=51:100)\n",
       "\\end{verbatim}\n",
       "Specify \\texttt{cache=false} to prioritize memory management over speed, and to guarantee data anonymity when serializing composite models.\n",
       "\n",
       "When building a learning network, \\texttt{Node} objects can be substituted for the concrete data.\n",
       "\n",
       "\\subsubsection{Learning network machines}\n",
       "\\begin{verbatim}\n",
       "machine(Xs; oper1=node1, oper2=node2, ...)\n",
       "machine(Xs, ys; oper1=node1, oper2=node2, ...)\n",
       "machine(Xs, ys, extras...; oper1=node1, oper2=node2, ...)\n",
       "\\end{verbatim}\n",
       "Construct a special machine called a \\emph{learning network machine}, that wraps a learning network, usually in preparation to export the network as a stand-alone composite model type. The keyword arguments declare what nodes are called when operations, such as \\texttt{predict} and \\texttt{transform}, are called on the machine. An advanced option allows one to additionally pass the output of any node to the machine's report; see below.\n",
       "\n",
       "In addition to the operations named in the constructor, the methods \\texttt{fit!}, \\texttt{report}, and \\texttt{fitted\\_params} can be applied as usual to the machine constructed.\n",
       "\n",
       "\\begin{verbatim}\n",
       "machine(Probabilistic(), args...; kwargs...)\n",
       "machine(Deterministic(), args...; kwargs...)\n",
       "machine(Unsupervised(), args...; kwargs...)\n",
       "machine(Static(), args...; kwargs...)\n",
       "\\end{verbatim}\n",
       "Same as above, but specifying explicitly the kind of model the learning network is to meant to represent.\n",
       "\n",
       "Learning network machines are not to be confused with an ordinary machine that happens to be bound to a stand-alone composite model (i.e., an \\emph{exported} learning network).\n",
       "\n",
       "\\subsubsection{Examples of learning network machines}\n",
       "Supposing a supervised learning network's final predictions are obtained by calling a node \\texttt{yhat}, then the code\n",
       "\n",
       "\\begin{verbatim}\n",
       "mach = machine(Deterministic(), Xs, ys; predict=yhat)\n",
       "fit!(mach; rows=train)\n",
       "predictions = predict(mach, Xnew) # `Xnew` concrete data\n",
       "\\end{verbatim}\n",
       "is  equivalent to\n",
       "\n",
       "\\begin{verbatim}\n",
       "fit!(yhat, rows=train)\n",
       "predictions = yhat(Xnew)\n",
       "\\end{verbatim}\n",
       "Here \\texttt{Xs} and \\texttt{ys} are the source nodes receiving, respectively, the input and target data.\n",
       "\n",
       "In a unsupervised learning network for clustering, with single source node \\texttt{Xs} for inputs, and in which the node \\texttt{Xout} delivers the output of dimension reduction, and \\texttt{yhat} the class labels, one can write\n",
       "\n",
       "\\begin{verbatim}\n",
       "mach = machine(Unsupervised(), Xs; transform=Xout, predict=yhat)\n",
       "fit!(mach)\n",
       "transformed = transform(mach, Xnew) # `Xnew` concrete data\n",
       "predictions = predict(mach, Xnew)\n",
       "\\end{verbatim}\n",
       "which is equivalent to\n",
       "\n",
       "\\begin{verbatim}\n",
       "fit!(Xout)\n",
       "fit!(yhat)\n",
       "transformed = Xout(Xnew)\n",
       "predictions = yhat(Xnew)\n",
       "\\end{verbatim}\n",
       "\\subsubsection{Including a node's output in the report}\n",
       "The return value of a node called with no arguments can be included in a learning network machine's report, and so in the report of any composite model type constructed by exporting a learning network. This is useful for exposing byproducts of network training that are not readily deduced from the \\texttt{report}s and \\texttt{fitted\\_params} of the component machines (which are automatically exposed).\n",
       "\n",
       "The following example shows how to expose \\texttt{err1()} and \\texttt{err2()}, where \\texttt{err1} are \\texttt{err2} are nodes in the network delivering training errors.\n",
       "\n",
       "\\begin{verbatim}\n",
       "X, y = make_moons()\n",
       "Xs = source(X)\n",
       "ys = source(y)\n",
       "\n",
       "model = ConstantClassifier()\n",
       "mach = machine(model, Xs, ys)\n",
       "yhat = predict(mach, Xs)\n",
       "err1 = @node auc(yhat, ys)\n",
       "err2 = @node accuracy(yhat, ys)\n",
       "\n",
       "network_mach = machine(Probabilistic(),\n",
       "                       Xs,\n",
       "                       ys,\n",
       "                       predict=yhat,\n",
       "                       report=(auc=err1, accuracy=err2))\n",
       "\n",
       "fit!(network_mach)\n",
       "r = report(network_mach)\n",
       "@assert r.auc == auc(yhat(), ys())\n",
       "@assert r.accuracy == accuracy(yhat(), ys())\n",
       "\\end{verbatim}\n"
      ],
      "text/markdown": [
       "```\n",
       "machine(model, args...; cache=true)\n",
       "```\n",
       "\n",
       "Construct a `Machine` object binding a `model`, storing hyper-parameters of some machine learning algorithm, to some data, `args`. Calling `fit!` on a `Machine` object stores in the machine object the outcomes of applying the algorithm. This in turn enables generalization to new data using operations such as `predict` or `transform`:\n",
       "\n",
       "```julia\n",
       "using MLJModels\n",
       "X, y = make_regression()\n",
       "\n",
       "PCA = @load PCA pkg=MultivariateStats\n",
       "model = PCA()\n",
       "mach = machine(model, X)\n",
       "fit!(mach, rows=1:50)\n",
       "transform(mach, selectrows(X, 51:100)) # or transform(mach, rows=51:100)\n",
       "\n",
       "DecisionTreeRegressor = @load DecisionTreeRegressor pkg=DecisionTree\n",
       "model = DecisionTreeRegressor()\n",
       "mach = machine(model, X, y)\n",
       "fit!(mach, rows=1:50)\n",
       "predict(mach, selectrows(X, 51:100)) # or predict(mach, rows=51:100)\n",
       "```\n",
       "\n",
       "Specify `cache=false` to prioritize memory management over speed, and to guarantee data anonymity when serializing composite models.\n",
       "\n",
       "When building a learning network, `Node` objects can be substituted for the concrete data.\n",
       "\n",
       "### Learning network machines\n",
       "\n",
       "```\n",
       "machine(Xs; oper1=node1, oper2=node2, ...)\n",
       "machine(Xs, ys; oper1=node1, oper2=node2, ...)\n",
       "machine(Xs, ys, extras...; oper1=node1, oper2=node2, ...)\n",
       "```\n",
       "\n",
       "Construct a special machine called a *learning network machine*, that wraps a learning network, usually in preparation to export the network as a stand-alone composite model type. The keyword arguments declare what nodes are called when operations, such as `predict` and `transform`, are called on the machine. An advanced option allows one to additionally pass the output of any node to the machine's report; see below.\n",
       "\n",
       "In addition to the operations named in the constructor, the methods `fit!`, `report`, and `fitted_params` can be applied as usual to the machine constructed.\n",
       "\n",
       "```\n",
       "machine(Probabilistic(), args...; kwargs...)\n",
       "machine(Deterministic(), args...; kwargs...)\n",
       "machine(Unsupervised(), args...; kwargs...)\n",
       "machine(Static(), args...; kwargs...)\n",
       "```\n",
       "\n",
       "Same as above, but specifying explicitly the kind of model the learning network is to meant to represent.\n",
       "\n",
       "Learning network machines are not to be confused with an ordinary machine that happens to be bound to a stand-alone composite model (i.e., an *exported* learning network).\n",
       "\n",
       "### Examples of learning network machines\n",
       "\n",
       "Supposing a supervised learning network's final predictions are obtained by calling a node `yhat`, then the code\n",
       "\n",
       "```julia\n",
       "mach = machine(Deterministic(), Xs, ys; predict=yhat)\n",
       "fit!(mach; rows=train)\n",
       "predictions = predict(mach, Xnew) # `Xnew` concrete data\n",
       "```\n",
       "\n",
       "is  equivalent to\n",
       "\n",
       "```julia\n",
       "fit!(yhat, rows=train)\n",
       "predictions = yhat(Xnew)\n",
       "```\n",
       "\n",
       "Here `Xs` and `ys` are the source nodes receiving, respectively, the input and target data.\n",
       "\n",
       "In a unsupervised learning network for clustering, with single source node `Xs` for inputs, and in which the node `Xout` delivers the output of dimension reduction, and `yhat` the class labels, one can write\n",
       "\n",
       "```julia\n",
       "mach = machine(Unsupervised(), Xs; transform=Xout, predict=yhat)\n",
       "fit!(mach)\n",
       "transformed = transform(mach, Xnew) # `Xnew` concrete data\n",
       "predictions = predict(mach, Xnew)\n",
       "```\n",
       "\n",
       "which is equivalent to\n",
       "\n",
       "```julia\n",
       "fit!(Xout)\n",
       "fit!(yhat)\n",
       "transformed = Xout(Xnew)\n",
       "predictions = yhat(Xnew)\n",
       "```\n",
       "\n",
       "### Including a node's output in the report\n",
       "\n",
       "The return value of a node called with no arguments can be included in a learning network machine's report, and so in the report of any composite model type constructed by exporting a learning network. This is useful for exposing byproducts of network training that are not readily deduced from the `report`s and `fitted_params` of the component machines (which are automatically exposed).\n",
       "\n",
       "The following example shows how to expose `err1()` and `err2()`, where `err1` are `err2` are nodes in the network delivering training errors.\n",
       "\n",
       "```julia\n",
       "X, y = make_moons()\n",
       "Xs = source(X)\n",
       "ys = source(y)\n",
       "\n",
       "model = ConstantClassifier()\n",
       "mach = machine(model, Xs, ys)\n",
       "yhat = predict(mach, Xs)\n",
       "err1 = @node auc(yhat, ys)\n",
       "err2 = @node accuracy(yhat, ys)\n",
       "\n",
       "network_mach = machine(Probabilistic(),\n",
       "                       Xs,\n",
       "                       ys,\n",
       "                       predict=yhat,\n",
       "                       report=(auc=err1, accuracy=err2))\n",
       "\n",
       "fit!(network_mach)\n",
       "r = report(network_mach)\n",
       "@assert r.auc == auc(yhat(), ys())\n",
       "@assert r.accuracy == accuracy(yhat(), ys())\n",
       "```\n"
      ],
      "text/plain": [
       "\u001b[36m  machine(model, args...; cache=true)\u001b[39m\n",
       "\n",
       "  Construct a \u001b[36mMachine\u001b[39m object binding a \u001b[36mmodel\u001b[39m, storing hyper-parameters of some\n",
       "  machine learning algorithm, to some data, \u001b[36margs\u001b[39m. Calling \u001b[36mfit!\u001b[39m on a \u001b[36mMachine\u001b[39m\n",
       "  object stores in the machine object the outcomes of applying the algorithm.\n",
       "  This in turn enables generalization to new data using operations such as\n",
       "  \u001b[36mpredict\u001b[39m or \u001b[36mtransform\u001b[39m:\n",
       "\n",
       "\u001b[36m  using MLJModels\u001b[39m\n",
       "\u001b[36m  X, y = make_regression()\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  PCA = @load PCA pkg=MultivariateStats\u001b[39m\n",
       "\u001b[36m  model = PCA()\u001b[39m\n",
       "\u001b[36m  mach = machine(model, X)\u001b[39m\n",
       "\u001b[36m  fit!(mach, rows=1:50)\u001b[39m\n",
       "\u001b[36m  transform(mach, selectrows(X, 51:100)) # or transform(mach, rows=51:100)\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  DecisionTreeRegressor = @load DecisionTreeRegressor pkg=DecisionTree\u001b[39m\n",
       "\u001b[36m  model = DecisionTreeRegressor()\u001b[39m\n",
       "\u001b[36m  mach = machine(model, X, y)\u001b[39m\n",
       "\u001b[36m  fit!(mach, rows=1:50)\u001b[39m\n",
       "\u001b[36m  predict(mach, selectrows(X, 51:100)) # or predict(mach, rows=51:100)\u001b[39m\n",
       "\n",
       "  Specify \u001b[36mcache=false\u001b[39m to prioritize memory management over speed, and to\n",
       "  guarantee data anonymity when serializing composite models.\n",
       "\n",
       "  When building a learning network, \u001b[36mNode\u001b[39m objects can be substituted for the\n",
       "  concrete data.\n",
       "\n",
       "\u001b[1m  Learning network machines\u001b[22m\n",
       "\u001b[1m  –––––––––––––––––––––––––––\u001b[22m\n",
       "\n",
       "\u001b[36m  machine(Xs; oper1=node1, oper2=node2, ...)\u001b[39m\n",
       "\u001b[36m  machine(Xs, ys; oper1=node1, oper2=node2, ...)\u001b[39m\n",
       "\u001b[36m  machine(Xs, ys, extras...; oper1=node1, oper2=node2, ...)\u001b[39m\n",
       "\n",
       "  Construct a special machine called a \u001b[4mlearning network machine\u001b[24m, that wraps a\n",
       "  learning network, usually in preparation to export the network as a\n",
       "  stand-alone composite model type. The keyword arguments declare what nodes\n",
       "  are called when operations, such as \u001b[36mpredict\u001b[39m and \u001b[36mtransform\u001b[39m, are called on the\n",
       "  machine. An advanced option allows one to additionally pass the output of\n",
       "  any node to the machine's report; see below.\n",
       "\n",
       "  In addition to the operations named in the constructor, the methods \u001b[36mfit!\u001b[39m,\n",
       "  \u001b[36mreport\u001b[39m, and \u001b[36mfitted_params\u001b[39m can be applied as usual to the machine\n",
       "  constructed.\n",
       "\n",
       "\u001b[36m  machine(Probabilistic(), args...; kwargs...)\u001b[39m\n",
       "\u001b[36m  machine(Deterministic(), args...; kwargs...)\u001b[39m\n",
       "\u001b[36m  machine(Unsupervised(), args...; kwargs...)\u001b[39m\n",
       "\u001b[36m  machine(Static(), args...; kwargs...)\u001b[39m\n",
       "\n",
       "  Same as above, but specifying explicitly the kind of model the learning\n",
       "  network is to meant to represent.\n",
       "\n",
       "  Learning network machines are not to be confused with an ordinary machine\n",
       "  that happens to be bound to a stand-alone composite model (i.e., an \u001b[4mexported\u001b[24m\n",
       "  learning network).\n",
       "\n",
       "\u001b[1m  Examples of learning network machines\u001b[22m\n",
       "\u001b[1m  –––––––––––––––––––––––––––––––––––––––\u001b[22m\n",
       "\n",
       "  Supposing a supervised learning network's final predictions are obtained by\n",
       "  calling a node \u001b[36myhat\u001b[39m, then the code\n",
       "\n",
       "\u001b[36m  mach = machine(Deterministic(), Xs, ys; predict=yhat)\u001b[39m\n",
       "\u001b[36m  fit!(mach; rows=train)\u001b[39m\n",
       "\u001b[36m  predictions = predict(mach, Xnew) # `Xnew` concrete data\u001b[39m\n",
       "\n",
       "  is equivalent to\n",
       "\n",
       "\u001b[36m  fit!(yhat, rows=train)\u001b[39m\n",
       "\u001b[36m  predictions = yhat(Xnew)\u001b[39m\n",
       "\n",
       "  Here \u001b[36mXs\u001b[39m and \u001b[36mys\u001b[39m are the source nodes receiving, respectively, the input and\n",
       "  target data.\n",
       "\n",
       "  In a unsupervised learning network for clustering, with single source node\n",
       "  \u001b[36mXs\u001b[39m for inputs, and in which the node \u001b[36mXout\u001b[39m delivers the output of dimension\n",
       "  reduction, and \u001b[36myhat\u001b[39m the class labels, one can write\n",
       "\n",
       "\u001b[36m  mach = machine(Unsupervised(), Xs; transform=Xout, predict=yhat)\u001b[39m\n",
       "\u001b[36m  fit!(mach)\u001b[39m\n",
       "\u001b[36m  transformed = transform(mach, Xnew) # `Xnew` concrete data\u001b[39m\n",
       "\u001b[36m  predictions = predict(mach, Xnew)\u001b[39m\n",
       "\n",
       "  which is equivalent to\n",
       "\n",
       "\u001b[36m  fit!(Xout)\u001b[39m\n",
       "\u001b[36m  fit!(yhat)\u001b[39m\n",
       "\u001b[36m  transformed = Xout(Xnew)\u001b[39m\n",
       "\u001b[36m  predictions = yhat(Xnew)\u001b[39m\n",
       "\n",
       "\u001b[1m  Including a node's output in the report\u001b[22m\n",
       "\u001b[1m  –––––––––––––––––––––––––––––––––––––––––\u001b[22m\n",
       "\n",
       "  The return value of a node called with no arguments can be included in a\n",
       "  learning network machine's report, and so in the report of any composite\n",
       "  model type constructed by exporting a learning network. This is useful for\n",
       "  exposing byproducts of network training that are not readily deduced from\n",
       "  the \u001b[36mreport\u001b[39ms and \u001b[36mfitted_params\u001b[39m of the component machines (which are\n",
       "  automatically exposed).\n",
       "\n",
       "  The following example shows how to expose \u001b[36merr1()\u001b[39m and \u001b[36merr2()\u001b[39m, where \u001b[36merr1\u001b[39m are\n",
       "  \u001b[36merr2\u001b[39m are nodes in the network delivering training errors.\n",
       "\n",
       "\u001b[36m  X, y = make_moons()\u001b[39m\n",
       "\u001b[36m  Xs = source(X)\u001b[39m\n",
       "\u001b[36m  ys = source(y)\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  model = ConstantClassifier()\u001b[39m\n",
       "\u001b[36m  mach = machine(model, Xs, ys)\u001b[39m\n",
       "\u001b[36m  yhat = predict(mach, Xs)\u001b[39m\n",
       "\u001b[36m  err1 = @node auc(yhat, ys)\u001b[39m\n",
       "\u001b[36m  err2 = @node accuracy(yhat, ys)\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  network_mach = machine(Probabilistic(),\u001b[39m\n",
       "\u001b[36m                         Xs,\u001b[39m\n",
       "\u001b[36m                         ys,\u001b[39m\n",
       "\u001b[36m                         predict=yhat,\u001b[39m\n",
       "\u001b[36m                         report=(auc=err1, accuracy=err2))\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  fit!(network_mach)\u001b[39m\n",
       "\u001b[36m  r = report(network_mach)\u001b[39m\n",
       "\u001b[36m  @assert r.auc == auc(yhat(), ys())\u001b[39m\n",
       "\u001b[36m  @assert r.accuracy == accuracy(yhat(), ys())\u001b[39m"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?MLJ.machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c78fdb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training Machine{LogisticClassifier,…}.\n",
      "└ @ MLJBase /home/ciro/.julia/packages/MLJBase/CglMw/src/machines.jl:464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Machine{LogisticClassifier,…} trained 1 time; caches data\n",
       "  model: LogisticClassifier\n",
       "  args: \n",
       "    1:\tSource @092 ⏎ `Table{AbstractVector{ScientificTypesBase.Continuous}}`\n",
       "    2:\tSource @020 ⏎ `AbstractVector{OrderedFactor{2}}`\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "mdl = LogisticClassifier()\n",
    "mach = machine(mdl, trainXLog, trainYLog)\n",
    "fit!(mach)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c250f985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element CategoricalDistributions.UnivariateFiniteArray{OrderedFactor{2}, Int64, UInt32, Float64, 1}:\n",
       " UnivariateFinite{OrderedFactor{2}}(1=>0.633, 5=>0.367)\n",
       " UnivariateFinite{OrderedFactor{2}}(1=>0.704, 5=>0.296)\n",
       " UnivariateFinite{OrderedFactor{2}}(1=>0.698, 5=>0.302)\n",
       " UnivariateFinite{OrderedFactor{2}}(1=>0.632, 5=>0.368)\n",
       " UnivariateFinite{OrderedFactor{2}}(1=>0.647, 5=>0.353)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict with trainset\n",
    "params = fitted_params(mach)\n",
    "p = MLJ.predict(mach, trainXLog)\n",
    "p[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf9588f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         \u001b[1mUnivariateFinite{OrderedFactor{2}}\u001b[22m     \n",
       "     \u001b[90m┌                                        ┐\u001b[39m \n",
       "   \u001b[0m1 \u001b[90m┤\u001b[39m\u001b[38;5;2m■■■■■■■■■■■■■■■■■■■■\u001b[39m\u001b[0m 0.6330328095306961 \u001b[90m \u001b[39m \n",
       "   \u001b[0m5 \u001b[90m┤\u001b[39m\u001b[38;5;2m■■■■■■■■■■■■\u001b[39m\u001b[0m 0.36696719046930387        \u001b[90m \u001b[39m \n",
       "     \u001b[90m└                                        ┘\u001b[39m "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d15c3d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element CategoricalArrays.CategoricalArray{Int64,1,UInt32}:\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert probability to classes\n",
    "ŷ = predict_mode(mach, trainXLog)\n",
    "ŷ[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8424b726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              ┌───────────────────────────┐\n",
       "              │       Ground Truth        │\n",
       "┌─────────────┼─────────────┬─────────────┤\n",
       "│  Predicted  │      1      │      5      │\n",
       "├─────────────┼─────────────┼─────────────┤\n",
       "│      1      │    4651     │    1281     │\n",
       "├─────────────┼─────────────┼─────────────┤\n",
       "│      5      │     68      │    2514     │\n",
       "└─────────────┴─────────────┴─────────────┘\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metrics\n",
    "confmat(ŷ, trainYLog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3a8c313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tbody><tr><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAf9JREFUaAW9wb+L1gUAB+An+TgpQgnaYjiYRIYHLYHY4OAQBUIkQhhlLUEOgv9AgzQ03KBI6CBEcC3ScEQYTcElHjYockNgukhg0CCSCP7A4TuIyNv7vXvj8zxRFmVRFmVRFmVRFmVRFmVRFmVRFmVRFmVRFmVRFmUxo/XYjHexA6/jTWzAF/jes6IsyqIs1uBlfIS3sR1vGFzHZXyFBdzxvCiLsiiLVZjDZziAbQbLmMcSLuC+/xZlURZlsQrHcRh3cRIL+B2PjRdlURZlMcIr+AZz+AA/419rE2VRFmUxwud4B9/hB7OJsiiLsphiBz41+NrsoizKoiym+BBbDE7iocFVXMeP+Mt4URZlURZT7PLUPk/tN7iNPbhpnCiLsiiLKX7CLSzhosFreBVHsRsL2ItHpouyKIuymOJbz7uNX7GIW3gL5/Cx6aIsyqIsZvA3TuBL7DROlEVZlMWM/jR4yThRFmVRFjNYh0MGl4wTZVEWZTGD/XjP4IZxoizKoixmcN5gEfPGibIoi7KYYA/u4YpnvYA5nMVG/IZPcNc4URZlURYTzGMTjmDZYCtO432DX3AQd4wXZVEWZTHBIk5gCSsG2/AiruEsTlu9KIuyKIsJzmALjmI3VnAK5/EHHlibKIuyKIsJ/sExHPP/irIoi7Ioi7Ioi7Ioi7Ioi7InNC1ILnZj/tgAAAAASUVORK5C\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAgpJREFUaAW9wT2oFWQABuDn3l6yGmoJxNlaomzNpa2MQAz6gYigFCVobosgEANLEboqgmDQ0BJkiHcIgyBqSHFxMrEcXLqD+JNKWNhwh4bTOeeTK+/zRFmURVmURVmURVmURVmURVmURVmURVmURVmURVmUxRSLeBsf4gncNd1G/G5MlEVZlMUUj2Mf/sJOXMJmrLfqKn7AV3gRR4yJsiiLsphiBSexDT/iPE6Z9Bx+My7KoizKYob3sAG/4EmsmHTRvYmyKIuymOE23sdZvIElaxdlURZlMccF/IxPsGTtoizKoiwGfI0X8DKWsYgteA3f4w4u4bT5oizKoiwGfIslPIRncQibcQuvYAGP4FN8jL9NF2VRFmUxYAUX8DkexiL24wAu4wHswkHcwF7TRVmURVkM+gnbcRCf4bL//IOj2Im3sNd0URZlURaDPsA+/Or/3cFxvGq2KIuyKItB13HdbH+aL8qiLMriPlpvviiLsiiL++RRvIvDZouyKIuyGLSAd3DMpAVsxTqcMFuURVmUxaBd2INjJj2NL/ERzpgtyqIsymLQ8zhv0lM4jnM4YL4oi7Ioi3vwIB7DNatewje4gk24ab4oi7Ioi0Gn8CYu4jurXscVPIObxkRZlEVZDPoCf2AHtuAMdmM/bhgXZVEWZTHoLpaxbG2iLMqiLMqiLMqiLMqiLMqi7F+u01NwEtlQfQAAAABJRU5ErkJg\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAd9JREFUaAW9wTGIlgUABuBHeB0OF4e00UFBcXWRmxOuxVk9EI8IhFvEQZFAKGgpcAk5F0kHFUEQxKUzUBpcRNTR7cThqIiuxoRs+AZx6P/v++94nyfKoizKoizKoizKoizKoizKoizKoizKoizKoizKoizKoizKoixGCpax1wc78B7z+BSHfOwdHmMBURZlURYjHcMVH9uB9wYbWDe4jt/xCr8YRFmURVnM6BJ+M5jHU4MnWPP/oizKoixG2I89eIk7eGtww+ZFWZRFWWzCHL7FIp7hiNlFWZRFWUxxGOexhD/xg62JsiiLsphgJ77HAjawiJ9sTZRFWZTFBOewgL9xAo9sXZRFWZTFBJcN/sGa7RFlURZlMcFp3MMneIVb+Bl3zS7KoizKYoL7+Byf4SzO4Ascw0X8Ybwoi7IoiylWsYoLOI5vsITnWDFelEVZlMUID/AOD3EOt/GXcaIsyqIsRnqJNziAU1gxTpRFWZTFSOvYwD4cNF6URVmUxUhHccDsoizKoiymmMMlXDaYxy6sYcV4URZlURZT7MaX+BFf4aTBCbw2XpRFWZTFJuzFc8xhHd/hhdlEWZRFWUzxK5ZxFW/xNW6aXZRFWZTFFP/iGq7ZHlEWZVEWZVEWZVH2H5gARV5x+vZWAAAAAElFTkSuQmCC\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAUZJREFUaAW9waGqlwcAxuHnwA8RYasuLRmNYwvalkRYXDWcW7KZvQGDLGjaDXgRCwcHZhHGWTjB+v++A+/zZCxjGctYxjKWsYxlLGMZy1jGMpaxjOWka7zCn7hxuYxlLGM56RbP8TveulzGMpax3NNrfMSNy2QsYxnLPf2IX/HOZTKWsYzlpJfOyVjGMpYTHuEJrhyXsYxlLCf8jKe4xX/45nIZy1jGck+f8JfLZSxjGcsJv/jug2MylrGM5YSHvnvvmIxlLGM54RmucIXPjslYxjKWE17iFv/gi2MylrGM5aDf8IM7f+Nfx2QsYxnLQT/hgTvXjstYxjKWe/jquIxlLGM56DGunJexjGUsB73ArfMylrGMZSxjGctYxjKWsYzloPf4w3kZy1jGctAbvHFexjKWsYxlLGMZy1jGMpaxjGUsYxn7H0juG0tpx7iYAAAAAElFTkSuQmCC\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAXJJREFUaAW9wSFrVmEABtCDPGxJ8F8sLQkKat1QlkVxzb9gMaltyLpWi1hcF4xiM4hYnDIQDFYFYYig4evuvfd+POdEWZRFWZRFWZRFWZRFWZRFWZRFWZRFWZRFWZRFWZTFGhziHj5jy/9FWZRFWazBMf7gmbNFWZRFWazBHr7gwNmiLMqiLBa6hes4MSbKoizKYqFH2MCxMVEWZVEWC1zDFt7jtjFRFmVRFgtsW/mEU2OiLMqiLBa4aOWFcVEWZVEWM+1gHyd4ZVyURVmUxUwPsYkD/DYuyqIsymKGm7iKt3hpmiiLsiiLGZ7gL57ih2miLMqiLCa6jPN4jeemi7Ioi7KYIHiADTw2T5RFWZTFBJdwA1/xzjxRFmVRFhPct3IHP80TZVEWZTHoCnbxER/MF2VRFmUx6C5OsYtf5ouyKIuyGHAB+/iG75aJsiiLshiwjU0cWS7KoizKYsAbnLMeURZlURZlURZlURZlURZlUfYPRcgnvfhqr14AAAAASUVORK5C\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAh9JREFUaAW9wbGL1QUAB/BP1xdtiTwouiEIl8gcHIrgiJKwqTEuaGh0ylr6ByJqSoIoxwg5hws0F4eglsJRqIaGBgcV4qCXQ0gSJO81vOHHA39378X5/XyiLMqiLMqiLMqiLMqiLMqiLMqiLMqiLMriAVrHYfyNO+aiLMqiLB6AE3gC57GBH3HKXJRFWZTFAdrEq/gIM/cXZVEWZXFATuMzPGJvURZlURb/w5t42txJPI8jOGQwwTa2cdMgyqIsymJFm/jaYA1Tg2/xIa65vyiLsiiLJb2Ot7CJmcEUt/AzLuMS/jEuyqIsymIJr+FTPIMZfsJtXMNV/Ipdy4myKIuy2McmvsRTBuvYwZ/43mqiLMqiLPZwHFdwxKKjOGvuE7yHS5YTZVEWZTHiYXyAdYM1TC3awDlcxy/2F2VRFmUx4jm8gZnB7ziP38x9jsfwOHbwCib2FmVRFmUx4phFN3EKNwxexBmribIoi7IYcRVn8TbOYRu7Fn2DM1YTZVEWZTFiF1/gHr7CxKLj2DG4gYn9RVmURVmMeBTf4RguYmLRy3gSa5jiruVEWZRFWYw4iWdxEes4gXu4g9N4BzNMcQvvWk6URVmUxYgtc1vYMvcvbmPD4C7ex67lRFmURVmM+Bgv4ajBIWxYdAE/WF6URVmUxYjreAGHDR7CzKI/rCbKoizKYg9/OXhRFmVRFmVRFmVRFmVRFmVRFmVRFmVR9h8+Y1VkypEbQQAAAABJRU5ErkJg\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAb5JREFUaAW9wb+LzgEAB+AnfbLpDKgrZVAyioU/wA2sN/gHdF2SU5RBlAXLUZJNYVDcbrvBJoOSjcEgPwqZ6JIfww2X5d73+975PE+URVmURVmURVmURVmURVmURVmURVmURVmURVmURVmURVmURVmURVmURVn8B7uw3b/e4TuiLMqiLCa0FcEMDmDGmj2YtuoXVnATFxFlURZlMcAU5nAIB7HXv37hCZ5hNx7hC5atibIoi7IYwxZcw0lMWfMJH/AAL/ASX60vyqIsymIMl3DOqh+4hYf4hI+GibIoi7IYYRtOWPUNC7hvclEWZVEWI5zDPqvO4r6NibIoi7IYYcWaZRsXZVEWZTHCXZzBTsziho2JsiiLshjhI5Ywj0UcwRW8Mpkoi7IoizGcRjCLWRzDPVzGZ8NEWZRFWYzhN+ZwFaewgHkcxiHDRFmURVkM8BbnsR/HscNwURZlURYDncBRk4uyKIuyGNM2LOACtuInrhouyqIsymIM87iIaazgMW7jqeGiLMqiLNZxB7OYwnNcxxLem1yURVmUxToWsYg/eGNzRFmURVms47XNF2VRFmVRFmVRFmVRFmVRFmV/AWCOPDa6f/LtAAAAAElFTkSuQmCC\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAWZJREFUaAW9wSFyU1EABdCTmatAtplBMcjWxncPKWtgBxgQOMCxgeJRnXQlxf7sgdSCDKIb+O915p4TZVEWZVEWZVEWZVEWZVEWZVEWZVEWZVEWA97jHt/wxZwoi7Ioi5W2+IEzPuMXFuOiLMqiLFb6g4+49+wGi3FRFmVRFgMOOONsXpRFWZTFoCdcmBdlURZlMeiAD+ZFWZRFWQw6YYMb3BkXZVEWZTHoAZ+wxxWOxkRZlEVZDPqLf3iNV8ZFWZRFWQxacMQOt/htTJRFWZTFoGtcYYNL46IsyqIsBi04YmdOlEVZlMWkDbbGRVmURVlMeMAOe1xjsV6URVmUxYTv+OrZDRbrRVmURVlMOmCPW9xZL8qiLMpi0gkbbI2JsiiLsniBMy5wiZN1oizKoixeYIN3eIuTdaIsyqIsJv3EHk84Wi/KoizKYtIj3hgXZVEWZVEWZVEWZVEWZVEWZVEWZVEWZf8B+k0o2l08IjsAAAAASUVORK5C\"></td></tr></tbody></table><div><small>(a vector displayed as a row to save space)</small></div>"
      ],
      "text/plain": [
       "8-element Vector{Base.ReinterpretArray{Gray{Float64}, 2, Float64, Matrix{Float64}, true}}:\n",
       " [Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); … ; Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0)]\n",
       " [Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); … ; Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0)]\n",
       " [Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); … ; Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0)]\n",
       " [Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); … ; Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0)]\n",
       " [Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); … ; Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0)]\n",
       " [Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); … ; Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0)]\n",
       " [Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); … ; Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0)]\n",
       " [Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); … ; Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0); Gray{Float64}(0.0) Gray{Float64}(0.0) … Gray{Float64}(0.0) Gray{Float64}(0.0)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "8-element Vector{Int64}:\n",
       " 5\n",
       " 5\n",
       " 5\n",
       " 1\n",
       " 1\n",
       " 5\n",
       " 5\n",
       " 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "8-element CategoricalArrays.CategoricalArray{Int64,1,UInt32}:\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 5\n",
       " 1\n",
       " 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# demonstration of prediction accuracy\n",
    "N = size(trainX)[1]\n",
    "v = rand(1:N, 8)                            # select a random sample of images\n",
    "\n",
    "trainXLog = generatePredictors(trainX[v])   # convert images to predictors\n",
    "p = MLJ.predict(mach, trainXLog)            # predict outcome from sample images\n",
    "ŷ = predict_mode(mach, trainXLog)           # convert probability to classes\n",
    "\n",
    "display([MNIST.convert2image(vector2Image( trainX[i], 28, 28) ) for i in v])\n",
    "display(trainY[v])\n",
    "display(ŷ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1ec78f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.5",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
