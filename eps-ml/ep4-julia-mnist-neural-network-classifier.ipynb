{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e145f758",
   "metadata": {},
   "source": [
    "# Neural Network Classifier with MNIST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f262ba3",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d63e87f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "#using Flux              # the julia ml library\n",
    "using Images            # image processing and machine vision for julia\n",
    "using MLJ               # make_blobs, rmse, confmat, f1score, coerce\n",
    "using MLJFlux           # NeuralNetworkClassifier, CUDALibs\n",
    "using MLDataUtils       # label, nlabel, labelfreq\n",
    "using MLDatasets        # mnist\n",
    "\n",
    "#using LinearAlgebra     # pinv pseudo-inverse matrix\n",
    "#using Metrics           # r2-score\n",
    "using Random\n",
    "using StatsBase         # standardize (normalization)\n",
    "#using Distributions\n",
    "\n",
    "using Plots; gr()\n",
    "#using StatsPlots\n",
    "using Printf\n",
    "\n",
    "#using CSV\n",
    "using DataFrames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53a09fe",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66ccdfa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "printMetrics (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metrics\n",
    "function printMetrics(ŷ, y)\n",
    "    display(confmat(ŷ, y))\n",
    "    println(\"accuracy: \", round(accuracy(ŷ, y); digits=3))\n",
    "    println(\"f1-score: \", round(multiclass_f1score(ŷ, y); digits=3))\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53255360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "batchImage2DF (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lib functions\n",
    "image2Vector(M) = vec(Float64.(M))\n",
    "\n",
    "function batchImage2Vector(imagesArray3D)\n",
    "    h, v, N = size(imagesArray3D)\n",
    "    vectorOfImageVectors = [ image2Vector( imagesArray3D[:, :, i] ) for i in 1:N]\n",
    "end\n",
    "\n",
    "function batchImage2DF(imagesArray3D)\n",
    "    vectorOfImageVectors = batchImage2Vector(imagesArray3D)\n",
    "    M = reduce(hcat, vectorOfImageVectors)\n",
    "    DataFrame(M', :auto)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8903cf71",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bd90da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tbody><tr><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAiVJREFUaAW9wT2IFgQABuAHemnI4aJFISgJwkDIIiqIsMLcajiKIEEIshosmgSHhhoUIW/IcIgCISHa+psKsp8hEKSSSAlyECon61Q+jMDT4RuO7w6/n5Pe54myKIuyKIuyKIuyKIuyKIuyKIuyKIuyKIuyKIuyKIsZ3YQ5y17FLdiE3TiI5/EvDuAto6IsyqIsJrgDN+MRPIpb8YzV/sAhzOMSTuI7q0VZlEVZjHE/vsac8ZbwBgb4CH/hH/xmtSiLsiiLMc7iPOasdhyLeAL/4ajpRFmURVmM8Tf24Cn8hEOGfsZ2DLAZr5telEVZlMUEn+IYLmELXsQCBoZ+xcumF2VRFmUxhYuGLhjahY+xZHZRFmVRFjN4Ew/gMTyJr8wuyqIsymIGA7yEH/E+vsEJHMZV04myKIuymNEZvIAj2ImdWIcPcc5kURZlURZr8Al+xwK2YT/uxD78abwoi7IoizX6Bc/haRzBK7gb240XZVEWZXEDFnEUHyDYisfxreuLsiiLslije/EsHkQMncL3xouyKIuymNEmvIZ5bLDsCs5hyXhRFmVRFlPagB3YjY1GncA+fG6yKIuyKIsJ1mMz3sU9Rh3H2/gMS6YTZVEWZXEdt+E93Ie7jPoBC/gSl80myqIsymKFh7EHD+F2oy7jHezHwNpEWZRFWawwj3nLTuMLXMFBLLoxURZlURYr7MVe/58oi7Ioi7Ioi7Ioi7Ioi7IouwZsVVgTmd3ynQAAAABJRU5ErkJg\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAjJJREFUaAW9wT1oHAQABtB3+mGISDN0sIK46SaGFEUnxbEVFTtIkWYVRCgoAYcomRzUDlYQBREUhTo4WCwihcKB0EGtOneTQkAtgu1ih5zDDRlyf0nley/KoizKoizKoizKoizKoizKoizKoizKoixuw1G8inV8jg9wxWxRFmVRFge0ios4hBFO4VkcNluURVmUxQE8hq+xghFu4BYO4wn8jFsmi7Ioi7LYh7uxhi9wn11X8Q7O4Qe8ibdNFmVRFmWxDx/jpL3WcA+GeAoPmy7KoizKYkFHcRwDY0N8i3exjV/wN57GwHRRFmVRFgtYxUUcwgjf4SSexCY+wZ/4DTs4jjVcsVeURVmUxRwPYQMr+Avb+Aw3cQEX7LWM1/GSvaIsyqIsZljCeziGG1jHT1g23wMmi7Ioi7KYYQ3HjD2HodsXZVEWZTHDGQwwxNBi7sAOBiaLsiiLspjiGaxihPMWt4MRfjVZlEVZlMUUy7gLf+Ar8y1hy9glvGGyKIuyKIs5/sW22ZawiQ1cwxncNFmURVmUxRznzbaKDbyIb3DCbFEWZVEWUwwwwPM4bbLXsIkVfIl180VZlEVZTDHCCEdwFp/iOh7HKTyC+/E7vseHFhNlURZlMcedeAUn8A8etOsyLuEti4uyKIuymOIyfsSjxo7gXmPXcQ6n7V+URVmUxRTX8AJexqZd7+MjXHUwURZlURYzbGMLW/4/URZlURZlURZlURZlURZlURZlURZlUfYfqPxYlL4fzGQAAAAASUVORK5C\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAbVJREFUaAW9wT2rDQAABuDnnN6UhSLdlNQdbrZrMjCgbkl2E9kY/ASrSfkBBukOjMJkMJkQRvJRihhsSpFSDGdw7nHP/Tid3ueJsiiLsiiLsiiLsiiLsiiLsiiLsiiLsiiLsiiLsiiLOVvBHZzAW/+LsiiLsphwHHtxz2yO4IXpoizKoiwmnMQS7tm+IRZxEAPri7Ioi7KYcAFPzGY/LuI23lhflEVZlMWEodndNPLedFEWZVEWY5axYHa7jTwyXZRFWZTFmDPYaTYLWDTyxXRRFmVRFmMOGXll+65jAe/w3XRRFmVRFut4bmt24TTO45SRq/hmuiiLsiiLdeyx1mEMsYID2IFzGOInnuEXgpc2FmVRFmUx5if+4Aau+GcZA/zGD7zGLbzAY3zFZ+zEGxuLsiiLshhzGR9xzFqf8ACv8dT/LmEfPthclEVZlMWEa7Zvxchdm4uyKIuymKP7NhdlURZlURZlURZlMScDLOGJjUVZlEVZzMkfDG0uyqIsymKOjmLVxqIsyqIs5mRga6IsyqIs5uAhztqaKIuyKIs5WMWqrYmyKIuyKIuyKIuyKIuyKIuyv/irMYSJ7ydGAAAAAElFTkSuQmCC\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAYtJREFUaAW9waFqVQEABuCP8YNRRUFM7glkDzDQoGIw+AYbdpugYcUgDEwiy4p9wSooCjLwDWYRDIJrCibD1XDCLc577rmX//uiLMqiLMqiLMqiLMqiLMqiLMqiLMqiLMqiLMqiLMpiTfbwGBu4jg/+LcqiLMpiDXbxCDODP04XZVEWZbEGV3DGOFEWZVEWK7qB+wbHuIMTp4uyKIuyWME2XuKswVN89X9RFmVRFivYwWWD93hlsSiLsiiLiS7iHmb4gSfGibIoi7KYYBOH5p7jnXGiLMqiLCa4jasGb/HMeFEWZVEWS7qLfYOP2MFP40VZlEVZLGETh+a+4MRyoizKoiyW8BAzc/uWF2VRFmUx0hZumXuNz5YXZVEWZTHSG5w3+IRd00RZlEVZjHQBM4MD/DJNlEVZlMUIL7Bh7sh0URZlURYLbOEmZviNA5yYLsqiLMpigXO4ZPAND6wmyqIsyqIsyqIsymKBYxxh23pEWZRFWSzwHdesT5RFWZRFWZRFWZRFWZRFWZT9BXYjLFSLepVZAAAAAElFTkSuQmCC\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAf5JREFUaAW9wT+I1QUAB/DPxRf7Q4PEXeDikG22STRlS1xbOHkOOTganFMQooSgNtTU0pJDosEhIogtR0uUi9AmuES1iMtFxAMJHO45/IYb5L177xd8P58oi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7JY0ns4jeM4avAZnuB93MADs0VZlEVZLGED32AVK/gZa/jaYAWrOGW2KIuyKIsFBO/iO7yGX3AZ9/EybmHd4DfzRVmURVks4BNcM/gJG5gYbGDd4DGumy/KoizKYh9XcB5TfIuLmNhzwZ5z2DFflEVZlMUcX+A8nmEbn+M/g1ewjsNYwRXctb8oi7IoixkO4lNMsY0T9ryNH3DM4Da+spgoi7IoixkOYNXgHN7EGXyMd/A6ppjiJp5aTJRFWZTFDM+wgzX8hak9TzDBIfyNexYXZVEWZTHDvziBH/EG/sBdfI9/sIVD2LKcKIuyKIs5HmDNi47jA+ziT8uJsiiLshjhVexiii3LibIoi7IYYdt4URZlURYjfGS8KIuyKIsRjhgvyqIsymKEX/ESdi0vyqIsymKEh/gdb+EIdiwuyqIsymKkL3ENV7GJRxYTZVEWZTHSHZzCh7iEM3hqf1EWZVEWI01wEldxFpfwyP6iLMqiLP6HCTaxaXFRFmVR9hxr7UyvfehgBAAAAABJRU5ErkJg\"></td></tr></tbody></table><div><small>(a vector displayed as a row to save space)</small></div>"
      ],
      "text/plain": [
       "5-element Vector{Base.ReinterpretArray{Gray{N0f8}, 2, N0f8, Matrix{N0f8}, true}}:\n",
       " [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n",
       " [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n",
       " [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n",
       " [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n",
       " [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1×5 adjoint(::Vector{Int64}) with eltype Int64:\n",
       " 5  0  4  1  9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load mnist from MLDatasets\n",
    "trainX_original,      trainY_original      = MNIST.traindata()\n",
    "validationX_original, validationY_original = MNIST.testdata();\n",
    "\n",
    "display([MNIST.convert2image(MNIST.traintensor(i)) for i in 1:5])\n",
    "trainY_original[1:5]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f2acc6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28, 28, 42001), (28, 28, 17999), (28, 28, 10000))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split trainset, testset, validation set\n",
    "Random.seed!(1)\n",
    "(trainX, trainY), (testX, testY) = stratifiedobs((trainX_original, trainY_original), p = 0.7)\n",
    "validationX = copy(validationX_original); validationY = copy(validationY_original)\n",
    "\n",
    "size(trainX), size(testX), size(validationX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b9c3b0",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "Data preprocessing depends on the data source, thus can widely vary from what is shown here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f76c815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "function preprocessing(X, y)\n",
    "    newX = batchImage2DF(X)\n",
    "    #coerce!(newX)   # no need, all scitypes are Continuous in this example\n",
    "    new_y = coerce(y, OrderedFactor)\n",
    "    \n",
    "    return (newX, new_y)\n",
    "end\n",
    "\n",
    "X, y = preprocessing(trainX, trainY);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a82db1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Table{AbstractVector{Continuous}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scitype(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4724874c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AbstractVector{OrderedFactor{10}} (alias for AbstractArray{OrderedFactor{10}, 1})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scitype(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26954e9",
   "metadata": {},
   "source": [
    "## Training, Testing, Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb875eb7",
   "metadata": {},
   "source": [
    "### Load the algorithm"
   ]
  },
  {
   "cell_type": "raw",
   "id": "009c36ac",
   "metadata": {},
   "source": [
    "models(\"Neural\")[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da2ebd67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLJFlux.NeuralNetworkClassifier"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NeuralNetworkClassifier = @load NeuralNetworkClassifier pkg=MLJFlux verbosity=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9827ee",
   "metadata": {},
   "source": [
    "### Instantiate the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5a09f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetworkClassifier(\n",
       "    builder = Short(\n",
       "            n_hidden = 0,\n",
       "            dropout = 0.5,\n",
       "            σ = NNlib.σ),\n",
       "    finaliser = NNlib.softmax,\n",
       "    optimiser = Flux.Optimise.ADAM(0.001, (0.9, 0.999), 1.0e-8, IdDict{Any, Any}()),\n",
       "    loss = Flux.Losses.crossentropy,\n",
       "    epochs = 10,\n",
       "    batch_size = 1,\n",
       "    lambda = 0.0,\n",
       "    alpha = 0.0,\n",
       "    rng = Random._GLOBAL_RNG(),\n",
       "    optimiser_changes_trigger_retraining = false,\n",
       "    acceleration = CUDALibs{Nothing}(nothing))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetworkClassifier(acceleration=CUDALibs())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad11e62b",
   "metadata": {},
   "source": [
    "### Create and train the machine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f819d464",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training Machine{NeuralNetworkClassifier{Short,…},…}.\n",
      "└ @ MLJBase /home/ciro/.julia/packages/MLJBase/pCiRR/src/machines.jl:464\n",
      "┌ Error: Problem fitting the machine Machine{NeuralNetworkClassifier{Short,…},…}. \n",
      "└ @ MLJBase /home/ciro/.julia/packages/MLJBase/pCiRR/src/machines.jl:594\n",
      "┌ Info: Running type checks... \n",
      "└ @ MLJBase /home/ciro/.julia/packages/MLJBase/pCiRR/src/machines.jl:600\n",
      "┌ Info: Type checks okay. \n",
      "└ @ MLJBase /home/ciro/.julia/packages/MLJBase/pCiRR/src/machines.jl:603\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      "  [1] _zip_iterate_interleave",
      "    @ ./iterators.jl:380 [inlined]",
      "  [2] _zip_iterate_all",
      "    @ ./iterators.jl:364 [inlined]",
      "  [3] iterate",
      "    @ ./iterators.jl:351 [inlined]",
      "  [4] iterate",
      "    @ ./generator.jl:44 [inlined]",
      "  [5] collect_to!(dest::Vector{Any}, itr::Base.Generator{Base.Iterators.Zip{Tuple{Vector{ChainRulesCore.ProjectTo{AbstractArray, NamedTuple{(:element, :axes), Tuple{ChainRulesCore.ProjectTo{Float32, NamedTuple{(), Tuple{}}}, Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}}}}}}, Vector{Any}}}, Base.var\"#4#5\"{ChainRulesCore.var\"#58#59\"}}, offs::Int64, st::Tuple{Int64, Int64})",
      "    @ Base ./array.jl:728",
      "  [6] collect_to!(dest::Vector{ChainRulesCore.NoTangent}, itr::Base.Generator{Base.Iterators.Zip{Tuple{Vector{ChainRulesCore.ProjectTo{AbstractArray, NamedTuple{(:element, :axes), Tuple{ChainRulesCore.ProjectTo{Float32, NamedTuple{(), Tuple{}}}, Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}}}}}}, Vector{Any}}}, Base.var\"#4#5\"{ChainRulesCore.var\"#58#59\"}}, offs::Int64, st::Tuple{Int64, Int64})",
      "    @ Base ./array.jl:736",
      "  [7] collect_to_with_first!(dest::Vector{ChainRulesCore.NoTangent}, v1::ChainRulesCore.NoTangent, itr::Base.Generator{Base.Iterators.Zip{Tuple{Vector{ChainRulesCore.ProjectTo{AbstractArray, NamedTuple{(:element, :axes), Tuple{ChainRulesCore.ProjectTo{Float32, NamedTuple{(), Tuple{}}}, Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}}}}}}, Vector{Any}}}, Base.var\"#4#5\"{ChainRulesCore.var\"#58#59\"}}, st::Tuple{Int64, Int64})",
      "    @ Base ./array.jl:706",
      "  [8] collect(itr::Base.Generator{Base.Iterators.Zip{Tuple{Vector{ChainRulesCore.ProjectTo{AbstractArray, NamedTuple{(:element, :axes), Tuple{ChainRulesCore.ProjectTo{Float32, NamedTuple{(), Tuple{}}}, Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}}}}}}, Vector{Any}}}, Base.var\"#4#5\"{ChainRulesCore.var\"#58#59\"}})",
      "    @ Base ./array.jl:687",
      "  [9] map",
      "    @ ./abstractarray.jl:2383 [inlined]",
      " [10] (::ChainRulesCore.ProjectTo{AbstractArray, NamedTuple{(:elements, :axes), Tuple{Vector{ChainRulesCore.ProjectTo{AbstractArray, NamedTuple{(:element, :axes), Tuple{ChainRulesCore.ProjectTo{Float32, NamedTuple{(), Tuple{}}}, Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}}}}}}, Tuple{Base.OneTo{Int64}}}}})(dx::Vector{Any})",
      "    @ ChainRulesCore ~/.julia/packages/ChainRulesCore/uxrij/src/projection.jl:237",
      " [11] _project",
      "    @ ~/.julia/packages/Zygote/FPUm3/src/compiler/chainrules.jl:182 [inlined]",
      " [12] (::Zygote.var\"#428#430\"{1, CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, Vector{CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}, Tuple{Int64}})(dy::CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer})",
      "    @ Zygote ~/.julia/packages/Zygote/FPUm3/src/lib/array.jl:41",
      " [13] (::Zygote.var\"#2298#back#424\"{Zygote.var\"#428#430\"{1, CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, Vector{CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}, Tuple{Int64}}})(Δ::CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer})",
      "    @ Zygote ~/.julia/packages/ZygoteRules/AIbCs/src/adjoint.jl:67",
      " [14] Pullback",
      "    @ ~/.julia/packages/MLJFlux/ex3rh/src/core.jl:60 [inlined]",
      " [15] (::typeof(∂(λ)))(Δ::Float32)",
      "    @ Zygote ~/.julia/packages/Zygote/FPUm3/src/compiler/interface2.jl:0",
      " [16] (::Zygote.var\"#88#89\"{Zygote.Params, typeof(∂(λ)), Zygote.Context})(Δ::Float32)",
      "    @ Zygote ~/.julia/packages/Zygote/FPUm3/src/compiler/interface.jl:357",
      " [17] gradient(f::Function, args::Zygote.Params)",
      "    @ Zygote ~/.julia/packages/Zygote/FPUm3/src/compiler/interface.jl:76",
      " [18] train!(loss::typeof(Flux.Losses.crossentropy), penalty::MLJFlux.Penalty{MLJFlux.Penalizer{Nothing}}, chain::Flux.Chain{Tuple{Flux.Chain{Tuple{Flux.Dense{typeof(NNlib.σ), CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Flux.Dropout{Float64, Colon}, Flux.Dense{typeof(identity), CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}}}, typeof(NNlib.softmax)}}, optimiser::Flux.Optimise.ADAM, X::Vector{CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}, y::Vector{Flux.OneHotArray{UInt32, 10, 1, 2, CUDA.CuArray{UInt32, 1, CUDA.Mem.DeviceBuffer}}})",
      "    @ MLJFlux ~/.julia/packages/MLJFlux/ex3rh/src/core.jl:59",
      " [19] fit!(loss::typeof(Flux.Losses.crossentropy), penalty::MLJFlux.Penalty{MLJFlux.Penalizer{Nothing}}, chain::Flux.Chain{Tuple{Flux.Chain{Tuple{Flux.Dense{typeof(NNlib.σ), CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}, Flux.Dropout{Float64, Colon}, Flux.Dense{typeof(identity), CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, CUDA.CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}}}}, typeof(NNlib.softmax)}}, optimiser::Flux.Optimise.ADAM, epochs::Int64, verbosity::Int64, X::Vector{CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}, y::Vector{Flux.OneHotArray{UInt32, 10, 1, 2, CUDA.CuArray{UInt32, 1, CUDA.Mem.DeviceBuffer}}})",
      "    @ MLJFlux ~/.julia/packages/MLJFlux/ex3rh/src/core.jl:125",
      " [20] fit(model::MLJFlux.NeuralNetworkClassifier{MLJFlux.Short, typeof(NNlib.softmax), Flux.Optimise.ADAM, typeof(Flux.Losses.crossentropy)}, verbosity::Int64, X::DataFrame, y::CategoricalArrays.CategoricalVector{Int64, UInt32, Int64, CategoricalArrays.CategoricalValue{Int64, UInt32}, Union{}})",
      "    @ MLJFlux ~/.julia/packages/MLJFlux/ex3rh/src/mlj_model_interface.jl:60",
      " [21] fit_only!(mach::Machine{MLJFlux.NeuralNetworkClassifier{MLJFlux.Short, typeof(NNlib.softmax), Flux.Optimise.ADAM, typeof(Flux.Losses.crossentropy)}, true}; rows::Nothing, verbosity::Int64, force::Bool)",
      "    @ MLJBase ~/.julia/packages/MLJBase/pCiRR/src/machines.jl:592",
      " [22] fit_only!",
      "    @ ~/.julia/packages/MLJBase/pCiRR/src/machines.jl:545 [inlined]",
      " [23] #fit!#56",
      "    @ ~/.julia/packages/MLJBase/pCiRR/src/machines.jl:659 [inlined]",
      " [24] fit!",
      "    @ ~/.julia/packages/MLJBase/pCiRR/src/machines.jl:657 [inlined]",
      " [25] |>(x::Machine{MLJFlux.NeuralNetworkClassifier{MLJFlux.Short, typeof(NNlib.softmax), Flux.Optimise.ADAM, typeof(Flux.Losses.crossentropy)}, true}, f::typeof(fit!))",
      "    @ Base ./operators.jl:858",
      " [26] top-level scope",
      "    @ In[11]:2",
      " [27] eval",
      "    @ ./boot.jl:360 [inlined]",
      " [28] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "model.epochs=1   # computationally heavy model, leave it at 1\n",
    "mach = MLJ.machine(model, X, y) |> fit!;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30bb17d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: mach not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: mach not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[12]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "fitted_params(mach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "382dd5b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: mach not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: mach not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[13]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "report(mach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "942e853b",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: mach not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: mach not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[14]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "losses = report(mach)[1]\n",
    "epochs = model.epochs\n",
    "plot(0:epochs, losses, title=\"Error function\", size=(500,300), linewidth=2, legend=false)\n",
    "xlabel!(\"Epochs\")\n",
    "ylabel!(\"Cross-entropy loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c248ab3",
   "metadata": {},
   "source": [
    "### Predict the outcome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2545bb5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: mach not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: mach not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[15]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "ŷ = predict_mode(mach, X)\n",
    "ŷ[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0b75dbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: ŷ not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: ŷ not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[16]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "printMetrics(ŷ, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565ce406",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.5",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
