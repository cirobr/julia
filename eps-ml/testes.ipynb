{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca0f90b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "using Flux              # the julia ml library\n",
    "using Images            # image processing and machine vision for julia\n",
    "using MLJ               # make_blobs, rmse, confmat, categorical\n",
    "using MLDataUtils       # label, nlabel, labelfreq\n",
    "using MLDatasets        # mnist\n",
    "\n",
    "using GLM               # (lm works as regression; GLM not OK for categorical outcomes)\n",
    "using MLJLinearModels   # LogisticClassifier\n",
    "\n",
    "using LinearAlgebra     # pinv pseudo-inverse matrix\n",
    "using Metrics           # r2-score\n",
    "using Random\n",
    "using StatsBase         # standardize (normalization)\n",
    "using Distributions\n",
    "\n",
    "using Plots; gr()\n",
    "using StatsPlots\n",
    "using Printf\n",
    "\n",
    "using CSV\n",
    "using DataFrames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9fba548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186-element Vector{NamedTuple{(:name, :package_name, :is_supervised, :abstract_type, :deep_properties, :docstring, :fit_data_scitype, :hyperparameter_ranges, :hyperparameter_types, :hyperparameters, :implemented_methods, :inverse_transform_scitype, :is_pure_julia, :is_wrapper, :iteration_parameter, :load_path, :package_license, :package_url, :package_uuid, :predict_scitype, :prediction_type, :supports_class_weights, :supports_online, :supports_training_losses, :supports_weights, :transform_scitype, :input_scitype, :target_scitype, :output_scitype), T} where T<:Tuple}:\n",
       " (name = ABODDetector, package_name = OutlierDetectionNeighbors, ... )\n",
       " (name = ABODDetector, package_name = OutlierDetectionPython, ... )\n",
       " (name = AEDetector, package_name = OutlierDetectionNetworks, ... )\n",
       " (name = ARDRegressor, package_name = ScikitLearn, ... )\n",
       " (name = AdaBoostClassifier, package_name = ScikitLearn, ... )\n",
       " (name = AdaBoostRegressor, package_name = ScikitLearn, ... )\n",
       " (name = AdaBoostStumpClassifier, package_name = DecisionTree, ... )\n",
       " (name = AffinityPropagation, package_name = ScikitLearn, ... )\n",
       " (name = AgglomerativeClustering, package_name = ScikitLearn, ... )\n",
       " (name = BM25Transformer, package_name = MLJText, ... )\n",
       " (name = BagOfWordsTransformer, package_name = MLJText, ... )\n",
       " (name = BaggingClassifier, package_name = ScikitLearn, ... )\n",
       " (name = BaggingRegressor, package_name = ScikitLearn, ... )\n",
       " ⋮\n",
       " (name = SubspaceLDA, package_name = MultivariateStats, ... )\n",
       " (name = TSVDTransformer, package_name = TSVD, ... )\n",
       " (name = TfidfTransformer, package_name = MLJText, ... )\n",
       " (name = TheilSenRegressor, package_name = ScikitLearn, ... )\n",
       " (name = UnivariateBoxCoxTransformer, package_name = MLJModels, ... )\n",
       " (name = UnivariateDiscretizer, package_name = MLJModels, ... )\n",
       " (name = UnivariateFillImputer, package_name = MLJModels, ... )\n",
       " (name = UnivariateStandardizer, package_name = MLJModels, ... )\n",
       " (name = UnivariateTimeTypeToContinuous, package_name = MLJModels, ... )\n",
       " (name = XGBoostClassifier, package_name = XGBoost, ... )\n",
       " (name = XGBoostCount, package_name = XGBoost, ... )\n",
       " (name = XGBoostRegressor, package_name = XGBoost, ... )"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models = models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecb983f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: For silent loading, specify `verbosity=0`. \n",
      "└ @ Main /home/ciro/.julia/packages/MLJModels/Ci1zC/src/loading.jl:168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJLinearModels ✔\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticClassifier"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = @load LogisticClassifier pkg=\"MLJLinearModels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e226d35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1ml\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1mg\u001b[22m\u001b[0m\u001b[1m_\u001b[22m\u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1mu\u001b[22m\u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1mv\u001b[22m\u001b[0m\u001b[1me\u001b[22m \u001b[0m\u001b[1ml\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1mg\u001b[22m\u001b[0m\u001b[1m_\u001b[22m\u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1mu\u001b[22m\u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1mv\u001b[22m\u001b[0m\u001b[1me\u001b[22m!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "curve = learning_curve(mach; resolution=30,\n",
       "                             resampling=Holdout(),\n",
       "                             repeats=1,\n",
       "                             measure=default_measure(machine.model),\n",
       "                             rows=nothing,\n",
       "                             weights=nothing,\n",
       "                             operation=nothing,\n",
       "                             range=nothing,\n",
       "                             acceleration=default_resource(),\n",
       "                             acceleration_grid=CPU1(),\n",
       "                             rngs=nothing,\n",
       "                             rng_name=nothing)\n",
       "\\end{verbatim}\n",
       "Given a supervised machine \\texttt{mach}, returns a named tuple of objects suitable for generating a plot of performance estimates, as a function of the single hyperparameter specified in \\texttt{range}. The tuple \\texttt{curve} has the following keys: \\texttt{:parameter\\_name}, \\texttt{:parameter\\_scale}, \\texttt{:parameter\\_values}, \\texttt{:measurements}.\n",
       "\n",
       "To generate multiple curves for a \\texttt{model} with a random number generator (RNG) as a hyperparameter, specify the name, \\texttt{rng\\_name}, of the (possibly nested) RNG field, and a vector \\texttt{rngs} of RNG's, one for each curve. Alternatively, set \\texttt{rngs} to the number of curves desired, in which case RNG's are automatically generated. The individual curve computations can be distributed across multiple processes using \\texttt{acceleration=CPUProcesses()} or \\texttt{acceleration=CPUThreads()}. See the second example below for a demonstration.\n",
       "\n",
       "\\begin{verbatim}\n",
       "X, y = @load_boston;\n",
       "atom = @load RidgeRegressor pkg=MultivariateStats\n",
       "ensemble = EnsembleModel(atom=atom, n=1000)\n",
       "mach = machine(ensemble, X, y)\n",
       "r_lambda = range(ensemble, :(atom.lambda), lower=10, upper=500, scale=:log10)\n",
       "curve = learning_curve(mach; range=r_lambda, resampling=CV(), measure=mav)\n",
       "using Plots\n",
       "plot(curve.parameter_values,\n",
       "     curve.measurements,\n",
       "     xlab=curve.parameter_name,\n",
       "     xscale=curve.parameter_scale,\n",
       "     ylab = \"CV estimate of RMS error\")\n",
       "\\end{verbatim}\n",
       "If using a \\texttt{Holdout()} \\texttt{resampling} strategy (with no shuffling) and if the specified hyperparameter is the number of iterations in some iterative model (and that model has an appropriately overloaded \\texttt{MLJModelInterface.update} method) then training is not restarted from scratch for each increment of the parameter, ie the model is trained progressively.\n",
       "\n",
       "\\begin{verbatim}\n",
       "atom.lambda=200\n",
       "r_n = range(ensemble, :n, lower=1, upper=250)\n",
       "curves = learning_curve(mach; range=r_n, verbosity=0, rng_name=:rng, rngs=3)\n",
       "plot!(curves.parameter_values,\n",
       "     curves.measurements,\n",
       "     xlab=curves.parameter_name,\n",
       "     ylab=\"Holdout estimate of RMS error\")\n",
       "\n",
       "\n",
       "\\end{verbatim}\n",
       "\\begin{verbatim}\n",
       "learning_curve(model::Supervised, X, y; kwargs...)\n",
       "learning_curve(model::Supervised, X, y, w; kwargs...)\n",
       "\\end{verbatim}\n",
       "Plot a learning curve (or curves) directly, without first constructing a machine.\n",
       "\n",
       "\\subsubsection{Summary of key-word options}\n",
       "\\begin{itemize}\n",
       "\\item \\texttt{resolution} - number of points generated from \\texttt{range} (number model evaluations); default is \\texttt{30}\n",
       "\n",
       "\n",
       "\\item \\texttt{acceleration} - parallelization option for passing to \\texttt{evaluate!}; an instance of \\texttt{CPU1}, \\texttt{CPUProcesses} or \\texttt{CPUThreads} from the \\texttt{ComputationalResources.jl}; default is \\texttt{default\\_resource()}\n",
       "\n",
       "\n",
       "\\item \\texttt{acceleration\\_grid} - parallelization option for distributing each performancde evaluation\n",
       "\n",
       "\n",
       "\\item \\texttt{rngs} - for specifying random number generator(s) to be passed to the model (see above)\n",
       "\n",
       "\n",
       "\\item \\texttt{rng\\_name} - name of the model hyper-parameter representing a random number generator (see above); possibly nested\n",
       "\n",
       "\\end{itemize}\n",
       "Other key-word options are documented at \\href{@ref}{\\texttt{TunedModel}}.\n",
       "\n"
      ],
      "text/markdown": [
       "```\n",
       "curve = learning_curve(mach; resolution=30,\n",
       "                             resampling=Holdout(),\n",
       "                             repeats=1,\n",
       "                             measure=default_measure(machine.model),\n",
       "                             rows=nothing,\n",
       "                             weights=nothing,\n",
       "                             operation=nothing,\n",
       "                             range=nothing,\n",
       "                             acceleration=default_resource(),\n",
       "                             acceleration_grid=CPU1(),\n",
       "                             rngs=nothing,\n",
       "                             rng_name=nothing)\n",
       "```\n",
       "\n",
       "Given a supervised machine `mach`, returns a named tuple of objects suitable for generating a plot of performance estimates, as a function of the single hyperparameter specified in `range`. The tuple `curve` has the following keys: `:parameter_name`, `:parameter_scale`, `:parameter_values`, `:measurements`.\n",
       "\n",
       "To generate multiple curves for a `model` with a random number generator (RNG) as a hyperparameter, specify the name, `rng_name`, of the (possibly nested) RNG field, and a vector `rngs` of RNG's, one for each curve. Alternatively, set `rngs` to the number of curves desired, in which case RNG's are automatically generated. The individual curve computations can be distributed across multiple processes using `acceleration=CPUProcesses()` or `acceleration=CPUThreads()`. See the second example below for a demonstration.\n",
       "\n",
       "```julia\n",
       "X, y = @load_boston;\n",
       "atom = @load RidgeRegressor pkg=MultivariateStats\n",
       "ensemble = EnsembleModel(atom=atom, n=1000)\n",
       "mach = machine(ensemble, X, y)\n",
       "r_lambda = range(ensemble, :(atom.lambda), lower=10, upper=500, scale=:log10)\n",
       "curve = learning_curve(mach; range=r_lambda, resampling=CV(), measure=mav)\n",
       "using Plots\n",
       "plot(curve.parameter_values,\n",
       "     curve.measurements,\n",
       "     xlab=curve.parameter_name,\n",
       "     xscale=curve.parameter_scale,\n",
       "     ylab = \"CV estimate of RMS error\")\n",
       "```\n",
       "\n",
       "If using a `Holdout()` `resampling` strategy (with no shuffling) and if the specified hyperparameter is the number of iterations in some iterative model (and that model has an appropriately overloaded `MLJModelInterface.update` method) then training is not restarted from scratch for each increment of the parameter, ie the model is trained progressively.\n",
       "\n",
       "```julia\n",
       "atom.lambda=200\n",
       "r_n = range(ensemble, :n, lower=1, upper=250)\n",
       "curves = learning_curve(mach; range=r_n, verbosity=0, rng_name=:rng, rngs=3)\n",
       "plot!(curves.parameter_values,\n",
       "     curves.measurements,\n",
       "     xlab=curves.parameter_name,\n",
       "     ylab=\"Holdout estimate of RMS error\")\n",
       "\n",
       "\n",
       "```\n",
       "\n",
       "```\n",
       "learning_curve(model::Supervised, X, y; kwargs...)\n",
       "learning_curve(model::Supervised, X, y, w; kwargs...)\n",
       "```\n",
       "\n",
       "Plot a learning curve (or curves) directly, without first constructing a machine.\n",
       "\n",
       "### Summary of key-word options\n",
       "\n",
       "  * `resolution` - number of points generated from `range` (number model evaluations); default is `30`\n",
       "  * `acceleration` - parallelization option for passing to `evaluate!`; an instance of `CPU1`, `CPUProcesses` or `CPUThreads` from the `ComputationalResources.jl`; default is `default_resource()`\n",
       "  * `acceleration_grid` - parallelization option for distributing each performancde evaluation\n",
       "  * `rngs` - for specifying random number generator(s) to be passed to the model (see above)\n",
       "  * `rng_name` - name of the model hyper-parameter representing a random number generator (see above); possibly nested\n",
       "\n",
       "Other key-word options are documented at [`TunedModel`](@ref).\n"
      ],
      "text/plain": [
       "\u001b[36m  curve = learning_curve(mach; resolution=30,\u001b[39m\n",
       "\u001b[36m                               resampling=Holdout(),\u001b[39m\n",
       "\u001b[36m                               repeats=1,\u001b[39m\n",
       "\u001b[36m                               measure=default_measure(machine.model),\u001b[39m\n",
       "\u001b[36m                               rows=nothing,\u001b[39m\n",
       "\u001b[36m                               weights=nothing,\u001b[39m\n",
       "\u001b[36m                               operation=nothing,\u001b[39m\n",
       "\u001b[36m                               range=nothing,\u001b[39m\n",
       "\u001b[36m                               acceleration=default_resource(),\u001b[39m\n",
       "\u001b[36m                               acceleration_grid=CPU1(),\u001b[39m\n",
       "\u001b[36m                               rngs=nothing,\u001b[39m\n",
       "\u001b[36m                               rng_name=nothing)\u001b[39m\n",
       "\n",
       "  Given a supervised machine \u001b[36mmach\u001b[39m, returns a named tuple of objects suitable\n",
       "  for generating a plot of performance estimates, as a function of the single\n",
       "  hyperparameter specified in \u001b[36mrange\u001b[39m. The tuple \u001b[36mcurve\u001b[39m has the following keys:\n",
       "  \u001b[36m:parameter_name\u001b[39m, \u001b[36m:parameter_scale\u001b[39m, \u001b[36m:parameter_values\u001b[39m, \u001b[36m:measurements\u001b[39m.\n",
       "\n",
       "  To generate multiple curves for a \u001b[36mmodel\u001b[39m with a random number generator (RNG)\n",
       "  as a hyperparameter, specify the name, \u001b[36mrng_name\u001b[39m, of the (possibly nested)\n",
       "  RNG field, and a vector \u001b[36mrngs\u001b[39m of RNG's, one for each curve. Alternatively,\n",
       "  set \u001b[36mrngs\u001b[39m to the number of curves desired, in which case RNG's are\n",
       "  automatically generated. The individual curve computations can be\n",
       "  distributed across multiple processes using \u001b[36macceleration=CPUProcesses()\u001b[39m or\n",
       "  \u001b[36macceleration=CPUThreads()\u001b[39m. See the second example below for a demonstration.\n",
       "\n",
       "\u001b[36m  X, y = @load_boston;\u001b[39m\n",
       "\u001b[36m  atom = @load RidgeRegressor pkg=MultivariateStats\u001b[39m\n",
       "\u001b[36m  ensemble = EnsembleModel(atom=atom, n=1000)\u001b[39m\n",
       "\u001b[36m  mach = machine(ensemble, X, y)\u001b[39m\n",
       "\u001b[36m  r_lambda = range(ensemble, :(atom.lambda), lower=10, upper=500, scale=:log10)\u001b[39m\n",
       "\u001b[36m  curve = learning_curve(mach; range=r_lambda, resampling=CV(), measure=mav)\u001b[39m\n",
       "\u001b[36m  using Plots\u001b[39m\n",
       "\u001b[36m  plot(curve.parameter_values,\u001b[39m\n",
       "\u001b[36m       curve.measurements,\u001b[39m\n",
       "\u001b[36m       xlab=curve.parameter_name,\u001b[39m\n",
       "\u001b[36m       xscale=curve.parameter_scale,\u001b[39m\n",
       "\u001b[36m       ylab = \"CV estimate of RMS error\")\u001b[39m\n",
       "\n",
       "  If using a \u001b[36mHoldout()\u001b[39m \u001b[36mresampling\u001b[39m strategy (with no shuffling) and if the\n",
       "  specified hyperparameter is the number of iterations in some iterative model\n",
       "  (and that model has an appropriately overloaded \u001b[36mMLJModelInterface.update\u001b[39m\n",
       "  method) then training is not restarted from scratch for each increment of\n",
       "  the parameter, ie the model is trained progressively.\n",
       "\n",
       "\u001b[36m  atom.lambda=200\u001b[39m\n",
       "\u001b[36m  r_n = range(ensemble, :n, lower=1, upper=250)\u001b[39m\n",
       "\u001b[36m  curves = learning_curve(mach; range=r_n, verbosity=0, rng_name=:rng, rngs=3)\u001b[39m\n",
       "\u001b[36m  plot!(curves.parameter_values,\u001b[39m\n",
       "\u001b[36m       curves.measurements,\u001b[39m\n",
       "\u001b[36m       xlab=curves.parameter_name,\u001b[39m\n",
       "\u001b[36m       ylab=\"Holdout estimate of RMS error\")\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\n",
       "\u001b[36m  learning_curve(model::Supervised, X, y; kwargs...)\u001b[39m\n",
       "\u001b[36m  learning_curve(model::Supervised, X, y, w; kwargs...)\u001b[39m\n",
       "\n",
       "  Plot a learning curve (or curves) directly, without first constructing a\n",
       "  machine.\n",
       "\n",
       "\u001b[1m  Summary of key-word options\u001b[22m\n",
       "\u001b[1m  –––––––––––––––––––––––––––––\u001b[22m\n",
       "\n",
       "    •  \u001b[36mresolution\u001b[39m - number of points generated from \u001b[36mrange\u001b[39m (number model\n",
       "       evaluations); default is \u001b[36m30\u001b[39m\n",
       "\n",
       "    •  \u001b[36macceleration\u001b[39m - parallelization option for passing to \u001b[36mevaluate!\u001b[39m; an\n",
       "       instance of \u001b[36mCPU1\u001b[39m, \u001b[36mCPUProcesses\u001b[39m or \u001b[36mCPUThreads\u001b[39m from the\n",
       "       \u001b[36mComputationalResources.jl\u001b[39m; default is \u001b[36mdefault_resource()\u001b[39m\n",
       "\n",
       "    •  \u001b[36macceleration_grid\u001b[39m - parallelization option for distributing each\n",
       "       performancde evaluation\n",
       "\n",
       "    •  \u001b[36mrngs\u001b[39m - for specifying random number generator(s) to be passed to\n",
       "       the model (see above)\n",
       "\n",
       "    •  \u001b[36mrng_name\u001b[39m - name of the model hyper-parameter representing a random\n",
       "       number generator (see above); possibly nested\n",
       "\n",
       "  Other key-word options are documented at \u001b[36mTunedModel\u001b[39m."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b7cc540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mu\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1md\u001b[22m \u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mu\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1md\u001b[22ming \u001b[0m\u001b[1mR\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mu\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1md\u001b[22mUp \u001b[0m\u001b[1mR\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mu\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1md\u001b[22mDown \u001b[0m\u001b[1mR\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mu\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1md\u001b[22mToZero \u001b[0m\u001b[1mR\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mu\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1md\u001b[22mingMode \u001b[0m\u001b[1mR\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mu\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1md\u001b[22mNearest\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "round(z::Complex[, RoundingModeReal, [RoundingModeImaginary]])\n",
       "round(z::Complex[, RoundingModeReal, [RoundingModeImaginary]]; digits=, base=10)\n",
       "round(z::Complex[, RoundingModeReal, [RoundingModeImaginary]]; sigdigits=, base=10)\n",
       "\\end{verbatim}\n",
       "Return the nearest integral value of the same type as the complex-valued \\texttt{z} to \\texttt{z}, breaking ties using the specified \\href{@ref}{\\texttt{RoundingMode}}s. The first \\href{@ref}{\\texttt{RoundingMode}} is used for rounding the real components while the second is used for rounding the imaginary components.\n",
       "\n",
       "\\section{Example}\n",
       "\\begin{verbatim}\n",
       "julia> round(3.14 + 4.5im)\n",
       "3.0 + 4.0im\n",
       "\\end{verbatim}\n",
       "\\rule{\\textwidth}{1pt}\n",
       "\\begin{verbatim}\n",
       "round([T,] x, [r::RoundingMode])\n",
       "round(x, [r::RoundingMode]; digits::Integer=0, base = 10)\n",
       "round(x, [r::RoundingMode]; sigdigits::Integer, base = 10)\n",
       "\\end{verbatim}\n",
       "Rounds the number \\texttt{x}.\n",
       "\n",
       "Without keyword arguments, \\texttt{x} is rounded to an integer value, returning a value of type \\texttt{T}, or of the same type of \\texttt{x} if no \\texttt{T} is provided. An \\href{@ref}{\\texttt{InexactError}} will be thrown if the value is not representable by \\texttt{T}, similar to \\href{@ref}{\\texttt{convert}}.\n",
       "\n",
       "If the \\texttt{digits} keyword argument is provided, it rounds to the specified number of digits after the decimal place (or before if negative), in base \\texttt{base}.\n",
       "\n",
       "If the \\texttt{sigdigits} keyword argument is provided, it rounds to the specified number of significant digits, in base \\texttt{base}.\n",
       "\n",
       "The \\href{@ref}{\\texttt{RoundingMode}} \\texttt{r} controls the direction of the rounding; the default is \\href{@ref}{\\texttt{RoundNearest}}, which rounds to the nearest integer, with ties (fractional values of 0.5) being rounded to the nearest even integer. Note that \\texttt{round} may give incorrect results if the global rounding mode is changed (see \\href{@ref}{\\texttt{rounding}}).\n",
       "\n",
       "\\section{Examples}\n",
       "\\begin{verbatim}\n",
       "julia> round(1.7)\n",
       "2.0\n",
       "\n",
       "julia> round(Int, 1.7)\n",
       "2\n",
       "\n",
       "julia> round(1.5)\n",
       "2.0\n",
       "\n",
       "julia> round(2.5)\n",
       "2.0\n",
       "\n",
       "julia> round(pi; digits=2)\n",
       "3.14\n",
       "\n",
       "julia> round(pi; digits=3, base=2)\n",
       "3.125\n",
       "\n",
       "julia> round(123.456; sigdigits=2)\n",
       "120.0\n",
       "\n",
       "julia> round(357.913; sigdigits=4, base=2)\n",
       "352.0\n",
       "\\end{verbatim}\n",
       "\\begin{quote}\n",
       "\\textbf{note}\n",
       "\n",
       "Note\n",
       "\n",
       "Rounding to specified digits in bases other than 2 can be inexact when operating on binary floating point numbers. For example, the \\href{@ref}{\\texttt{Float64}} value represented by \\texttt{1.15} is actually \\emph{less} than 1.15, yet will be rounded to 1.2.\n",
       "\n",
       "\\section{Examples}\n",
       "\\begin{verbatim}\n",
       "julia> x = 1.15\n",
       "1.15\n",
       "\n",
       "julia> @sprintf \"%.20f\" x\n",
       "\"1.14999999999999991118\"\n",
       "\n",
       "julia> x < 115//100\n",
       "true\n",
       "\n",
       "julia> round(x, digits=1)\n",
       "1.2\n",
       "\\end{verbatim}\n",
       "\\end{quote}\n",
       "\\section{Extensions}\n",
       "To extend \\texttt{round} to new numeric types, it is typically sufficient to define \\texttt{Base.round(x::NewType, r::RoundingMode)}.\n",
       "\n",
       "\\rule{\\textwidth}{1pt}\n",
       "\\begin{verbatim}\n",
       "round(dt::TimeType, p::Period, [r::RoundingMode]) -> TimeType\n",
       "\\end{verbatim}\n",
       "Return the \\texttt{Date} or \\texttt{DateTime} nearest to \\texttt{dt} at resolution \\texttt{p}. By default (\\texttt{RoundNearestTiesUp}), ties (e.g., rounding 9:30 to the nearest hour) will be rounded up.\n",
       "\n",
       "For convenience, \\texttt{p} may be a type instead of a value: \\texttt{round(dt, Dates.Hour)} is a shortcut for \\texttt{round(dt, Dates.Hour(1))}.\n",
       "\n",
       "\\begin{verbatim}\n",
       "julia> round(Date(1985, 8, 16), Dates.Month)\n",
       "1985-08-01\n",
       "\n",
       "julia> round(DateTime(2013, 2, 13, 0, 31, 20), Dates.Minute(15))\n",
       "2013-02-13T00:30:00\n",
       "\n",
       "julia> round(DateTime(2016, 8, 6, 12, 0, 0), Dates.Day)\n",
       "2016-08-07T00:00:00\n",
       "\\end{verbatim}\n",
       "Valid rounding modes for \\texttt{round(::TimeType, ::Period, ::RoundingMode)} are \\texttt{RoundNearestTiesUp} (default), \\texttt{RoundDown} (\\texttt{floor}), and \\texttt{RoundUp} (\\texttt{ceil}).\n",
       "\n",
       "\\rule{\\textwidth}{1pt}\n",
       "\\begin{verbatim}\n",
       "round(x::Period, precision::T, [r::RoundingMode]) where T <: Union{TimePeriod, Week, Day} -> T\n",
       "\\end{verbatim}\n",
       "Round \\texttt{x} to the nearest multiple of \\texttt{precision}. If \\texttt{x} and \\texttt{precision} are different subtypes of \\texttt{Period}, the return value will have the same type as \\texttt{precision}. By default (\\texttt{RoundNearestTiesUp}), ties (e.g., rounding 90 minutes to the nearest hour) will be rounded up.\n",
       "\n",
       "For convenience, \\texttt{precision} may be a type instead of a value: \\texttt{round(x, Dates.Hour)} is a shortcut for \\texttt{round(x, Dates.Hour(1))}.\n",
       "\n",
       "\\begin{verbatim}\n",
       "julia> round(Dates.Day(16), Dates.Week)\n",
       "2 weeks\n",
       "\n",
       "julia> round(Dates.Minute(44), Dates.Minute(15))\n",
       "45 minutes\n",
       "\n",
       "julia> round(Dates.Hour(36), Dates.Day)\n",
       "2 days\n",
       "\\end{verbatim}\n",
       "Valid rounding modes for \\texttt{round(::Period, ::T, ::RoundingMode)} are \\texttt{RoundNearestTiesUp} (default), \\texttt{RoundDown} (\\texttt{floor}), and \\texttt{RoundUp} (\\texttt{ceil}).\n",
       "\n",
       "Rounding to a \\texttt{precision} of \\texttt{Month}s or \\texttt{Year}s is not supported, as these \\texttt{Period}s are of inconsistent length.\n",
       "\n"
      ],
      "text/markdown": [
       "```\n",
       "round(z::Complex[, RoundingModeReal, [RoundingModeImaginary]])\n",
       "round(z::Complex[, RoundingModeReal, [RoundingModeImaginary]]; digits=, base=10)\n",
       "round(z::Complex[, RoundingModeReal, [RoundingModeImaginary]]; sigdigits=, base=10)\n",
       "```\n",
       "\n",
       "Return the nearest integral value of the same type as the complex-valued `z` to `z`, breaking ties using the specified [`RoundingMode`](@ref)s. The first [`RoundingMode`](@ref) is used for rounding the real components while the second is used for rounding the imaginary components.\n",
       "\n",
       "# Example\n",
       "\n",
       "```jldoctest\n",
       "julia> round(3.14 + 4.5im)\n",
       "3.0 + 4.0im\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "```\n",
       "round([T,] x, [r::RoundingMode])\n",
       "round(x, [r::RoundingMode]; digits::Integer=0, base = 10)\n",
       "round(x, [r::RoundingMode]; sigdigits::Integer, base = 10)\n",
       "```\n",
       "\n",
       "Rounds the number `x`.\n",
       "\n",
       "Without keyword arguments, `x` is rounded to an integer value, returning a value of type `T`, or of the same type of `x` if no `T` is provided. An [`InexactError`](@ref) will be thrown if the value is not representable by `T`, similar to [`convert`](@ref).\n",
       "\n",
       "If the `digits` keyword argument is provided, it rounds to the specified number of digits after the decimal place (or before if negative), in base `base`.\n",
       "\n",
       "If the `sigdigits` keyword argument is provided, it rounds to the specified number of significant digits, in base `base`.\n",
       "\n",
       "The [`RoundingMode`](@ref) `r` controls the direction of the rounding; the default is [`RoundNearest`](@ref), which rounds to the nearest integer, with ties (fractional values of 0.5) being rounded to the nearest even integer. Note that `round` may give incorrect results if the global rounding mode is changed (see [`rounding`](@ref)).\n",
       "\n",
       "# Examples\n",
       "\n",
       "```jldoctest\n",
       "julia> round(1.7)\n",
       "2.0\n",
       "\n",
       "julia> round(Int, 1.7)\n",
       "2\n",
       "\n",
       "julia> round(1.5)\n",
       "2.0\n",
       "\n",
       "julia> round(2.5)\n",
       "2.0\n",
       "\n",
       "julia> round(pi; digits=2)\n",
       "3.14\n",
       "\n",
       "julia> round(pi; digits=3, base=2)\n",
       "3.125\n",
       "\n",
       "julia> round(123.456; sigdigits=2)\n",
       "120.0\n",
       "\n",
       "julia> round(357.913; sigdigits=4, base=2)\n",
       "352.0\n",
       "```\n",
       "\n",
       "!!! note\n",
       "    Rounding to specified digits in bases other than 2 can be inexact when operating on binary floating point numbers. For example, the [`Float64`](@ref) value represented by `1.15` is actually *less* than 1.15, yet will be rounded to 1.2.\n",
       "\n",
       "    # Examples\n",
       "\n",
       "    ```jldoctest; setup = :(using Printf)\n",
       "    julia> x = 1.15\n",
       "    1.15\n",
       "\n",
       "    julia> @sprintf \"%.20f\" x\n",
       "    \"1.14999999999999991118\"\n",
       "\n",
       "    julia> x < 115//100\n",
       "    true\n",
       "\n",
       "    julia> round(x, digits=1)\n",
       "    1.2\n",
       "    ```\n",
       "\n",
       "\n",
       "# Extensions\n",
       "\n",
       "To extend `round` to new numeric types, it is typically sufficient to define `Base.round(x::NewType, r::RoundingMode)`.\n",
       "\n",
       "---\n",
       "\n",
       "```\n",
       "round(dt::TimeType, p::Period, [r::RoundingMode]) -> TimeType\n",
       "```\n",
       "\n",
       "Return the `Date` or `DateTime` nearest to `dt` at resolution `p`. By default (`RoundNearestTiesUp`), ties (e.g., rounding 9:30 to the nearest hour) will be rounded up.\n",
       "\n",
       "For convenience, `p` may be a type instead of a value: `round(dt, Dates.Hour)` is a shortcut for `round(dt, Dates.Hour(1))`.\n",
       "\n",
       "```jldoctest\n",
       "julia> round(Date(1985, 8, 16), Dates.Month)\n",
       "1985-08-01\n",
       "\n",
       "julia> round(DateTime(2013, 2, 13, 0, 31, 20), Dates.Minute(15))\n",
       "2013-02-13T00:30:00\n",
       "\n",
       "julia> round(DateTime(2016, 8, 6, 12, 0, 0), Dates.Day)\n",
       "2016-08-07T00:00:00\n",
       "```\n",
       "\n",
       "Valid rounding modes for `round(::TimeType, ::Period, ::RoundingMode)` are `RoundNearestTiesUp` (default), `RoundDown` (`floor`), and `RoundUp` (`ceil`).\n",
       "\n",
       "---\n",
       "\n",
       "```\n",
       "round(x::Period, precision::T, [r::RoundingMode]) where T <: Union{TimePeriod, Week, Day} -> T\n",
       "```\n",
       "\n",
       "Round `x` to the nearest multiple of `precision`. If `x` and `precision` are different subtypes of `Period`, the return value will have the same type as `precision`. By default (`RoundNearestTiesUp`), ties (e.g., rounding 90 minutes to the nearest hour) will be rounded up.\n",
       "\n",
       "For convenience, `precision` may be a type instead of a value: `round(x, Dates.Hour)` is a shortcut for `round(x, Dates.Hour(1))`.\n",
       "\n",
       "```jldoctest\n",
       "julia> round(Dates.Day(16), Dates.Week)\n",
       "2 weeks\n",
       "\n",
       "julia> round(Dates.Minute(44), Dates.Minute(15))\n",
       "45 minutes\n",
       "\n",
       "julia> round(Dates.Hour(36), Dates.Day)\n",
       "2 days\n",
       "```\n",
       "\n",
       "Valid rounding modes for `round(::Period, ::T, ::RoundingMode)` are `RoundNearestTiesUp` (default), `RoundDown` (`floor`), and `RoundUp` (`ceil`).\n",
       "\n",
       "Rounding to a `precision` of `Month`s or `Year`s is not supported, as these `Period`s are of inconsistent length.\n"
      ],
      "text/plain": [
       "\u001b[36m  round(z::Complex[, RoundingModeReal, [RoundingModeImaginary]])\u001b[39m\n",
       "\u001b[36m  round(z::Complex[, RoundingModeReal, [RoundingModeImaginary]]; digits=, base=10)\u001b[39m\n",
       "\u001b[36m  round(z::Complex[, RoundingModeReal, [RoundingModeImaginary]]; sigdigits=, base=10)\u001b[39m\n",
       "\n",
       "  Return the nearest integral value of the same type as the complex-valued \u001b[36mz\u001b[39m\n",
       "  to \u001b[36mz\u001b[39m, breaking ties using the specified \u001b[36mRoundingMode\u001b[39ms. The first\n",
       "  \u001b[36mRoundingMode\u001b[39m is used for rounding the real components while the second is\n",
       "  used for rounding the imaginary components.\n",
       "\n",
       "\u001b[1m  Example\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "\u001b[36m  julia> round(3.14 + 4.5im)\u001b[39m\n",
       "\u001b[36m  3.0 + 4.0im\u001b[39m\n",
       "\n",
       "  ────────────────────────────────────────────────────────────────────────────\n",
       "\n",
       "\u001b[36m  round([T,] x, [r::RoundingMode])\u001b[39m\n",
       "\u001b[36m  round(x, [r::RoundingMode]; digits::Integer=0, base = 10)\u001b[39m\n",
       "\u001b[36m  round(x, [r::RoundingMode]; sigdigits::Integer, base = 10)\u001b[39m\n",
       "\n",
       "  Rounds the number \u001b[36mx\u001b[39m.\n",
       "\n",
       "  Without keyword arguments, \u001b[36mx\u001b[39m is rounded to an integer value, returning a\n",
       "  value of type \u001b[36mT\u001b[39m, or of the same type of \u001b[36mx\u001b[39m if no \u001b[36mT\u001b[39m is provided. An\n",
       "  \u001b[36mInexactError\u001b[39m will be thrown if the value is not representable by \u001b[36mT\u001b[39m, similar\n",
       "  to \u001b[36mconvert\u001b[39m.\n",
       "\n",
       "  If the \u001b[36mdigits\u001b[39m keyword argument is provided, it rounds to the specified\n",
       "  number of digits after the decimal place (or before if negative), in base\n",
       "  \u001b[36mbase\u001b[39m.\n",
       "\n",
       "  If the \u001b[36msigdigits\u001b[39m keyword argument is provided, it rounds to the specified\n",
       "  number of significant digits, in base \u001b[36mbase\u001b[39m.\n",
       "\n",
       "  The \u001b[36mRoundingMode\u001b[39m \u001b[36mr\u001b[39m controls the direction of the rounding; the default is\n",
       "  \u001b[36mRoundNearest\u001b[39m, which rounds to the nearest integer, with ties (fractional\n",
       "  values of 0.5) being rounded to the nearest even integer. Note that \u001b[36mround\u001b[39m\n",
       "  may give incorrect results if the global rounding mode is changed (see\n",
       "  \u001b[36mrounding\u001b[39m).\n",
       "\n",
       "\u001b[1m  Examples\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "\u001b[36m  julia> round(1.7)\u001b[39m\n",
       "\u001b[36m  2.0\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> round(Int, 1.7)\u001b[39m\n",
       "\u001b[36m  2\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> round(1.5)\u001b[39m\n",
       "\u001b[36m  2.0\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> round(2.5)\u001b[39m\n",
       "\u001b[36m  2.0\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> round(pi; digits=2)\u001b[39m\n",
       "\u001b[36m  3.14\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> round(pi; digits=3, base=2)\u001b[39m\n",
       "\u001b[36m  3.125\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> round(123.456; sigdigits=2)\u001b[39m\n",
       "\u001b[36m  120.0\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> round(357.913; sigdigits=4, base=2)\u001b[39m\n",
       "\u001b[36m  352.0\u001b[39m\n",
       "\n",
       "\u001b[36m\u001b[1m  │ \u001b[22m\u001b[39m\u001b[36m\u001b[1mNote\u001b[22m\u001b[39m\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m  Rounding to specified digits in bases other than 2 can be inexact\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m  when operating on binary floating point numbers. For example, the\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m  \u001b[36mFloat64\u001b[39m value represented by \u001b[36m1.15\u001b[39m is actually \u001b[4mless\u001b[24m than 1.15, yet\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m  will be rounded to 1.2.\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m\u001b[1m  Examples\u001b[22m\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m\u001b[1m  ≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m\u001b[36m  julia> x = 1.15\u001b[39m\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m\u001b[36m  1.15\u001b[39m\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m\u001b[36m  \u001b[39m\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m\u001b[36m  julia> @sprintf \"%.20f\" x\u001b[39m\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m\u001b[36m  \"1.14999999999999991118\"\u001b[39m\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m\u001b[36m  \u001b[39m\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m\u001b[36m  julia> x < 115//100\u001b[39m\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m\u001b[36m  true\u001b[39m\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m\u001b[36m  \u001b[39m\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m\u001b[36m  julia> round(x, digits=1)\u001b[39m\n",
       "\u001b[36m\u001b[1m  │\u001b[22m\u001b[39m\u001b[36m  1.2\u001b[39m\n",
       "\n",
       "\u001b[1m  Extensions\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "  To extend \u001b[36mround\u001b[39m to new numeric types, it is typically sufficient to define\n",
       "  \u001b[36mBase.round(x::NewType, r::RoundingMode)\u001b[39m.\n",
       "\n",
       "  ────────────────────────────────────────────────────────────────────────────\n",
       "\n",
       "\u001b[36m  round(dt::TimeType, p::Period, [r::RoundingMode]) -> TimeType\u001b[39m\n",
       "\n",
       "  Return the \u001b[36mDate\u001b[39m or \u001b[36mDateTime\u001b[39m nearest to \u001b[36mdt\u001b[39m at resolution \u001b[36mp\u001b[39m. By default\n",
       "  (\u001b[36mRoundNearestTiesUp\u001b[39m), ties (e.g., rounding 9:30 to the nearest hour) will be\n",
       "  rounded up.\n",
       "\n",
       "  For convenience, \u001b[36mp\u001b[39m may be a type instead of a value: \u001b[36mround(dt, Dates.Hour)\u001b[39m\n",
       "  is a shortcut for \u001b[36mround(dt, Dates.Hour(1))\u001b[39m.\n",
       "\n",
       "\u001b[36m  julia> round(Date(1985, 8, 16), Dates.Month)\u001b[39m\n",
       "\u001b[36m  1985-08-01\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> round(DateTime(2013, 2, 13, 0, 31, 20), Dates.Minute(15))\u001b[39m\n",
       "\u001b[36m  2013-02-13T00:30:00\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> round(DateTime(2016, 8, 6, 12, 0, 0), Dates.Day)\u001b[39m\n",
       "\u001b[36m  2016-08-07T00:00:00\u001b[39m\n",
       "\n",
       "  Valid rounding modes for \u001b[36mround(::TimeType, ::Period, ::RoundingMode)\u001b[39m are\n",
       "  \u001b[36mRoundNearestTiesUp\u001b[39m (default), \u001b[36mRoundDown\u001b[39m (\u001b[36mfloor\u001b[39m), and \u001b[36mRoundUp\u001b[39m (\u001b[36mceil\u001b[39m).\n",
       "\n",
       "  ────────────────────────────────────────────────────────────────────────────\n",
       "\n",
       "\u001b[36m  round(x::Period, precision::T, [r::RoundingMode]) where T <: Union{TimePeriod, Week, Day} -> T\u001b[39m\n",
       "\n",
       "  Round \u001b[36mx\u001b[39m to the nearest multiple of \u001b[36mprecision\u001b[39m. If \u001b[36mx\u001b[39m and \u001b[36mprecision\u001b[39m are\n",
       "  different subtypes of \u001b[36mPeriod\u001b[39m, the return value will have the same type as\n",
       "  \u001b[36mprecision\u001b[39m. By default (\u001b[36mRoundNearestTiesUp\u001b[39m), ties (e.g., rounding 90 minutes\n",
       "  to the nearest hour) will be rounded up.\n",
       "\n",
       "  For convenience, \u001b[36mprecision\u001b[39m may be a type instead of a value: \u001b[36mround(x,\n",
       "  Dates.Hour)\u001b[39m is a shortcut for \u001b[36mround(x, Dates.Hour(1))\u001b[39m.\n",
       "\n",
       "\u001b[36m  julia> round(Dates.Day(16), Dates.Week)\u001b[39m\n",
       "\u001b[36m  2 weeks\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> round(Dates.Minute(44), Dates.Minute(15))\u001b[39m\n",
       "\u001b[36m  45 minutes\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> round(Dates.Hour(36), Dates.Day)\u001b[39m\n",
       "\u001b[36m  2 days\u001b[39m\n",
       "\n",
       "  Valid rounding modes for \u001b[36mround(::Period, ::T, ::RoundingMode)\u001b[39m are\n",
       "  \u001b[36mRoundNearestTiesUp\u001b[39m (default), \u001b[36mRoundDown\u001b[39m (\u001b[36mfloor\u001b[39m), and \u001b[36mRoundUp\u001b[39m (\u001b[36mceil\u001b[39m).\n",
       "\n",
       "  Rounding to a \u001b[36mprecision\u001b[39m of \u001b[36mMonth\u001b[39ms or \u001b[36mYear\u001b[39ms is not supported, as these\n",
       "  \u001b[36mPeriod\u001b[39ms are of inconsistent length."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?round"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.5",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
