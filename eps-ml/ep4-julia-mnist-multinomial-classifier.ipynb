{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b439f11d",
   "metadata": {},
   "source": [
    "# Multinomial classification with MNIST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f262ba3",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d63e87f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "#using Flux              # the julia ml library\n",
    "using Images            # image processing and machine vision for julia\n",
    "using MLJ               # make_blobs, rmse, confmat, f1score, coerce\n",
    "using MLDataUtils       # label, nlabel, labelfreq\n",
    "using MLDatasets        # mnist\n",
    "\n",
    "#using LinearAlgebra     # pinv pseudo-inverse matrix\n",
    "#using Metrics           # r2-score\n",
    "using Random\n",
    "using StatsBase         # standardize (normalization)\n",
    "#using Distributions\n",
    "\n",
    "using Plots; gr()\n",
    "#using StatsPlots\n",
    "using Printf\n",
    "\n",
    "#using CSV\n",
    "using DataFrames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53a09fe",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d5df2025",
   "metadata": {},
   "source": [
    "# feature extraction\n",
    "meanIntensity(img) = mean(Float64.(img))\n",
    "\n",
    "function hSymmetry(img)\n",
    "    imgFloat = Float64.(img)\n",
    "    imgReverse = reverse(imgFloat, dims=1)\n",
    "    return -mean( abs.(imgFloat - imgReverse) )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66ccdfa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "printMetrics (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metrics\n",
    "function printMetrics(ŷ, y)\n",
    "    display(confmat(ŷ, y))\n",
    "    println(\"accuracy: \", round(accuracy(ŷ, y); digits=3))\n",
    "    println(\"f1-score: \", round(f1score(ŷ, y);  digits=3))\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53255360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "batchImage2DF (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lib functions\n",
    "image2Vector(M) = vec(Float64.(M))\n",
    "\n",
    "function batchImage2Vector(imagesArray3D)\n",
    "    h, v, N = size(imagesArray3D)\n",
    "    vectorOfImageVectors = [ image2Vector( imagesArray3D[:, :, i] ) for i in 1:N]\n",
    "end\n",
    "\n",
    "function batchImage2DF(imagesArray3D)\n",
    "    vectorOfImageVectors = batchImage2Vector(imagesArray3D)\n",
    "    M = reduce(hcat, vectorOfImageVectors)\n",
    "    DataFrame(M', :auto)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d069ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8903cf71",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bd90da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tbody><tr><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAiVJREFUaAW9wT2IFgQABuAHemnI4aJFISgJwkDIIiqIsMLcajiKIEEIshosmgSHhhoUIW/IcIgCISHa+psKsp8hEKSSSAlyECon61Q+jMDT4RuO7w6/n5Pe54myKIuyKIuyKIuyKIuyKIuyKIuyKIuyKIuyKIuyKIsZ3YQ5y17FLdiE3TiI5/EvDuAto6IsyqIsJrgDN+MRPIpb8YzV/sAhzOMSTuI7q0VZlEVZjHE/vsac8ZbwBgb4CH/hH/xmtSiLsiiLMc7iPOasdhyLeAL/4ajpRFmURVmM8Tf24Cn8hEOGfsZ2DLAZr5telEVZlMUEn+IYLmELXsQCBoZ+xcumF2VRFmUxhYuGLhjahY+xZHZRFmVRFjN4Ew/gMTyJr8wuyqIsymIGA7yEH/E+vsEJHMZV04myKIuymNEZvIAj2ImdWIcPcc5kURZlURZr8Al+xwK2YT/uxD78abwoi7IoizX6Bc/haRzBK7gb240XZVEWZXEDFnEUHyDYisfxreuLsiiLslije/EsHkQMncL3xouyKIuymNEmvIZ5bLDsCs5hyXhRFmVRFlPagB3YjY1GncA+fG6yKIuyKIsJ1mMz3sU9Rh3H2/gMS6YTZVEWZXEdt+E93Ie7jPoBC/gSl80myqIsymKFh7EHD+F2oy7jHezHwNpEWZRFWawwj3nLTuMLXMFBLLoxURZlURYr7MVe/58oi7Ioi7Ioi7Ioi7Ioi7IouwZsVVgTmd3ynQAAAABJRU5ErkJg\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAjJJREFUaAW9wT1oHAQABtB3+mGISDN0sIK46SaGFEUnxbEVFTtIkWYVRCgoAYcomRzUDlYQBREUhTo4WCwihcKB0EGtOneTQkAtgu1ih5zDDRlyf0nley/KoizKoizKoizKoizKoizKoizKoizKoixuw1G8inV8jg9wxWxRFmVRFge0ios4hBFO4VkcNluURVmUxQE8hq+xghFu4BYO4wn8jFsmi7Ioi7LYh7uxhi9wn11X8Q7O4Qe8ibdNFmVRFmWxDx/jpL3WcA+GeAoPmy7KoizKYkFHcRwDY0N8i3exjV/wN57GwHRRFmVRFgtYxUUcwgjf4SSexCY+wZ/4DTs4jjVcsVeURVmUxRwPYQMr+Avb+Aw3cQEX7LWM1/GSvaIsyqIsZljCeziGG1jHT1g23wMmi7Ioi7KYYQ3HjD2HodsXZVEWZTHDGQwwxNBi7sAOBiaLsiiLspjiGaxihPMWt4MRfjVZlEVZlMUUy7gLf+Ar8y1hy9glvGGyKIuyKIs5/sW22ZawiQ1cwxncNFmURVmUxRznzbaKDbyIb3DCbFEWZVEWUwwwwPM4bbLXsIkVfIl180VZlEVZTDHCCEdwFp/iOh7HKTyC+/E7vseHFhNlURZlMcedeAUn8A8etOsyLuEti4uyKIuymOIyfsSjxo7gXmPXcQ6n7V+URVmUxRTX8AJexqZd7+MjXHUwURZlURYzbGMLW/4/URZlURZlURZlURZlURZlURZlURZlUfYfqPxYlL4fzGQAAAAASUVORK5C\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAbVJREFUaAW9wT2rDQAABuDnnN6UhSLdlNQdbrZrMjCgbkl2E9kY/ASrSfkBBukOjMJkMJkQRvJRihhsSpFSDGdw7nHP/Tid3ueJsiiLsiiLsiiLsiiLsiiLsiiLsiiLsiiLsiiLsiiLOVvBHZzAW/+LsiiLsphwHHtxz2yO4IXpoizKoiwmnMQS7tm+IRZxEAPri7Ioi7KYcAFPzGY/LuI23lhflEVZlMWEodndNPLedFEWZVEWY5axYHa7jTwyXZRFWZTFmDPYaTYLWDTyxXRRFmVRFmMOGXll+65jAe/w3XRRFmVRFut4bmt24TTO45SRq/hmuiiLsiiLdeyx1mEMsYID2IFzGOInnuEXgpc2FmVRFmUx5if+4Aau+GcZA/zGD7zGLbzAY3zFZ+zEGxuLsiiLshhzGR9xzFqf8ACv8dT/LmEfPthclEVZlMWEa7Zvxchdm4uyKIuymKP7NhdlURZlURZlURZlMScDLOGJjUVZlEVZzMkfDG0uyqIsymKOjmLVxqIsyqIs5mRga6IsyqIs5uAhztqaKIuyKIs5WMWqrYmyKIuyKIuyKIuyKIuyKIuyv/irMYSJ7ydGAAAAAElFTkSuQmCC\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAYtJREFUaAW9waFqVQEABuCP8YNRRUFM7glkDzDQoGIw+AYbdpugYcUgDEwiy4p9wSooCjLwDWYRDIJrCibD1XDCLc577rmX//uiLMqiLMqiLMqiLMqiLMqiLMqiLMqiLMqiLMqiLMpiTfbwGBu4jg/+LcqiLMpiDXbxCDODP04XZVEWZbEGV3DGOFEWZVEWK7qB+wbHuIMTp4uyKIuyWME2XuKswVN89X9RFmVRFivYwWWD93hlsSiLsiiLiS7iHmb4gSfGibIoi7KYYBOH5p7jnXGiLMqiLCa4jasGb/HMeFEWZVEWS7qLfYOP2MFP40VZlEVZLGETh+a+4MRyoizKoiyW8BAzc/uWF2VRFmUx0hZumXuNz5YXZVEWZTHSG5w3+IRd00RZlEVZjHQBM4MD/DJNlEVZlMUIL7Bh7sh0URZlURYLbOEmZviNA5yYLsqiLMpigXO4ZPAND6wmyqIsyqIsyqIsymKBYxxh23pEWZRFWSzwHdesT5RFWZRFWZRFWZRFWZRFWZT9BXYjLFSLepVZAAAAAElFTkSuQmCC\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAAgY0hSTQAAeiYAAICEAAD6AAAAgOgAAHUwAADqYAAAOpgAABdwnLpRPAAAAf5JREFUaAW9wT+I1QUAB/DPxRf7Q4PEXeDikG22STRlS1xbOHkOOTganFMQooSgNtTU0pJDosEhIogtR0uUi9AmuES1iMtFxAMJHO45/IYb5L177xd8P58oi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7Ioi7JY0ns4jeM4avAZnuB93MADs0VZlEVZLGED32AVK/gZa/jaYAWrOGW2KIuyKIsFBO/iO7yGX3AZ9/EybmHd4DfzRVmURVks4BNcM/gJG5gYbGDd4DGumy/KoizKYh9XcB5TfIuLmNhzwZ5z2DFflEVZlMUcX+A8nmEbn+M/g1ewjsNYwRXctb8oi7IoixkO4lNMsY0T9ryNH3DM4Da+spgoi7IoixkOYNXgHN7EGXyMd/A6ppjiJp5aTJRFWZTFDM+wgzX8hak9TzDBIfyNexYXZVEWZTHDvziBH/EG/sBdfI9/sIVD2LKcKIuyKIs5HmDNi47jA+ziT8uJsiiLshjhVexiii3LibIoi7IYYdt4URZlURYjfGS8KIuyKIsRjhgvyqIsymKEX/ESdi0vyqIsymKEh/gdb+EIdiwuyqIsymKkL3ENV7GJRxYTZVEWZTHSHZzCh7iEM3hqf1EWZVEWI01wEldxFpfwyP6iLMqiLP6HCTaxaXFRFmVR9hxr7UyvfehgBAAAAABJRU5ErkJg\"></td></tr></tbody></table><div><small>(a vector displayed as a row to save space)</small></div>"
      ],
      "text/plain": [
       "5-element Vector{Base.ReinterpretArray{Gray{N0f8}, 2, N0f8, Matrix{N0f8}, true}}:\n",
       " [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n",
       " [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n",
       " [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n",
       " [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n",
       " [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1×5 adjoint(::Vector{Int64}) with eltype Int64:\n",
       " 5  0  4  1  9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load mnist from MLDatasets\n",
    "trainX_original,      trainY_original      = MNIST.traindata()\n",
    "validationX_original, validationY_original = MNIST.testdata();\n",
    "\n",
    "display([MNIST.convert2image(MNIST.traintensor(i)) for i in 1:5])\n",
    "trainY_original[1:5]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f2acc6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28, 28, 42001), (28, 28, 17999), (28, 28, 10000))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split trainset, testset, validation set\n",
    "Random.seed!(1)\n",
    "(trainX, trainY), (testX, testY) = stratifiedobs((trainX_original, trainY_original), p = 0.7)\n",
    "validationX = copy(validationX_original); validationY = copy(validationY_original)\n",
    "\n",
    "size(trainX), size(testX), size(validationX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b9c3b0",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "Data preprocessing depends on the data source, thus can widely vary from what is shown here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f76c815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "function preprocessing(X, y)\n",
    "    newX = batchImage2DF(X)\n",
    "    #coerce!(newX)   # no need, all scitypes are Continuous in this example\n",
    "    \n",
    "    new_y = coerce(y, OrderedFactor)\n",
    "    \n",
    "    return (newX, new_y)\n",
    "end\n",
    "\n",
    "X, y = preprocessing(trainX, trainY);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a82db1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Table{AbstractVector{Continuous}}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scitype(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4724874c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AbstractVector{OrderedFactor{10}} (alias for AbstractArray{OrderedFactor{10}, 1})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scitype(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26954e9",
   "metadata": {},
   "source": [
    "## Training, Testing, Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb875eb7",
   "metadata": {},
   "source": [
    "### Load the algorithm"
   ]
  },
  {
   "cell_type": "raw",
   "id": "658c10e1",
   "metadata": {},
   "source": [
    "models(\"multinomial\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "da2ebd67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLJLinearModels.MultinomialClassifier"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultinomialClassifier = @load MultinomialClassifier pkg=MLJLinearModels verbosity=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9827ee",
   "metadata": {},
   "source": [
    "### Instantiate the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f5a09f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialClassifier(\n",
       "    lambda = 1.0,\n",
       "    gamma = 0.0,\n",
       "    penalty = :l2,\n",
       "    fit_intercept = true,\n",
       "    penalize_intercept = false,\n",
       "    scale_penalty_with_samples = true,\n",
       "    solver = nothing)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad11e62b",
   "metadata": {},
   "source": [
    "### Creates a machine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f819d464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Machine{MultinomialClassifier,…} trained 0 times; caches data\n",
       "  model: MLJLinearModels.MultinomialClassifier\n",
       "  args: \n",
       "    1:\tSource @983 ⏎ `Table{AbstractVector{Continuous}}`\n",
       "    2:\tSource @597 ⏎ `AbstractVector{OrderedFactor{10}}`\n"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mach = MLJ.machine(model, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b248fb7",
   "metadata": {},
   "source": [
    "### Train the machine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "54941db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training Machine{MultinomialClassifier,…}.\n",
      "└ @ MLJBase /home/ciro/.julia/packages/MLJBase/CglMw/src/machines.jl:464\n",
      "┌ Error: Problem fitting the machine Machine{MultinomialClassifier,…}. \n",
      "└ @ MLJBase /home/ciro/.julia/packages/MLJBase/CglMw/src/machines.jl:594\n",
      "┌ Info: Running type checks... \n",
      "└ @ MLJBase /home/ciro/.julia/packages/MLJBase/CglMw/src/machines.jl:600\n",
      "┌ Info: Type checks okay. \n",
      "└ @ MLJBase /home/ciro/.julia/packages/MLJBase/CglMw/src/machines.jl:603\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      "  [1] reduced_indices(inds::Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}}, d::Int64)",
      "    @ Base ./reducedim.jl:20",
      "  [2] reduced_indices",
      "    @ ./reducedim.jl:15 [inlined]",
      "  [3] reducedim_initarray(A::Matrix{Float64}, region::Int64, init::Float64, #unused#::Type{Float64})",
      "    @ Base ./reducedim.jl:92",
      "  [4] reducedim_initarray",
      "    @ ./reducedim.jl:93 [inlined]",
      "  [5] reducedim_init",
      "    @ ./reducedim.jl:172 [inlined]",
      "  [6] _mapreduce_dim",
      "    @ ./reducedim.jl:324 [inlined]",
      "  [7] #mapreduce#672",
      "    @ ./reducedim.jl:310 [inlined]",
      "  [8] #_sum#702",
      "    @ ./reducedim.jl:900 [inlined]",
      "  [9] _sum",
      "    @ ./reducedim.jl:900 [inlined]",
      " [10] #_sum#701",
      "    @ ./reducedim.jl:899 [inlined]",
      " [11] _sum",
      "    @ ./reducedim.jl:899 [inlined]",
      " [12] #sum#679",
      "    @ ./reducedim.jl:873 [inlined]",
      " [13] (::MLJLinearModels.var\"#102#103\"{MLJLinearModels.GeneralizedLinearRegression{MLJLinearModels.MultinomialLoss{10}, MLJLinearModels.ScaledPenalty{MLJLinearModels.L2Penalty}}, Matrix{Float64}, Vector{Int64}, NamedTuple{(:n, :n2, :n3, :p, :dims, :nc, :nc2, :nc3, :nc4, :pc), Tuple{Vector{Float64}, Vector{Float64}, Vector{Float64}, Vector{Float64}, Tuple{Int64, Int64, Int64}, Matrix{Float64}, Matrix{Float64}, Matrix{Float64}, Matrix{Float64}, Matrix{Float64}}}, Float64, Int64, Int64, Int64})(f::Float64, g::Vector{Float64}, θ::Vector{Float64})",
      "    @ MLJLinearModels ~/.julia/packages/MLJLinearModels/oDTrS/src/glr/d_logistic.jl:166",
      " [14] (::NLSolversBase.var\"#69#70\"{NLSolversBase.InplaceObjective{Nothing, MLJLinearModels.var\"#102#103\"{MLJLinearModels.GeneralizedLinearRegression{MLJLinearModels.MultinomialLoss{10}, MLJLinearModels.ScaledPenalty{MLJLinearModels.L2Penalty}}, Matrix{Float64}, Vector{Int64}, NamedTuple{(:n, :n2, :n3, :p, :dims, :nc, :nc2, :nc3, :nc4, :pc), Tuple{Vector{Float64}, Vector{Float64}, Vector{Float64}, Vector{Float64}, Tuple{Int64, Int64, Int64}, Matrix{Float64}, Matrix{Float64}, Matrix{Float64}, Matrix{Float64}, Matrix{Float64}}}, Float64, Int64, Int64, Int64}, Nothing, Nothing, Nothing}, Float64})(G::Vector{Float64}, x::Vector{Float64})",
      "    @ NLSolversBase ~/.julia/packages/NLSolversBase/cfJrN/src/objective_types/incomplete.jl:54",
      " [15] value_gradient!!(obj::NLSolversBase.OnceDifferentiable{Float64, Vector{Float64}, Vector{Float64}}, x::Vector{Float64})",
      "    @ NLSolversBase ~/.julia/packages/NLSolversBase/cfJrN/src/interface.jl:82",
      " [16] value_gradient!(obj::NLSolversBase.OnceDifferentiable{Float64, Vector{Float64}, Vector{Float64}}, x::Vector{Float64})",
      "    @ NLSolversBase ~/.julia/packages/NLSolversBase/cfJrN/src/interface.jl:69",
      " [17] update_g!(d::NLSolversBase.OnceDifferentiable{Float64, Vector{Float64}, Vector{Float64}}, state::Optim.LBFGSState{Vector{Float64}, Vector{Vector{Float64}}, Vector{Vector{Float64}}, Float64, Vector{Float64}}, method::Optim.LBFGS{Nothing, LineSearches.InitialStatic{Float64}, LineSearches.HagerZhang{Float64, Base.RefValue{Bool}}, Optim.var\"#17#19\"})",
      "    @ Optim ~/.julia/packages/Optim/DmCp2/src/multivariate/optimize/optimize.jl:4",
      " [18] optimize(d::NLSolversBase.OnceDifferentiable{Float64, Vector{Float64}, Vector{Float64}}, initial_x::Vector{Float64}, method::Optim.LBFGS{Nothing, LineSearches.InitialStatic{Float64}, LineSearches.HagerZhang{Float64, Base.RefValue{Bool}}, Optim.var\"#17#19\"}, options::Optim.Options{Float64, Nothing}, state::Optim.LBFGSState{Vector{Float64}, Vector{Vector{Float64}}, Vector{Vector{Float64}}, Float64, Vector{Float64}})",
      "    @ Optim ~/.julia/packages/Optim/DmCp2/src/multivariate/optimize/optimize.jl:59",
      " [19] optimize",
      "    @ ~/.julia/packages/Optim/DmCp2/src/multivariate/optimize/optimize.jl:36 [inlined]",
      " [20] optimize(f::NLSolversBase.InplaceObjective{Nothing, MLJLinearModels.var\"#102#103\"{MLJLinearModels.GeneralizedLinearRegression{MLJLinearModels.MultinomialLoss{10}, MLJLinearModels.ScaledPenalty{MLJLinearModels.L2Penalty}}, Matrix{Float64}, Vector{Int64}, NamedTuple{(:n, :n2, :n3, :p, :dims, :nc, :nc2, :nc3, :nc4, :pc), Tuple{Vector{Float64}, Vector{Float64}, Vector{Float64}, Vector{Float64}, Tuple{Int64, Int64, Int64}, Matrix{Float64}, Matrix{Float64}, Matrix{Float64}, Matrix{Float64}, Matrix{Float64}}}, Float64, Int64, Int64, Int64}, Nothing, Nothing, Nothing}, initial_x::Vector{Float64}, method::Optim.LBFGS{Nothing, LineSearches.InitialStatic{Float64}, LineSearches.HagerZhang{Float64, Base.RefValue{Bool}}, Optim.var\"#17#19\"}, options::Optim.Options{Float64, Nothing}; inplace::Bool, autodiff::Symbol)",
      "    @ Optim ~/.julia/packages/Optim/DmCp2/src/multivariate/optimize/interface.jl:142",
      " [21] optimize(f::NLSolversBase.InplaceObjective{Nothing, MLJLinearModels.var\"#102#103\"{MLJLinearModels.GeneralizedLinearRegression{MLJLinearModels.MultinomialLoss{10}, MLJLinearModels.ScaledPenalty{MLJLinearModels.L2Penalty}}, Matrix{Float64}, Vector{Int64}, NamedTuple{(:n, :n2, :n3, :p, :dims, :nc, :nc2, :nc3, :nc4, :pc), Tuple{Vector{Float64}, Vector{Float64}, Vector{Float64}, Vector{Float64}, Tuple{Int64, Int64, Int64}, Matrix{Float64}, Matrix{Float64}, Matrix{Float64}, Matrix{Float64}, Matrix{Float64}}}, Float64, Int64, Int64, Int64}, Nothing, Nothing, Nothing}, initial_x::Vector{Float64}, method::Optim.LBFGS{Nothing, LineSearches.InitialStatic{Float64}, LineSearches.HagerZhang{Float64, Base.RefValue{Bool}}, Optim.var\"#17#19\"}, options::Optim.Options{Float64, Nothing}) (repeats 2 times)",
      "    @ Optim ~/.julia/packages/Optim/DmCp2/src/multivariate/optimize/interface.jl:141",
      " [22] _fit(glr::MLJLinearModels.GeneralizedLinearRegression{MLJLinearModels.MultinomialLoss{10}, MLJLinearModels.ScaledPenalty{MLJLinearModels.L2Penalty}}, solver::MLJLinearModels.LBFGS, X::Matrix{Float64}, y::Vector{Int64}, scratch::NamedTuple{(:n, :n2, :n3, :p, :dims, :nc, :nc2, :nc3, :nc4, :pc), Tuple{Vector{Float64}, Vector{Float64}, Vector{Float64}, Vector{Float64}, Tuple{Int64, Int64, Int64}, Matrix{Float64}, Matrix{Float64}, Matrix{Float64}, Matrix{Float64}, Matrix{Float64}}})",
      "    @ MLJLinearModels ~/.julia/packages/MLJLinearModels/oDTrS/src/fit/newton.jl:114",
      " [23] fit(glr::MLJLinearModels.GeneralizedLinearRegression{MLJLinearModels.MultinomialLoss{10}, MLJLinearModels.ScaledPenalty{MLJLinearModels.L2Penalty}}, X::Matrix{Float64}, y::Vector{Int64}; solver::MLJLinearModels.LBFGS)",
      "    @ MLJLinearModels ~/.julia/packages/MLJLinearModels/oDTrS/src/fit/default.jl:41",
      " [24] fit(m::MLJLinearModels.MultinomialClassifier, verb::Int64, X::DataFrame, y::CategoricalArrays.CategoricalVector{Int64, UInt32, Int64, CategoricalArrays.CategoricalValue{Int64, UInt32}, Union{}})",
      "    @ MLJLinearModels ~/.julia/packages/MLJLinearModels/oDTrS/src/mlj/interface.jl:76",
      " [25] fit_only!(mach::Machine{MLJLinearModels.MultinomialClassifier, true}; rows::Nothing, verbosity::Int64, force::Bool)",
      "    @ MLJBase ~/.julia/packages/MLJBase/CglMw/src/machines.jl:592",
      " [26] #fit!#56",
      "    @ ~/.julia/packages/MLJBase/CglMw/src/machines.jl:659 [inlined]",
      " [27] top-level scope",
      "    @ In[63]:1",
      " [28] eval",
      "    @ ./boot.jl:360 [inlined]",
      " [29] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "fit!(mach,\n",
    "    #acceleration = CPUThreads(),   # https://alan-turing-institute.github.io/MLJ.jl/v0.7/acceleration_and_parallelism/\n",
    "    verbosity=1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "950aed0e",
   "metadata": {},
   "source": [
    "fitted_params(mach)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "099eb041",
   "metadata": {},
   "source": [
    "report(mach)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c248ab3",
   "metadata": {},
   "source": [
    "### Predict an outcome\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4a7a9036",
   "metadata": {},
   "source": [
    "ŷ = predict_mode(mach, X)\n",
    "ŷ[1:5]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a77d23d0",
   "metadata": {},
   "source": [
    "printMetrics(ŷ, trainYLog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00479bba",
   "metadata": {},
   "source": [
    "### Tune the hyper-parameters\n",
    "\n",
    "When this particular model was instantiated above, one can see that the hyper-parameter \"Lambda\" could be of relevance to improve the model. Let's tune it as an attempt to minimize the cross-entropy loss and maximize accuracy.\n",
    "\n",
    "First, we define the parameter and limits to scan:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "717910db",
   "metadata": {},
   "source": [
    "r = range(model, :lambda, lower = 1e-5, upper=1e-1, scale = :log10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76392a4",
   "metadata": {},
   "source": [
    "Then, we define a 10-fold cross-validation, and capture the range parameter(lambdas) and the cross-entropy losses vectors (losses). The first two parameters of the tuple out of the function \"learning_curve\" are not relevent for this example, so are ignored:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d9dfe0f2",
   "metadata": {},
   "source": [
    "_, _, lambdas, losses = learning_curve(mach,\n",
    "                                        range=r,\n",
    "                                        resampling=CV(nfolds=10),\n",
    "                                        resolution=100,                 # default 30\n",
    "                                        measure=cross_entropy,\n",
    "                                        acceleration=CPUProcesses());   # useful if more than one parameter is plot"
   ]
  },
  {
   "cell_type": "raw",
   "id": "174778cc",
   "metadata": {},
   "source": [
    "plot(lambdas, losses, title=\"Error function\", size=(500,300), linewidth=2, legend=false)\n",
    "xlabel!(\"Lambda\")\n",
    "ylabel!(\"Cross-entropy loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fddc3a8",
   "metadata": {},
   "source": [
    "As seen on the chart above, the best tuning parameter is:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ec92bd91",
   "metadata": {},
   "source": [
    "best_lambda = lambdas[argmin(losses)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9771b6c9",
   "metadata": {},
   "source": [
    "### Retrain with best tuning parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c71f7c",
   "metadata": {},
   "source": [
    "(in progress)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "624bd2e7",
   "metadata": {},
   "source": [
    "model.lambda = best_lambda\n",
    "fit!(mach,\n",
    "    verbosity=2);"
   ]
  },
  {
   "cell_type": "raw",
   "id": "52e10b20",
   "metadata": {},
   "source": [
    "ŷ = predict_mode(mach, trainXLog)\n",
    "printMetrics(ŷ, trainYLog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae20b9b9",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a597269f",
   "metadata": {},
   "source": [
    "(in progress)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "958f5851",
   "metadata": {},
   "source": [
    "MLJ.evaluate!(mach,\n",
    "    resampling=CV(nfolds=10),\n",
    "    measures=[f1score])\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "660d000a",
   "metadata": {},
   "source": [
    "fitted_params(mach)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4ba7e7b0",
   "metadata": {},
   "source": [
    "ŷ = predict_mode(mach, trainXLog)\n",
    "printMetrics(ŷ, trainYLog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41338dc",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adec86d6",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.5",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
