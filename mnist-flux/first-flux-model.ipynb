{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cb0422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dd3481a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ground_truth (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the ground truth model. We aim to recover W_truth and b_truth using\n",
    "# only examples of ground_truth()\n",
    "W_truth = [1 2 3 4 5;\n",
    "            5 4 3 2 1]\n",
    "b_truth = [-1.0; -2.0]\n",
    "ground_truth(x) = W_truth*x .+ b_truth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "448db08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000-element Array{Array{Float64,1},1}:\n",
       " [39.61470621403595, 36.22959169851687]\n",
       " [28.842448719113847, 38.572599435845056]\n",
       " [44.80968384230517, 42.185497816984004]\n",
       " [18.11746012175172, 22.826898700765945]\n",
       " [37.34357597095279, 18.916770967113916]\n",
       " [27.687534755486656, 35.51214067327718]\n",
       " [50.52802675625742, 43.2374810740802]\n",
       " [54.23887708484592, 39.34279247372555]\n",
       " [46.77378201450665, 51.5727525403774]\n",
       " [27.71335142873436, 34.56992492861688]\n",
       " [26.300719059686635, 40.134461562510914]\n",
       " [42.17710742283444, 29.356967432931842]\n",
       " [50.97572802935713, 38.8974692172143]\n",
       " ⋮\n",
       " [54.45534562794151, 45.31003945786663]\n",
       " [42.26053729878432, 50.228027178796644]\n",
       " [19.403389701273927, 33.43017915554205]\n",
       " [31.419433853379164, 28.4018406306899]\n",
       " [18.594656072655635, 24.559108795551516]\n",
       " [40.69594747612888, 26.969366783539808]\n",
       " [60.527818811179685, 54.74429852828056]\n",
       " [33.70977247596811, 34.00922324134338]\n",
       " [41.51396493090932, 41.53055187235174]\n",
       " [42.739357247283955, 37.05740005879266]\n",
       " [35.19686442694343, 33.77514435834113]\n",
       " [42.446184071486115, 35.532373275734024]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the ground truth training data as vectors-of-vectors\n",
    "x_train = [ 5 .* rand(5) for _ in 1:10_000 ]\n",
    "y_train = [ ground_truth(x) + 0.2 .* randn(2) for x in x_train ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53e01cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       " 0.08096345461855958\n",
       " 0.246453838055549"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define and initialize the model we want to train\n",
    "model(x) = W*x .+ b\n",
    "W = rand(2, 5)\n",
    "b = rand(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "118a823c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Params([[0.023013439119377255 0.41860686166169825 … 0.12137833153660904 0.31795034957306556; 0.14567448642356906 0.9757304093269719 … 0.7817161245532789 0.40551961018622285], [0.08096345461855958, 0.246453838055549]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define pieces we need to train: loss function, optimiser, examples, and params\n",
    "function loss(x, y)\n",
    "  ŷ = model(x)\n",
    "  sum((y .- ŷ).^2)\n",
    "end\n",
    "opt = Descent(0.01)\n",
    "train_data = zip(x_train, y_train)\n",
    "ps = params(W, b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "110e1b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute a training epoch\n",
    "for (x,y) in train_data\n",
    "  gs = gradient(ps) do\n",
    "    loss(x,y)\n",
    "  end\n",
    "  Flux.Optimise.update!(opt, ps, gs)\n",
    "end\n",
    "\n",
    "# An alternate way to execute a training epoch\n",
    "# Flux.train!(loss, params(W, b), train_data, opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad283221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W = [1.0039272525417395 2.0183115180248015 2.941126976896121 4.030915179864688 4.98815849693528; 5.019364869074857 4.043524527306904 3.000079284736376 1.9797907937455017 1.0015700006582988]\n",
      "maximum(abs, W .- W_truth) = 0.058873023103878985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.058873023103878985"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out how well we did\n",
    "@show W\n",
    "@show maximum(abs, W .- W_truth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
