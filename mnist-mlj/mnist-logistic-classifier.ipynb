{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b439f11d",
   "metadata": {},
   "source": [
    "### Logistic classification with MNIST\n",
    "\n",
    "(two predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f262ba3",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b12a07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLDatasets           # mnist\n",
    "using Images\n",
    "using PreprocessingImages; pim = PreprocessingImages\n",
    "using PreprocessingArrays; pa  = PreprocessingArrays\n",
    "\n",
    "using MLJ                  # make_blobs, rmse, confmat, categorical\n",
    "using MLDataUtils          # label, nlabel, labelfreq\n",
    "using GLM\n",
    "\n",
    "using Metrics              # r2-score\n",
    "using Random\n",
    "using Plots; gr()\n",
    "using StatsPlots\n",
    "using DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53a09fe",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ccdfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\n",
    "function printMetrics(ŷ, y)\n",
    "    display(confmat(ŷ, y))\n",
    "    println(\"accuracy: \", round(accuracy(ŷ, y); digits=3))\n",
    "    println(\"f1-score: \", round(f1score(ŷ, y);  digits=3))\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8903cf71",
   "metadata": {},
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7603a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mnist\n",
    "datasetX,    datasetY    = MNIST(:train)[:]\n",
    "validationX, validationY = MNIST(:test)[:]\n",
    "\n",
    "display( size(datasetX) )\n",
    "\n",
    "img  = datasetX[:, :, 1:5]\n",
    "img2 = permutedims(img, (2, 1, 3))\n",
    "\n",
    "display(datasetY[1:5]')\n",
    "mosaicview( Gray.(img2)  ; nrow=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecbb1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split trainset, testset from dataset\n",
    "Random.seed!(1)\n",
    "(trainX, trainY), (testX, testY) = stratifiedobs((datasetX, datasetY), p = 0.7)\n",
    "size(trainX), size(testX), size(validationX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b9c3b0",
   "metadata": {},
   "source": [
    "#### Preprocessing\n",
    "Data preprocessing depends on the data source, thus can widely vary from what is shown here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b80259f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select classes for prediction\n",
    "c = (1, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217d4aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction\n",
    "meanIntensity(img) = mean(Float64.(img))\n",
    "\n",
    "function hSymmetry(img)\n",
    "    imgFloat = Float32.(img)\n",
    "    imgReverse = reverse(imgFloat, dims=1)\n",
    "    return -mean( abs.(imgFloat - imgReverse) )\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4602b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "function preprocess(X, y)\n",
    "    # process X\n",
    "    Xs = pim.batchImage2Vector( Float32.(X) )\n",
    "\n",
    "    # data selection from chosen classes\n",
    "    Xs = vcat( Xs[y .== c[1] ], Xs[ y .== c[2] ] )\n",
    "    ys = vcat(  y[y .== c[1] ],  y[ y .== c[2] ] )\n",
    "\n",
    "    # extract parameters from X\n",
    "    N = size(Xs)[1]\n",
    "    x1 = [meanIntensity(Xs[i]) for i in 1:N]\n",
    "    x2 = [hSymmetry(Xs[i])     for i in 1:N]\n",
    "    Xs = hcat(x1, x2)\n",
    "    Xs = pa.rescaleByColumns( Float32.(Xs) )\n",
    "    \n",
    "    # formatting for MLJ\n",
    "    Xs = DataFrame(Xs, :auto)\n",
    "    ys = coerce(ys, OrderedFactor)\n",
    "    \n",
    "    return (Xs, ys)\n",
    "end\n",
    "\n",
    "\n",
    "trainXLog, trainYLog = preprocess(trainX, trainY)\n",
    "size(trainXLog), size(trainYLog), levels(trainYLog)'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26954e9",
   "metadata": {},
   "source": [
    "### Training, Testing, Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb875eb7",
   "metadata": {},
   "source": [
    "#### Load the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88839a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticClassifier = @load LogisticClassifier pkg=MLJLinearModels verbosity=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9827ee",
   "metadata": {},
   "source": [
    "#### Instantiate the model\n",
    "\n",
    "In the context of MLJ, \"model\" means just a container for hyper-parameters.\n",
    "\n",
    "It is worth to note the output of the below command line, which is a list of the actual values assigned for each hyper-parameters, including the default ones. This information can be useful, for exemple, for tuning the parameter at a later stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2e528b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b80462",
   "metadata": {},
   "outputs": [],
   "source": [
    "info(LogisticClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad11e62b",
   "metadata": {},
   "source": [
    "#### Creates a machine\n",
    "\n",
    "In MLJ, \"machine\" means an object with all learning parameters (i.e. hyper-parameters + trainset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac360eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mach = MLJ.machine(model, trainXLog, trainYLog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b248fb7",
   "metadata": {},
   "source": [
    "#### Train the machine\n",
    "\n",
    "The machine (or model) is trained according to the programmed hyper-parameters and dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f545d603",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit!(mach,\n",
    "    # acceleration = CPUThreads(),   # https://alan-turing-institute.github.io/MLJ.jl/v0.7/acceleration_and_parallelism/\n",
    "    verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ed512e",
   "metadata": {},
   "source": [
    "After training, one can inspect the learning parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75147513",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_params(mach)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da0347c",
   "metadata": {},
   "source": [
    "Everything else the developer might be interested in, if any, can be accesses from the training report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa670359",
   "metadata": {},
   "outputs": [],
   "source": [
    "report(mach)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c248ab3",
   "metadata": {},
   "source": [
    "#### Predict an outcome\n",
    "\n",
    "The trained machine/model, stored in the object created for that purpose, is now used to predict the outcome for the trainset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d929faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = MLJ.predict(mach, trainXLog);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d9e558",
   "metadata": {},
   "source": [
    "We can inspect a few rows of the prediction, then just a single row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e149e3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(p[1:5])\n",
    "p[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f980bed",
   "metadata": {},
   "source": [
    "For this particular model, the prediction is represented as probabilities for each of the classes. To translate that as the most likely class, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e709471",
   "metadata": {},
   "outputs": [],
   "source": [
    "ŷ = predict_mode(mach, trainXLog)\n",
    "ŷ[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a55afab",
   "metadata": {},
   "source": [
    "We can also extract relevant metrics as in the below example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526a13d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "printMetrics(ŷ, trainYLog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00479bba",
   "metadata": {},
   "source": [
    "#### Tune a single hyper-parameter\n",
    "\n",
    "When this particular model was instantiated above, one can see that the hyper-parameter \"Lambda\" could be of relevance to improve the model. Let's tune it as an attempt to minimize the cross-entropy loss and maximize accuracy.\n",
    "\n",
    "First, we define the parameter and limits to scan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aca7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = range(model, :lambda, lower = 1e-5, upper=1e-1, scale = :log10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76392a4",
   "metadata": {},
   "source": [
    "Then, we define a 10-fold cross-validation, and capture the range parameter(lambdas) and the cross-entropy losses vectors (losses). The first two parameters of the tuple out of the function \"learning_curve\" are not relevent for this example, so are ignored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e2511a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, lambdas, losses = learning_curve(mach,\n",
    "                                        range=r,\n",
    "                                        resampling=CV(nfolds=10),\n",
    "                                        resolution=100,                 # default 30\n",
    "                                        measure=cross_entropy,\n",
    "                                        acceleration=CPUProcesses());   # useful if more than one parameter is plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ce1ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(lambdas, losses, title=\"Error function\", size=(500,300), linewidth=2, legend=false)\n",
    "xlabel!(\"Lambda\")\n",
    "ylabel!(\"Cross-entropy loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fddc3a8",
   "metadata": {},
   "source": [
    "As seen on the chart above, the best tuning parameter is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e7a40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lambda = lambdas[argmin(losses)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9771b6c9",
   "metadata": {},
   "source": [
    "#### Retrain with best tuning parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad33182",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.lambda = best_lambda\n",
    "fit!(mach,\n",
    "    verbosity=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9747c65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ŷ = predict_mode(mach, trainXLog)\n",
    "printMetrics(ŷ, trainYLog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae20b9b9",
   "metadata": {},
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a597269f",
   "metadata": {},
   "source": [
    "(in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b033362f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLJ.evaluate!(mach,\n",
    "    resampling=CV(nfolds=10),\n",
    "    measures=[f1score])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1615552b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_params(mach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f2485a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ŷ = predict_mode(mach, trainXLog)\n",
    "printMetrics(ŷ, trainYLog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41338dc",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d999abef",
   "metadata": {},
   "outputs": [],
   "source": [
    "testXLog, testYLog = preprocess(testX, testY)\n",
    "\n",
    "ŷ = predict_mode(mach, testXLog)\n",
    "printMetrics(ŷ, testYLog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adec86d6",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9e76ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "validationXLog, validationYLog = preprocess(validationX, validationY)\n",
    "\n",
    "ŷ = predict_mode(mach, validationXLog)\n",
    "printMetrics(ŷ, validationYLog)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.6",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
