{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "341a23e0",
   "metadata": {},
   "source": [
    "### ep2-julia: linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc64e40",
   "metadata": {},
   "source": [
    "### Linear regression\n",
    "\n",
    "Given a dataset $\\{(\\mathbf{x}^{(1)}, y^{(1)}), \\dots ,(\\mathbf{x}^{(N)}, y^{(N)})\\}$ with $\\mathbf{x}^{(i)} \\in \\mathbb{R}^{d}$ and $y^{(i)} \\in \\mathbb{R}$, we would like to approximate the unknown function $f:\\mathbb{R}^{d} \\rightarrow \\mathbb{R}$ (recall that $y^{(i)} =f(\\mathbf{x}^{(i)})$) by means of a linear model $h$:\n",
    "$$\n",
    "h(\\mathbf{x}^{(i)}; \\mathbf{w}, b) = \\mathbf{w}^\\top  \\mathbf{x}^{(i)} + b\n",
    "$$\n",
    "\n",
    "Note that $h(\\mathbf{x}^{(i)}; \\mathbf{w}, b)$ is, in fact, an  [affine transformation](https://en.wikipedia.org/wiki/Affine_transformation) of  $\\mathbf{x}^{(i)}$. As commonly done, we will use the term \"linear\" to refer to an affine transformation.\n",
    "\n",
    "The output of $h$ is a linear transformation of $\\mathbf{x}^{(i)}$. We use the notation $h(\\mathbf{x}^{(i)}; \\mathbf{w}, b)$ to make clear that $h$ is a parametric model, i.e., the transformation $h$ is defined  by the parameters $\\mathbf{w}$ and $b$. We can view vector $\\mathbf{w}$ as a *weight* vector that controls the effect of each *feature* in the prediction.\n",
    "\n",
    "By adding one component with value equal to 1 to the observations $\\mathbf{x}$ (an artificial coordinate), we have:\n",
    "\n",
    "$$\\tilde{\\mathbf{x}} = (1, x_1, \\ldots, x_d) \\in \\mathbb{R}^{1+d}$$\n",
    "\n",
    "and then we can simplify the notation:\n",
    "$$\n",
    "h(\\mathbf{x}^{(i)}; \\mathbf{w}) = \\hat{y}^{(i)} = \\mathbf{w}^\\top  \\tilde{\\mathbf{x}}^{(i)}\n",
    "$$\n",
    "\n",
    "We would like to determine the optimal parameters $\\mathbf{w}$ such that prediction $\\hat{y}^{(i)}$ is as closest as possible to $y^{(i)}$ according to some error metric. Adopting the *mean square error* as such metric we have the following cost function:\n",
    "\n",
    "\\begin{equation}\n",
    "J(\\mathbf{w}) = \\frac{1}{N}\\sum_{i=1}^{N}\\big(\\hat{y}^{(i)} - y^{(i)}\\big)^{2}\n",
    "\\end{equation}\n",
    "\n",
    "Thus, the task of determining a function $h$ that is closest to $f$ is reduced to the task of finding the values $\\mathbf{w}$ that minimize $J(\\mathbf{w})$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34157304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "using LinearAlgebra    # pinv pseudo-inverse matrix\n",
    "using Metrics          # r2-score\n",
    "using Random\n",
    "using Distributions\n",
    "using Plots; gr()\n",
    "using Printf\n",
    "\n",
    "using CSV\n",
    "using DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116ce23c",
   "metadata": {},
   "source": [
    "### code d = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6d4e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generates artificial linear data\n",
    "function artificial_linear_data(N)\n",
    "    X = [range(90, 1200; length=N);]\n",
    "    gamma = rand(Normal(30, 10), N)\n",
    "    y = 50 * X + gamma * 400\n",
    "    (X, y)\n",
    "end\n",
    "\n",
    "X, y = artificial_linear_data(100)\n",
    "size(X), mean(X), std(X), size(y), mean(y), std(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e186949a",
   "metadata": {},
   "outputs": [],
   "source": [
    "function plot_points_regression(X, y)\n",
    "    scatter(X, y, \n",
    "        title = \"Real estate prices prediction\",\n",
    "        xlabel = \"m\\u00b2\",\n",
    "        ylabel = \"\\$\",\n",
    "        yformatter = :plain,\n",
    "        legend = :bottomright,\n",
    "        legendfontsize = 8,\n",
    "        label = \"true data\")\n",
    "end\n",
    "\n",
    "plot_points_regression(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da8b301",
   "metadata": {},
   "source": [
    "Cap 3 lecture Prof Mostafa\n",
    "\n",
    "Colocar aqui a demonstração de minimizar Ein matricialmente (igualar o gradiente a zero), matriz pseudo-inversa de X, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ac3365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that implements linear regression calculation (weights calculation) from (X, y) data available.\n",
    "function linear_regression_weights(X, y)   # normal_equation_weights\n",
    "    N = size(X)[1]\n",
    "    X_til = hcat(ones(N), X)\n",
    "    w = pinv(X_til) * y   # = inv(X_til' * X_til) * X_til'\n",
    "end\n",
    "\n",
    "w = linear_regression_weights(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292ee2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that predicts ŷ values from w and unkwown values of X.\n",
    "function linear_regression_prediction(X, w)\n",
    "    N = size(X)[1]\n",
    "    X_til = hcat(ones(N), X)\n",
    "    ŷ = X_til * w\n",
    "end\n",
    "\n",
    "ŷ = linear_regression_prediction(X, w)\n",
    "r2 = r2_score(ŷ, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62d411d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_points_regression(X, y)\n",
    "plot!(X, ŷ, label = \"prediction\", linewidth = 2)\n",
    "annotate!(250, 72000, text(@sprintf(\"r2-score = %.3f\", r2), 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f7c4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us use the prediction function\n",
    "x = [650]\n",
    "prediction = linear_regression_prediction(x, w)\n",
    "@printf(\"size = %s m2; predicted value = \\$ %0.2f\", x[1], prediction[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aea8969",
   "metadata": {},
   "source": [
    "### dataframe example, d = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb88f86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataframe\n",
    "df = CSV.File(\"QT1data.csv\") |> DataFrame\n",
    "println(first(df, 10))\n",
    "\n",
    "# get y = weight (outcome)\n",
    "y = df.Weight .|> Float64\n",
    "display(typeof(y))\n",
    "\n",
    "# get X = predictors\n",
    "X = df.Height\n",
    "display(size(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57b8c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = linear_regression_weights(X, y)\n",
    "ŷ = linear_regression_prediction(X, w)\n",
    "r2 = r2_score(ŷ, y)\n",
    "\n",
    "scatter(X, y, \n",
    "    title = \"Predicting weight = f(height)\",\n",
    "    label = \"true data\", \n",
    "    legend = :bottomright,\n",
    "    xlabel=\"height (cm)\",\n",
    "    ylabel=\"weight (Kg)\")\n",
    "plot!(X, ŷ, \n",
    "    label = \"prediction\", \n",
    "    linewidth = 2)\n",
    "annotate!(110, 110, text(@sprintf(\"r2-score = %.3f\", r2), 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbcdbb9",
   "metadata": {},
   "source": [
    "### d = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0711f4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get X = predictors\n",
    "feature_cols = [\"Height\", \"Shoe number\"]\n",
    "X = df[:, feature_cols] |> Array\n",
    "display(size(X))\n",
    "\n",
    "w = linear_regression_weights(X, y)\n",
    "ŷ = linear_regression_prediction(X, w)\n",
    "r2 = r2_score(ŷ, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec408374",
   "metadata": {},
   "source": [
    "### d = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f5759c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get X = predictors\n",
    "feature_cols = [\"Shoe number\", \"Age\", \"Height\"]\n",
    "X = df[:, feature_cols] |> Array\n",
    "display(size(X))\n",
    "\n",
    "w = linear_regression_weights(X, y)\n",
    "ŷ = linear_regression_prediction(X, w)\n",
    "r2 = r2_score(ŷ, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
